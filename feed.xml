<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="3.8.6">Jekyll</generator><link href="https://arthurpesah.me/feed.xml" rel="self" type="application/atom+xml" /><link href="https://arthurpesah.me/" rel="alternate" type="text/html" hreflang="en" /><updated>2025-09-30T19:43:22+02:00</updated><id>https://arthurpesah.me/feed.xml</id><title type="html">Arthur Pesah</title><subtitle>Research blog
</subtitle><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><entry><title type="html">Computing with quantum codes using transversal gates</title><link href="https://arthurpesah.me/blog/2023-12-25-transversal-gates/" rel="alternate" type="text/html" title="Computing with quantum codes using transversal gates" /><published>2023-12-25T00:00:00+01:00</published><updated>2023-12-25T00:00:00+01:00</updated><id>https://arthurpesah.me/blog/transversal-gates</id><content type="html" xml:base="https://arthurpesah.me/blog/2023-12-25-transversal-gates/">&lt;p&gt;If you have been following the quantum news lately, you certainly didn’t miss &lt;a href=&quot;https://scirate.com/arxiv/2312.03982&quot;&gt;one of the biggest announcements of the year&lt;/a&gt;: the demonstration of various quantum codes and logical operations on up to 48 logical qubits and 280 physical qubits of a Rydberg atom array. To me, one of the most exciting features of this experiment is its inherent &lt;strong&gt;non-locality&lt;/strong&gt;: it is possible to apply gates between qubits that are far away by simply moving the corresponding atoms, without inducing more errors than we are able to correct. From a quantum error correction point-of-view, this allows two things: the possibility to create codes beyond two dimensions (such as 3D codes or more general LDPC codes), and the possibility to apply logical two-qubit gates without inducing any additional space-time cost: transversal gates can be used instead of the more common lattice surgery of traditional surface code architectures.&lt;/p&gt;

&lt;p&gt;Transversal gates are both the earliest and simplest way to perform computation fault-tolerantly with a quantum code. But those new experimental prospects, along with the recent discovery of many new quantum LDPC codes with great parameters (but not a lot of gates yet!), make research into transversal gates an exciting area again! And if you haven’t had the occasion to learn about them yet, or even logical gates in general, this blog post is for you!&lt;/p&gt;

&lt;p&gt;We will start by building up the edifice necessary to understand transversal gates, defining the notions of logical gates, locality-preserving operators and fault-tolerant gates. This will allow us to define transversal gates and understand why they are useful. We will then give a few examples of such gates on both the surface code and the Steane code. Finally, we will study the limitations of transversal gates through the Eastin-Knill and the Bravyi-König theorem, and glimpse at how those limitations can be by-passed when considering non-transversal implementation methods.&lt;/p&gt;

&lt;h1 id=&quot;definition-and-examples&quot;&gt;Definition and examples&lt;/h1&gt;

&lt;h2 id=&quot;what-is-a-logical-gate&quot;&gt;What is a logical gate?&lt;/h2&gt;

&lt;p&gt;Let’s consider an &lt;code class=&quot;MathJax_Preview&quot;&gt;[[n,k,d]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[n,k,d]]&lt;/script&gt; stabilizer code defined by the stabilizer group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt;.
A &lt;strong&gt;logical unitary gate&lt;/strong&gt; is a unitary operator &lt;code class=&quot;MathJax_Preview&quot;&gt;U&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; acting on the &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; physical qubits of the code, that preserves its codespace &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt;, that is&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    U \vert \psi \rangle \in \mathcal{C}, \; \forall \vert \psi \rangle \in \mathcal{C}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    U \vert \psi \rangle \in \mathcal{C}, \; \forall \vert \psi \rangle \in \mathcal{C}
\end{aligned}&lt;/script&gt;

&lt;p&gt;For instance, if we start in a state &lt;code class=&quot;MathJax_Preview&quot;&gt;a\vert 000\rangle + b\vert 111\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a\vert 000\rangle + b\vert 111\rangle&lt;/script&gt; in the codespace of the repetition code, we want our logical operation to give us another state &lt;code class=&quot;MathJax_Preview&quot;&gt;a'\vert 000\rangle + b'\vert 111\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a'\vert 000\rangle + b'\vert 111\rangle&lt;/script&gt; within the same codespace. Note that if we take our code to be a tensor product of several stabilizer codes (e.g. a tensor product of two surface codes), this definition includes multi-qubit logical gates as well (e.g. a &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; between two surface codes). Also note that logical gates in general can also include measurements, but for the purpose of this post, we will restrain ourselves to logical &lt;em&gt;unitary&lt;/em&gt; gates.&lt;/p&gt;

&lt;p&gt;An important observation is that the set of logical unitary gates forms a group: both the product of two logical gates and the inverse of one preserve the codespace. For the inverse, we can see this by writing the unitary as a block diagonal matrix (with two blocks, one acting on the codespace and one acting on the rest of the Hilbert space) and remember that the inverse of a block diagonal matrix consists of the inverse of each block.&lt;/p&gt;

&lt;p&gt;Let’s now use the fact that we are dealing with stabilizer codes. By definition of the codespace of a stabilizer code, the definition above can be reformulated as&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    S U \vert \psi \rangle = U \vert \psi \rangle, \; \forall S \in \mathcal{S},\; \forall \vert \psi \rangle \in \mathcal{C}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    S U \vert \psi \rangle = U \vert \psi \rangle, \; \forall S \in \mathcal{S},\; \forall \vert \psi \rangle \in \mathcal{C}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Multiplying by &lt;code class=&quot;MathJax_Preview&quot;&gt;U^{\dagger}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U^{\dagger}&lt;/script&gt; on both sides, this is equivalent to:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    U^{\dagger} S U \vert \psi \rangle = \vert \psi \rangle, \; \forall S \in \mathcal{S},\; \forall \vert \psi \rangle \in \mathcal{C}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    U^{\dagger} S U \vert \psi \rangle = \vert \psi \rangle, \; \forall S \in \mathcal{S},\; \forall \vert \psi \rangle \in \mathcal{C}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Or, using the fact that the inverse of a logical gate is also a logical gate:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    U S U^{\dagger} \vert \psi \rangle = \vert \psi \rangle, \; \forall S \in \mathcal{S},\; \forall \vert \psi \rangle \in \mathcal{C}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    U S U^{\dagger} \vert \psi \rangle = \vert \psi \rangle, \; \forall S \in \mathcal{S},\; \forall \vert \psi \rangle \in \mathcal{C}
\end{aligned}&lt;/script&gt;

&lt;p&gt;In other words, logical gates turn stabilizers into stabilizers! From this point-of-view, it is tempting to redefine logical gates as operators that preserve the stabilizer group. However, this is not exactly true: while elements of the stabilizer group are by definition Pauli operators, there is no constraint for &lt;code class=&quot;MathJax_Preview&quot;&gt;USU^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;USU^\dagger&lt;/script&gt; to be Pauli. For instance, in the 3D color code, the transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; gate turns Pauli &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizers into products of &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; gates, which are (non-Pauli) stabilizers, and are therefore outside of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Denoting the group of (both Pauli and non-Pauli) stabilizers by &lt;code class=&quot;MathJax_Preview&quot;&gt;\widetilde{\mathcal{S}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\widetilde{\mathcal{S}}&lt;/script&gt;, we can now give the following equivalent definition of a logical gate. A unitary operator &lt;code class=&quot;MathJax_Preview&quot;&gt;U&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; is a logical gate if and only if&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    USU^{\dagger} \in \widetilde{\mathcal{S}}, \; \forall S \in \mathcal{S}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    USU^{\dagger} \in \widetilde{\mathcal{S}}, \; \forall S \in \mathcal{S}
\end{aligned}&lt;/script&gt;

&lt;p&gt;So whenever we introduce a new potential logical gate for a given code, the first step is always to verify that it maps Pauli stabilizers to general stabilizers&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. The second step is to check what logical operation it performs. Indeed, it is in principle possible that applying Hadamard gates on all the physical qubits ends up implementing a completely different logical gate than a Hadamard. To determine the effect of a logical gate, there are two possibilities:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;We check its effect on logical states. For instance, if we can prove that it maps &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0\rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0\rangle_L&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert +\rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert +\rangle_L&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 1\rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 1\rangle_L&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert -\rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert -\rangle_L&lt;/script&gt;, it means we are dealing with a logical Hadamard.&lt;/li&gt;
  &lt;li&gt;We check its effect on logical Paulis. For instance, showing that &lt;code class=&quot;MathJax_Preview&quot;&gt;UX_LU^{\dagger}=Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;UX_LU^{\dagger}=Z_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;UZ_LU^{\dagger}=X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;UZ_LU^{\dagger}=X_L&lt;/script&gt; also proves that &lt;code class=&quot;MathJax_Preview&quot;&gt;U&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; is a logical Hadamard.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;While we can find examples of the two methods used in the literature, I tend to prefer the second one as the resulting proofs are often easier to visualize.&lt;/p&gt;

&lt;p&gt;In this context, it can be useful to memorize how the most important gates transform Pauli operators. Here are a few examples:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{H}: X \leftrightarrow Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{H}: X \leftrightarrow Z&lt;/script&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}: X \rightarrow Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}: X \rightarrow Y&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z \rightarrow Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z \rightarrow Z&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger: X \rightarrow -Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger: X \rightarrow -Y&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z \rightarrow Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z \rightarrow Z&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}: X \rightarrow e^{-i\pi/4} \texttt{SX}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}: X \rightarrow e^{-i\pi/4} \texttt{SX}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z \rightarrow Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z \rightarrow Z&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}^\dagger: X \rightarrow e^{i\pi/4} \texttt{S}^\dagger\texttt{X}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}^\dagger: X \rightarrow e^{i\pi/4} \texttt{S}^\dagger\texttt{X}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z \rightarrow Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z \rightarrow Z&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}: XI \rightarrow XX,\; IX \rightarrow IX,\; ZI \rightarrow ZI&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}: XI \rightarrow XX,\; IX \rightarrow IX,\; ZI \rightarrow ZI&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;IZ \rightarrow ZZ&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;IZ \rightarrow ZZ&lt;/script&gt; (where the first qubit is the control and the second is the target)&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CZ}: XI \rightarrow XZ,\; IX \rightarrow ZX,\; ZI \rightarrow ZI&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CZ}: XI \rightarrow XZ,\; IX \rightarrow ZX,\; ZI \rightarrow ZI&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;IZ \rightarrow IZ&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;IZ \rightarrow IZ&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CCZ}: XII \rightarrow X(\texttt{CZ})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CCZ}: XII \rightarrow X(\texttt{CZ})&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;ZII \rightarrow ZII&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;ZII \rightarrow ZII&lt;/script&gt; (and similarly when putting the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; on the two other qubits)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-is-a-fault-tolerant-gate&quot;&gt;What is a fault-tolerant gate?&lt;/h2&gt;

&lt;p&gt;While our definition of logical gates guarantees that the code itself is preserved, it does not guarantee that the error-correcting properties are. For instance, imagine a code defined on a square grid, with qubits as vertices, and a logical gate made of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt;s between disjoint pairs of physical qubits. Something like this:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/fault-tolerant-example-1.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Now, imagine that an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error appears on the top-left qubit. We can understand how this error propagates by looking at the effect of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; on it. As we saw in the previous section, &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT} (XI) \texttt{CNOT}^{\dagger} = XX&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT} (XI) \texttt{CNOT}^{\dagger} = XX&lt;/script&gt;, or equivalently &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT} (XI) = (XX) \texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT} (XI) = (XX) \texttt{CNOT}&lt;/script&gt;. This can be visualized by the following circuit:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/cnot-error-propagation.png&quot; height=&quot;150&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;In other words, a single &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error propagates into two &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors once we have applied our logical gate. Now, let’s suppose that the distance of this code is &lt;code class=&quot;MathJax_Preview&quot;&gt;4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;4&lt;/script&gt; and that any vertical string of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; is an example of minimum-weight logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operator. It means that with only &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt; errors present before applying the gate, we can get a logical error once the gate has been applied. In other words, the &lt;strong&gt;effective distance&lt;/strong&gt; has been reduced by two.&lt;/p&gt;

&lt;p&gt;As a second (and even worse!) example, imagine that our &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}s&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}s&lt;/script&gt; were instead acting on intersecting pairs of qubits:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/fault-tolerant-example-2.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Then, a single qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error can propagate into &lt;code class=&quot;MathJax_Preview&quot;&gt;d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors and create a logical error, effectively reducing the distance to one!&lt;/p&gt;

&lt;p&gt;So what is a fault-tolerant logical gate? For a given family of code with a growing distance, a &lt;strong&gt;fault-tolerant logical gate&lt;/strong&gt; is a gate that doesn’t reduce the effective distance (i.e. the minimum number of physical errors that creates a logical error after applying the gate) to &lt;code class=&quot;MathJax_Preview&quot;&gt;O(1)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;O(1)&lt;/script&gt; when the family is growing&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. For instance, generalizing the two examples above to families of codes of size &lt;code class=&quot;MathJax_Preview&quot;&gt;L \times L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \times L&lt;/script&gt;, the first gate would be considered fault-tolerant while the second one wouldn’t.&lt;/p&gt;

&lt;p&gt;Within the class of fault-tolerant gates, locality-preserving gates are particularly useful to consider and easier to manipulate in practice. A &lt;strong&gt;locality-preserving gate&lt;/strong&gt; is a gate &lt;code class=&quot;MathJax_Preview&quot;&gt;U&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; that transforms small errors to small errors, that is, if &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt; is a Pauli error supported on &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell&lt;/script&gt; qubits, &lt;code class=&quot;MathJax_Preview&quot;&gt;UeU^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;UeU^\dagger&lt;/script&gt; must be supported on &lt;code class=&quot;MathJax_Preview&quot;&gt;c \ell&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;c \ell&lt;/script&gt; qubits, where &lt;code class=&quot;MathJax_Preview&quot;&gt;c=O(1)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;c=O(1)&lt;/script&gt;. Equivalently, a locality-preserving gate is a gate implemented via a constant depth circuit. Again, our first example is locality-preserving while the second one is not.&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-transversal-gate&quot;&gt;What is a transversal gate?&lt;/h2&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;The easiest examples of locality-preserving gates are the transversal gates. To understand them, let’s consider the setting where we are trying to apply a logical gate between multiple copies of a code (e.g. a CNOT between two surface code qubits). Each copy of the code is often called a &lt;strong&gt;code block&lt;/strong&gt;. &lt;strong&gt;Transversal gates&lt;/strong&gt; are logical gates that don’t propagate errors within each code block: one-qubit errors remain one-qubit errors on each code block, thereby preserving the distance. To guarantee this, transversal gates should never couple multiple physical qubits of the same code block. This include logical gates that can be written as a tensor product of single-qubit physical gates only, but also those made of multi-qubit gates connecting qubits of different code blocks.&lt;/p&gt;

&lt;p&gt;For instance, Pauli gates are transversal for all stabilizer codes, since by definition Pauli logicals can always be written as a tensor product of Pauli operators. But, as we will soon see, the gate made of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt;s between corresponding qubits on two code blocks also implements a transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; for any CSS code:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/transversal-cnot.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;h3 id=&quot;example-1-steane-code&quot;&gt;Example 1: Steane code&lt;/h3&gt;

&lt;p&gt;Let’s take a look at some examples of transversal gates in codes that we know. Let’s start with the Steane code. As a reminder, the Steane code is defined on the following lattice, where qubits are on vertices, and &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers on faces:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/steane-code-lattice.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Let’s consider the gate made of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{H}&lt;/script&gt; acting on every qubits. Is it a logical gate? To determine this, let’s see how it transforms stabilizers. Since &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{H}&lt;/script&gt; transforms &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;, and vice-versa, it means that any plaquette stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;XXXX&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XXXX&lt;/script&gt; will turn into &lt;code class=&quot;MathJax_Preview&quot;&gt;ZZZZ&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;ZZZZ&lt;/script&gt; supported on the same plaquette, and similarly, any stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;ZZZZ&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;ZZZZ&lt;/script&gt; will turn into &lt;code class=&quot;MathJax_Preview&quot;&gt;XXXX&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XXXX&lt;/script&gt;. Since the resulting operators are stabilizers as well, it means that our gate preserves the stabilizer group! So it’s a logical gate.&lt;/p&gt;

&lt;p&gt;What is the effect of this logical gate? Let’s see how it transforms the logical Paulis. For that, we can pick any representative Pauli &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; logical, such as those:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/steane-code-logicals.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Since our gate turns &lt;code class=&quot;MathJax_Preview&quot;&gt;XXX&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XXX&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;ZZZ&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;ZZZ&lt;/script&gt; and vice-versa, it means that it exchanges &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt; and is therefore a logical Hadamard!&lt;/p&gt;

&lt;p&gt;Can we also implement an &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gate transversally? Let’s see what happens when we apply &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; to all the physical qubits. Since &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}X\texttt{S}^\dagger=Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}X\texttt{S}^\dagger=Y&lt;/script&gt;, every &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette will turn into &lt;code class=&quot;MathJax_Preview&quot;&gt;Y^{\otimes 4}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y^{\otimes 4}&lt;/script&gt; under the action of our gate. Now, is &lt;code class=&quot;MathJax_Preview&quot;&gt;Y^{\otimes 4}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y^{\otimes 4}&lt;/script&gt; a stabilizer? Using &lt;code class=&quot;MathJax_Preview&quot;&gt;XZ=-iY&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XZ=-iY&lt;/script&gt;, we can see that multiplying an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; plaquette results in the stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;(-i)^{4} Y^{\otimes 4}=Y^{\otimes 4}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(-i)^{4} Y^{\otimes 4}=Y^{\otimes 4}&lt;/script&gt;, so &lt;code class=&quot;MathJax_Preview&quot;&gt;Y^{\otimes 4}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y^{\otimes 4}&lt;/script&gt; is indeed a stabilizer. Moreover, since &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}Z\texttt{S}^\dagger=Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}Z\texttt{S}^\dagger=Z&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; plaquettes are preserved. Hence, our gate preserves the codespace and is therefore a valid transversal logical gate!&lt;/p&gt;

&lt;p&gt;Let’s now look at the action of our gate on the logicals! For our gate to be a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gate, we need to prove that &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S} \bar{X} \texttt{S}^\dagger = \bar{Y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S} \bar{X} \texttt{S}^\dagger = \bar{Y}&lt;/script&gt;. Picking the logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; representative supported on three qubits from the figure above, we can see that the gate turns &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{X}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{X}&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;Y^{\otimes 3}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y^{\otimes 3}&lt;/script&gt;. But is &lt;code class=&quot;MathJax_Preview&quot;&gt;Y^{\otimes 3}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y^{\otimes 3}&lt;/script&gt; a &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; logical for our code? By definition, &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{Y}=i\bar{X}\bar{Z}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{Y}=i\bar{X}\bar{Z}&lt;/script&gt;. Multiplying the representatives of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{X}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{X}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{Z}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{Z}&lt;/script&gt; drawn in the figure above and using &lt;code class=&quot;MathJax_Preview&quot;&gt;XZ=-iY&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XZ=-iY&lt;/script&gt; again, we get the operator &lt;code class=&quot;MathJax_Preview&quot;&gt;(-i)^3 Y^{\otimes 3}=i Y^{\otimes 3}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(-i)^3 Y^{\otimes 3}=i Y^{\otimes 3}&lt;/script&gt;. So &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{Y}=i\bar{X}\bar{Z}=i^2 Y^{\otimes 3}=-Y^{\otimes 3}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{Y}=i\bar{X}\bar{Z}=i^2 Y^{\otimes 3}=-Y^{\otimes 3}&lt;/script&gt;, and the product of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gates turns any &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; logical into a &lt;code class=&quot;MathJax_Preview&quot;&gt;-Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-Y&lt;/script&gt; logical. So perhaps surprisingly, what our gate actually implements is a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger&lt;/script&gt;!&lt;/p&gt;

&lt;p&gt;To implement an actual logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt;, one simple solution is to instead apply &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger&lt;/script&gt; everywhere. However, there exists a second solution: take a bipartition of the qubits of the Steane code, that is, divide the vertices into two colors (black and white), such that two vertices of the same color are never incident to each other through an edge:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/steane-code-partition.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Since we have an odd number of qubits, one color will contain more vertices than the other. In the drawing above, there are more black vertices than white vertices. However, every plaquette contains the same number of white and black qubits. Now, let’s apply &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; to the four black qubits, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger&lt;/script&gt; to the three white qubits. Using the same calculation techniques as above, it should be an easy exercise to show that this gate also implements a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt;:&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;: Show that the following operator made of a combination of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger&lt;/script&gt; implements a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gate. &lt;a href=&quot;#solution-of-the-exercise&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot; class=&quot;figure message&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/steane-code-s-gate.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The advantage of this later implementation based on a bipartition of qubits is that it generalizes well to color codes, so it will be useful when we will discuss color codes in a future post! It also shows that the transversal implementation of a logical gate is not necessarily unique.&lt;/p&gt;

&lt;p&gt;Since we are on a good streak, let’s go on and look at the &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; gate! Can we implement a &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; gate transversally on the Steane code? Unfortunately, the answer is no this time. For instance, try to show that using a combination of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}^\dagger&lt;/script&gt; on all qubits does not implement a logical gate at all:&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;: Show that any operator made of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}^\dagger&lt;/script&gt; on every physical qubit of the Steane code does &lt;strong&gt;not&lt;/strong&gt; implement a logical gate. &lt;a href=&quot;#solution-of-the-exercise&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;More generally, we will soon see that it is not possible to implement non-Clifford gates transversally on 2D codes, so this eliminates any other possibility of transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; gate on the Steane code.&lt;/p&gt;

&lt;p&gt;There’s one last important gate that we can implement transversally on the Steane code: the &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; gate. As a matter of fact, &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; is transversal for any CSS code! Indeed, &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; maps &lt;code class=&quot;MathJax_Preview&quot;&gt;X \otimes I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X \otimes I&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;X \otimes X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X \otimes X&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;I \otimes Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;I \otimes Z&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;Z \otimes Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z \otimes Z&lt;/script&gt;, and preserves &lt;code class=&quot;MathJax_Preview&quot;&gt;I \otimes X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;I \otimes X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z \otimes I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z \otimes I&lt;/script&gt;. So any &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;S_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_X&lt;/script&gt; of the control code will be mapped to &lt;code class=&quot;MathJax_Preview&quot;&gt;S_X \otimes S_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_X \otimes S_X&lt;/script&gt;, which stabilizes the tensor product of the two codes, and similarly for &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers on the target code. So the transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; gate preserves the stabilizer group and is therefore a valid logical gate. Moreover, it will map any logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; representative of the control code to a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X \otimes X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X \otimes X&lt;/script&gt; representative of the two codes, and similarly for the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; logicals of the target code, thereby implementing a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;However, despite its simplicity, the transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; is often too impractical when dealing with a planar architecture. Indeed, to implement it physically, it requires either putting one code block above the other or having long-range connections. Alternatively, methods based on lattice surgery or code deformation, that I will discuss in a separate blog post, only use geometrically-local operations in 2D, making it more practical on planar architectures. On architectures that are not restricted to 2D operations, such as the &lt;a href=&quot;https://scirate.com/arxiv/2312.03982&quot;&gt;one&lt;/a&gt; I was talking about in the intro, the transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; is however perfectly valid and has even been implemented in real life!&lt;/p&gt;

&lt;h3 id=&quot;example-2-surface-code&quot;&gt;Example 2: Surface code&lt;/h3&gt;

&lt;p&gt;The biggest advantage of the Steane code (and more generally, color codes) is the ease with which it can implement the full Clifford group transversally. As we will now see, things gets a bit trickier with surface codes.&lt;/p&gt;

&lt;p&gt;Let’s start by considering an non-rotated surface code with periodic boundary conditions. We put qubits on edges, &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizers (red) on plaquettes and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers (blue) on vertices:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/transversal-gates/surface-code-stabilizers.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As a reminder, this version of the surface code encodes two logical qubits, whose logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators correspond to the two types of non-trivial loops of the torus, in the primal and dual pictures respectively:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/transversal-gates/surface-code-x-logicals.png&quot; style=&quot;display: block; float: left;&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/transversal-gates/surface-code-z-logicals.png&quot; style=&quot;display: block; float: right;&quot; /&gt;&lt;/p&gt;
&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;p&gt;So what happens when we apply a Hadamard gate on all physical qubits of the code? It turns the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette stabilizers into &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; plaquette operators, and the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; vertex stabilizers into &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; vertex operators. Since &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; plaquette and &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; vertex operators are not stabilizers of the surface code we are considering, the operation is &lt;em&gt;not&lt;/em&gt; a logical gate according to our definition. However, that’s where we might want to loosen our definition a little bit: the code resulting from the application of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{H}&lt;/script&gt; everywhere is still a valid surface code, with just a different convention for which stabilizers are &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;. Since we have periodic boundary conditions, this code transformation can also be seen as a simple translation by half an edge in the horizontal and vertical directions. Moreover, &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; logicals of the initial code are turned into &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; logicals of the new code, so the operation corresponds to a logical Hadamard applied simultaneously to the two logical qubits of the toric code. So, as long as we keep track of what the stabilizers are at every instant, we are in principle allowed to modify the code when applying logical gates (particularly if the new code is just a translation or rotation of the original one).&lt;/p&gt;

&lt;p&gt;More care is needed when considering this operation on the planar code, in the context of a broader quantum circuit. Indeed, when using a rotated planar code, we can see the code resulting from the application of the transversal Hadamard as a rotation of the original code.&lt;/p&gt;

&lt;p&gt;Now, let’s imagine that we would like to apply a &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; after the Hadamard. In most proposed fault-tolerant architectures based on the surface code, &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt;s are done using code deformation or lattice surgery. And for those to work, we need &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; logicals to be aligned on all the different patches of surface code. So to recover the original code with logicals aligned as before, we need to somehow rotate the code back. This can be done either by physically moving the qubits around, which is often not feasible in the context of a 2D architecture, or by applying some operations to perform the rotation without moving qubits. This &lt;a href=&quot;https://arxiv.org/abs/1111.4022&quot;&gt;can be done fault-tolerantly&lt;/a&gt; using lattice surgery on some ancilla patches, and a few &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{SWAP}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{SWAP}&lt;/script&gt; gates. In summary, it is possible to implement the Hadamard gate transversally on the surface code, but on a planar architecture, this requires some lattice surgery if we want to apply logical gates afterwards.&lt;/p&gt;

&lt;p&gt;What about the &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gate? Applying it on all physical qubits turns &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizers into &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; stabilizers, and preserves the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; ones. This “ZY surface code” defines a valid code, and you can check that the transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; has the right effect on the logicals. However, contrary to the Hadamard case, this new code is not a simple translation or rotation of the original surface code, it is a fundamentally different code with a different set of transversal gates. For instance, it is lacking a transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; (as a non-CSS code), which is replaced by a transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S} \; \texttt{CNOT} \; \texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S} \; \texttt{CNOT} \; \texttt{S}^\dagger&lt;/script&gt;. But applying this newly-available gate after having applied a transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gate would undo the &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt;, defeating the purpose of having it. I believe that a similar reasoning could be done when considering &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt;s implemented through lattice surgery. More generally, to design a complete architecture with a universal set of gates, imposing that gates preserve the codespace (potentially up to an isomorphism of the Tanner graph, like a rotation or translation of the code) is required. We therefore conclude that, contrary to the Steane code, the &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gate is &lt;strong&gt;not&lt;/strong&gt; available transversally on the surface code. As we will see in different posts, there are other ways to implement it, such as state injection, braiding, or fold-transversality.&lt;/p&gt;

&lt;p&gt;What about other gates? Similarly to the Steane code, non-Clifford gates such as &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; are not available on the surface code. Let’s now try to understand why using more general results in the field.&lt;/p&gt;

&lt;h1 id=&quot;limitations-on-transversal-gates&quot;&gt;Limitations on transversal gates&lt;/h1&gt;

&lt;p&gt;Now that we have understood how transversal gates work, let’s take a step back and try to answer the following question: given any stabilizer code, what types of gate can be implemented transversally? As we will see in this section, the answer is a resounding &lt;em&gt;not enough&lt;/em&gt;. The &lt;a href=&quot;https://arxiv.org/abs/0811.4262&quot;&gt;Eastin-Knill theorem&lt;/a&gt; states that no universal gate set can be fully implemented transversally, while the &lt;a href=&quot;https://arxiv.org/abs/1206.1609&quot;&gt;Bravyi-König theorem&lt;/a&gt; states that the subset of gates that can be implemented transversally depends on the dimension of the code.&lt;/p&gt;

&lt;h2 id=&quot;eastin-knill-theorem&quot;&gt;Eastin-Knill theorem&lt;/h2&gt;

&lt;p&gt;Let’s start with the Eastin-Knill theorem. The statement of the theorem from the original paper is the following:&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Theorem (Eastin-Knill)&lt;/strong&gt;: For any nontrivial local-error-detecting quantum code, the set of logical unitary product operators is not universal&lt;/p&gt;

&lt;p&gt;Let’s try to understand what that means. First, the theorem imposes a limit on &lt;em&gt;logical unitary product operators&lt;/em&gt;. For any partition of our physical qubits into &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; subsystems &lt;code class=&quot;MathJax_Preview&quot;&gt;\{ \mathcal{Q}_i \}_{1 \leq i \leq m}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{ \mathcal{Q}_i \}_{1 \leq i \leq m}&lt;/script&gt;, each of dimension &lt;code class=&quot;MathJax_Preview&quot;&gt;d_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d_i&lt;/script&gt;, a logical unitary product operator is a logical operator of the form &lt;code class=&quot;MathJax_Preview&quot;&gt;\otimes_{i=1}^m U_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\otimes_{i=1}^m U_i&lt;/script&gt; where each &lt;code class=&quot;MathJax_Preview&quot;&gt;U_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U_i&lt;/script&gt; acts on subsystem &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{Q}_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{Q}_i&lt;/script&gt;. For instance, if we pick each &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{Q}_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{Q}_i&lt;/script&gt; to contain exactly one physical qubit, those are exactly transversal operators.&lt;/p&gt;

&lt;p&gt;Then, any &lt;em&gt;local-error-detecting quantum code&lt;/em&gt; is concerned by this theorem. The notion of locality here is induced by the partition of our physical qubits. More precisely, a local error here is an error supported on a given subsystem, and the only assumption of our code is that those errors can be detected. This is translated mathematically by the so-called Knill-Laflamme condition, stating that &lt;code class=&quot;MathJax_Preview&quot;&gt;P E P \propto P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P E P \propto P&lt;/script&gt; for all local errors, where &lt;code class=&quot;MathJax_Preview&quot;&gt;P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; is the projector into the codespace. For instance, restricting ourselves to transversal gates, any stabilizer code with a distance &lt;code class=&quot;MathJax_Preview&quot;&gt;d \geq 2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d \geq 2&lt;/script&gt; will be concerned by this theorem.&lt;/p&gt;

&lt;p&gt;Finally, what is a &lt;em&gt;universal&lt;/em&gt; gate set? It is a gate set that can approximate any unitary in &lt;code class=&quot;MathJax_Preview&quot;&gt;U(2^n)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U(2^n)&lt;/script&gt; up to arbitrary precision. For instance, the set &lt;strong&gt;generated&lt;/strong&gt; by the gates &lt;code class=&quot;MathJax_Preview&quot;&gt;\{ \texttt{H}, \texttt{CNOT}, \texttt{T} \}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{ \texttt{H}, \texttt{CNOT}, \texttt{T} \}&lt;/script&gt;, i.e. that contains all the products of those gates, is universal.&lt;/p&gt;

&lt;p&gt;How is the Eastin-Knill theorem proven? The main idea is to show that the group of logical unitary product operators is finite, while any universal gate set is infinite. The technical details of the proof rely on the theory of Lie groups and algebras, and would require a separate post (in preparation!) to discuss properly.&lt;/p&gt;

&lt;p&gt;While the application domain of this theorem is already quite large—it applies both beyond stabilizer codes and beyond transversal gates—it has been generalized even further in the literature. For instance, the same limit applies when looking at locality-preserving gates in general, rather than product operators.&lt;/p&gt;

&lt;h2 id=&quot;bravyi-könig-theorem&quot;&gt;Bravyi-König theorem&lt;/h2&gt;

&lt;p&gt;The Bravyi-König theorem states that the transversal gates (or more generally the gates implemented by a constant-depth quantum circuit) of a &lt;code class=&quot;MathJax_Preview&quot;&gt;D&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt;-dimensional quantum code are limited to the &lt;code class=&quot;MathJax_Preview&quot;&gt;D&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt;-th level of the Clifford hierarchy. The &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;-qubit &lt;strong&gt;Clifford hierarchy&lt;/strong&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;\left(\mathcal{P}_j\right)_{j \geq 1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\left(\mathcal{P}_j\right)_{j \geq 1}&lt;/script&gt; is a family of sets of unitaries that can be defined by induction as follow:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The first element &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{P}_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{P}_1&lt;/script&gt; is the &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;-qubit Pauli group.&lt;/li&gt;
  &lt;li&gt;The &lt;code class=&quot;MathJax_Preview&quot;&gt;j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;-th element &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{P}_j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{P}_j&lt;/script&gt; is the set of &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;-qubit unitaries &lt;code class=&quot;MathJax_Preview&quot;&gt;U&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; such that &lt;code class=&quot;MathJax_Preview&quot;&gt;U \mathcal{P}_1 U^{\dagger} \subseteq \mathcal{P}_{j-1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U \mathcal{P}_1 U^{\dagger} \subseteq \mathcal{P}_{j-1}&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For instance, &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{P}_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{P}_2&lt;/script&gt; is the set of all unitaries such that &lt;code class=&quot;MathJax_Preview&quot;&gt;U \mathcal{P}_1 U^{\dagger} \subseteq \mathcal{P}_{1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U \mathcal{P}_1 U^{\dagger} \subseteq \mathcal{P}_{1}&lt;/script&gt;, or in other words, all the unitaries that preserve the Pauli group. This is known as the &lt;strong&gt;Clifford group&lt;/strong&gt;, which can be generated by &lt;code class=&quot;MathJax_Preview&quot;&gt;\{\texttt{H}, \texttt{S}, \texttt{CNOT}\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{\texttt{H}, \texttt{S}, \texttt{CNOT}\}&lt;/script&gt;. An important characteristic of the Clifford group is that it is not universal, and any circuit starting from the &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle&lt;/script&gt; state and consisting uniquely of Clifford gates can be simulated efficiently on a classical computer (using the &lt;a href=&quot;https://arxiv.org/abs/quant-ph/0406196&quot;&gt;stabilizer tableau formalism&lt;/a&gt;). Universality is achieved from the next element of the Clifford hierarchy, &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{P}_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{P}_3&lt;/script&gt;, which contains gates such as &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CCX}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CCX}&lt;/script&gt;. More generally, &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{P}_j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{P}_j&lt;/script&gt; contains &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{R}_k=\begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; e^{2i\pi/2^{j}} \end{pmatrix}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\texttt{R}_k=\begin{pmatrix} 1 &amp; 0 \\ 0 &amp; e^{2i\pi/2^{j}} \end{pmatrix} %]]&gt;&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{C}^{j-1} \texttt{X}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{C}^{j-1} \texttt{X}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Let’s now state the theorem as originally formulated in the &lt;a href=&quot;https://arxiv.org/abs/1206.1609&quot;&gt;Bravyi-König paper&lt;/a&gt;:&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Theorem (Bravyi-König)&lt;/strong&gt;: Suppose a unitary operator &lt;code class=&quot;MathJax_Preview&quot;&gt;U&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; implementable by a constant-depth quantum circuit preserves the codespace &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt; of a topological stabilizer code on a &lt;code class=&quot;MathJax_Preview&quot;&gt;D&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;D&lt;/script&gt;-dimensional lattice, &lt;code class=&quot;MathJax_Preview&quot;&gt;D \geq 2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;D \geq 2&lt;/script&gt;. Then the restriction of &lt;code class=&quot;MathJax_Preview&quot;&gt;U&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U&lt;/script&gt; onto &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt; implements an encoded gate from the set &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{P}_D&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{P}_D&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Applying this theorem to 2D codes, we see that they have their transversal gates limited to the Clifford group, so no hope of finding a transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gate on the 2D surface or color code. This justifies the need for magic-state distillation, a method to implement a &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gate (or any other non-Clifford gate) using state injection (more on that in the next section).&lt;/p&gt;

&lt;p&gt;What about 3D codes? Those can in principle implement transversal non-Clifford gates, which is one of their key advantages. For instance, the 3D toric code has a &lt;a href=&quot;https://arxiv.org/abs/1801.04255&quot;&gt;transversal CCZ&lt;/a&gt;, and the 3D color code (with open boundaries) has a &lt;a href=&quot;https://arxiv.org/abs/1410.0069&quot;&gt;transversal T&lt;/a&gt;. However, you might object, doesn’t the Eastin-Knill theorem also apply to 3D codes, meaning that their transversal gate set is still not universal? That’s right! For example, the 3D toric code doesn’t have a transversal Hadamard gate.
But as we will discuss in the next section, the key difference with the 2D case is that it is much less costly to implement a fault-tolerant &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{H}&lt;/script&gt; than a fault-tolerant &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; non-transversally using state injection.&lt;/p&gt;

&lt;p&gt;Note that the Bravyi-König theorem can also be generalized to &lt;a href=&quot;https://arxiv.org/abs/1408.1720&quot;&gt;subsystem codes&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;how-can-we-circumvent-those-limitations&quot;&gt;How can we circumvent those limitations?&lt;/h2&gt;

&lt;p&gt;While those two theorems put severe restrictions on how to implement fault-tolerant gates on quantum codes, there are many ways to circumvent them! The general idea is that those theorems apply to &lt;em&gt;unitary&lt;/em&gt; implementations only. So implementations involving measurements do not fall under the assumptions of Eastin-Knill and Bravyi-König!&lt;/p&gt;

&lt;p&gt;One example of non-transversal method to implement a logical gate is through state injection, where a certain ancilla state is coupled to our qubit, and a conditional measurement is used to implement a gate on this qubit. For instance, an &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{H}&lt;/script&gt; gate can be implemented by preparing an ancilla qubit in the &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert+\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert+\rangle&lt;/script&gt; state and using the following circuit:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/h-injection.png&quot; height=&quot;100&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;So for a given code, if there exists a method to prepare it in the logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert+\rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert+\rangle_L&lt;/script&gt; state (which is often the case, just exchange &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers when preparing the state) and to implement a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CZ}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CZ}&lt;/script&gt; gate, then it’s possible to implement the Hadamard gate as well. It is for instance the case of the 3D toric code, which has a transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CZ}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CZ}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CCZ}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CCZ}&lt;/script&gt; but no transversal &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{H}&lt;/script&gt;. Using Hadamard state injection allows to get a universal logical gate set on this code. So why isn’t everyone using 3D toric codes to perform encoded computation? Apart from the experimental challenges, I would say that the main reason is the lack of evidence that this method, when considered in an end-to-end architecture, actually reduces the overhead compared to more traditional techniques (we even have evidence of &lt;a href=&quot;https://arxiv.org/abs/2101.02211&quot;&gt;the opposite&lt;/a&gt;). This is mainly due to 3D codes having a worse distance scaling than 2D codes.&lt;/p&gt;

&lt;p&gt;A more common example of state injection is magic state distillation, where an approximation of the state &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T} \vert + \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T} \vert + \rangle_L&lt;/script&gt; (a so-called &lt;em&gt;magic state&lt;/em&gt;) is prepared and injected onto a code using the following circuit&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/intro-qec/magic-state-distillation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This results in a &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; gate being applied to the code. The main difficulty of this method comes from the preparation of the magic state, and countless papers and theses have been written on this topic! The main idea is to start with a noisy &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; state and distill it into a clean one, often using quantum codes that can implement &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; gates transversally in the process. Magic state distillation is for instance the preferred method to implement the &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; gate on the surface code.&lt;/p&gt;

&lt;p&gt;Another method to implement logical gates fault-tolerantly is code switching, where measurements are used to switch between two codes with different sets of transversal gates, while preserving the logical information. For instance, &lt;a href=&quot;https://arxiv.org/abs/2306.17686&quot;&gt;code switching between the 2D and 3D color code&lt;/a&gt; allows to implement both the &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; gate (using the 3D color code) and the &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{H}&lt;/script&gt; gate (using the 2D color code), which make up a universal gate set when adding &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{CNOT}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{CNOT}&lt;/script&gt; (implementable on both codes).&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this post, we looked at the definition of logical gates—operations that preserve the codespace—, fault-tolerant gates—operations that don’t propagate errors uncontrollably—, and transversal gates—operations that don’t propagate errors at all within a codeblock. After studying proof techniques to show that a gate is a logical gate, we considered a few examples of transversal gates in codes that you know. In particular, we showed that the Steane code can implement the full Clifford group transversally, while the surface code only has the Hadamard gate available (modulo a rotation of the code). Finally, we looked at general limitations on transversal gates through the Eastin-Knill and the Bravyi-König theorem. Due to those limitations, we discussed how many other methods are available to circumvent those theorems and implement logical gates fault-tolerantly. Therefore, there is much more to say about logical gates and I hope to continue this series with topics such as lattice surgery, fold-transversality, braiding, code switching, etc.&lt;/p&gt;

&lt;p&gt;However, despite this abundance of more complicated techniques to implement logical gates, research in transversal gates is still very much active and many open questions remain to be answered. In particular, with the recent rise of new qubit architectures which are not constrained by locality and of new LDPC codes which exploit this non-locality to drastically improve the (asymptotic) qubit overhead of quantum codes, transversal gates are becoming popular again. For instance, implementing a CNOT transversally by moving qubits that are far away close to each other could be less costly than performing lattice surgery (which involves the use some ancilla patches). But all the transversal gates of those LDPC codes have very much not been figured out. Only recently have the &lt;a href=&quot;https://arxiv.org/abs/2310.16982&quot;&gt;first codes with a constant rate and some transversal non-Clifford gates&lt;/a&gt; been found. Finding non-Clifford transversal gates on good LDPC codes (i.e. with a constant rate AND a linear distance) with extensive addressability (i.e. where logical gates could be implemented on all logical qubits, or pairs of logical qubits, individually) could result in very low-overhead fault-tolerant architectures.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Acknowledgment&lt;/strong&gt;: Big thanks to Asmae Benhemou and George Umbrarescu for their feedbacks on this post!&lt;/p&gt;

&lt;h2 id=&quot;solution-of-the-exercise&quot;&gt;Solution of the exercise&lt;/h2&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;: Show that the following operator made of a combination of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger&lt;/script&gt; implements a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gate. &lt;a href=&quot;#solution-of-the-exercise&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center;&quot; class=&quot;figure message&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/transversal-gates/steane-code-s-gate.png&quot; height=&quot;250&quot; /&gt;
&lt;/p&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Correction&lt;/strong&gt;: Let’s start by showing that this operator preserves the stabilizer group. Since both &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger&lt;/script&gt; preserve &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;, we just need to look at the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquettes. We note that each plaquette has exactly two &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; and two &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger&lt;/script&gt; applied to it.
So the gate transforms &lt;code class=&quot;MathJax_Preview&quot;&gt;XXXX&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XXXX&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;YY(-Y)(-Y)=YYYY&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;YY(-Y)(-Y)=YYYY&lt;/script&gt;, which is a stabilizer (as we proved at the beginning of the section). This means that the gate preserves the stabilizer group. We now need to study its logical action. Since it preserves &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators, any logical &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; representative is preserved. Let’s now pick a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; representative, such as the one supported on the three bottom qubits of the triangle. Since it contains a single &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}^\dagger&lt;/script&gt;, it transforms &lt;code class=&quot;MathJax_Preview&quot;&gt;XXX&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XXX&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;-YYY&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-YYY&lt;/script&gt;, which is the &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; logical of the code (as we also saw at the beginning of the section). Therefore, we are indeed dealing with a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{S}&lt;/script&gt; gate.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;: Show that any operator made of &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\texttt{T}^\dagger&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\texttt{T}^\dagger&lt;/script&gt; on every physical qubit of the Steane code does &lt;strong&gt;not&lt;/strong&gt; implement a logical gate. &lt;a href=&quot;#solution-of-the-exercise&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Correction&lt;/strong&gt;: We can show that such operator doesn’t turn &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquettes into stabilizers. Indeed, applying it to an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette &lt;code class=&quot;MathJax_Preview&quot;&gt;P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; gives a combination of &lt;code class=&quot;MathJax_Preview&quot;&gt;SX&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;SX&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;S^\dagger X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S^\dagger X&lt;/script&gt; with some phase factors. Let’s call this new operator &lt;code class=&quot;MathJax_Preview&quot;&gt;U_P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U_P&lt;/script&gt;. For it to be a stabilizer, it needs to turn Pauli stabilizers into stabilizers. Let’s pick an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;P'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'&lt;/script&gt; adjacent to &lt;code class=&quot;MathJax_Preview&quot;&gt;P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt;. We can see that &lt;code class=&quot;MathJax_Preview&quot;&gt;U_P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U_P&lt;/script&gt; intersect with &lt;code class=&quot;MathJax_Preview&quot;&gt;P'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'&lt;/script&gt; on exactly two qubits, turning it into a combination of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;s (where it doesn’t intersect) and &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;-Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-Y&lt;/script&gt; where it intersects. This operator made of both &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; on a plaquette is clearly not a stabilizer, meaning that &lt;code class=&quot;MathJax_Preview&quot;&gt;U_P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U_P&lt;/script&gt; is not a stabilizer, meaning that the initial gate is not a logical gate.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;In practice, if &lt;code class=&quot;MathJax_Preview&quot;&gt;U^{\dagger}SU&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U^{\dagger}SU&lt;/script&gt; is not a Pauli, it is often more involved to show that it’s a stabilizer. The most general method, that you find in &lt;a href=&quot;https://arxiv.org/abs/1408.1720&quot;&gt;many&lt;/a&gt; &lt;a href=&quot;https://arxiv.org/abs/1801.04255&quot;&gt;papers&lt;/a&gt;, is to explicitly write the states of the codespace and show that it stabilizes them. However, my favorite method is to show that &lt;code class=&quot;MathJax_Preview&quot;&gt;U^{\dagger}SU&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U^{\dagger}SU&lt;/script&gt; is itself a logical gate, acting as the identity (i.e. mapping &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt;). To show that &lt;code class=&quot;MathJax_Preview&quot;&gt;U^{\dagger}SU&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;U^{\dagger}SU&lt;/script&gt; is a logical gate, you either show that it maps Pauli stabilizers to Pauli stabilizers (which is the case in all the situations I’ve encountered), or you recursively continue this process until the operator maps Pauli stabilizers to Pauli stabilizers. We will revise this and look at some explicit examples when talking about 3D codes in a future post, so don’t dwell on that if you find this method a bit abstract at the moment. All our examples of logical gate in this post will map Paulis to Paulis. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;We can find many definitions (as well as absence of definitions) of fault-tolerance in the literature. One of the most formal and general ones is due to Gottesman and can be found &lt;a href=&quot;https://arxiv.org/pdf/0904.2557.pdf&quot;&gt;here&lt;/a&gt; (Sec. 4.2). However, in practice, not reducing the distance to a constant seems to be a good effective definition that is implied in many papers. Alternatively, depending on the context, it could also be useful to impose no more than a constant multiplicative reduction of the distance, or even no reduction at all (for instance if we want to talk about the fault-tolerance of a gate on a specific small code instead of a whole family). But I hope you get the idea. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="quantum-computing" /><summary type="html">If you have been following the quantum news lately, you certainly didn’t miss one of the biggest announcements of the year: the demonstration of various quantum codes and logical operations on up to 48 logical qubits and 280 physical qubits of a Rydberg atom array. To me, one of the most exciting features of this experiment is its inherent non-locality: it is possible to apply gates between qubits that are far away by simply moving the corresponding atoms, without inducing more errors than we are able to correct. From a quantum error correction point-of-view, this allows two things: the possibility to create codes beyond two dimensions (such as 3D codes or more general LDPC codes), and the possibility to apply logical two-qubit gates without inducing any additional space-time cost: transversal gates can be used instead of the more common lattice surgery of traditional surface code architectures.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/transversal-gates/thumbnail.png?4362984378" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/transversal-gates/thumbnail.png?4362984378" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">An interactive introduction to the surface code</title><link href="https://arthurpesah.me/blog/2023-05-13-surface-code/" rel="alternate" type="text/html" title="An interactive introduction to the surface code" /><published>2023-05-13T00:00:00+02:00</published><updated>2023-05-13T00:00:00+02:00</updated><id>https://arthurpesah.me/blog/surface-code</id><content type="html" xml:base="https://arthurpesah.me/blog/2023-05-13-surface-code/">&lt;script&gt;
    // Repair modulo bug with negative numbers
    Number.prototype.mod = function (n) {
        &quot;use strict&quot;;
        return ((this % n) + n) % n;
    };

    // Turn GUI into png
    function drawImage(gui, id, download) {
        gui.animate();

        let dataURL = gui.renderer.domElement.toDataURL();
        let img = new Image();
        img.src = dataURL;

        // Draw the Image object onto a new canvas

        requestAnimationFrame(function() {
            let newCanvas = document.createElement('canvas');
            let oldCanvas = document.getElementById(id).children[0];

            newCanvas.width = oldCanvas.offsetWidth;
            newCanvas.height = oldCanvas.offsetHeight;

            let ctx = newCanvas.getContext('2d');
            ctx.drawImage(img, 0, 0, newCanvas.width, newCanvas.height);

            oldCanvas.remove();

            let parent = document.getElementById(id);
            parent.appendChild(newCanvas);

            if (download) {
                let savedDataURL = newCanvas.toDataURL();
                let link = document.createElement('a');
                link.download = id + '.png';
                link.href = savedDataURL;
                document.body.appendChild(link);
                link.click();
            }
        });
    }

    const keycode = {
        'decode': -1, 'random': -1, 'remove': -1, 'opacity': -1,
        'x-logical': -1, 'z-logical': -1, 'x-error': 0, 'z-error': -1
    };
&lt;/script&gt;

&lt;p&gt;Last July, the quantum team at Google released a &lt;a href=&quot;https://arxiv.org/abs/2207.06431&quot;&gt;milestone paper&lt;/a&gt;, in which they show the first experimental demonstration of quantum error correction below threshold. What this means is that their experiment reached noise levels that are low enough such that by increasing the size of their code, they progressively reduced the number of errors in the encoded qubit. And how did they achieve such a milestone? You guessed it, by using the surface code to protect their qubits! The reasons they chose this code are plentiful: it can be layed down on a 2D lattice, it has a very high threshold compared to other codes, it doesn’t require too many qubits in its smallest instances, etc. And Google is far from the only company considering the surface code (or some of its variants) as part of their their fault-tolerant architecture!&lt;/p&gt;

&lt;p&gt;Apart from its experimental relevance, the surface code is also one of the most beautiful ideas of quantum computing, and if you ask me, of all physics. Inspired by the condensed matter concepts of topological order and anyonic particle, it was discovered by Alexei Kitaev in 1997, in a &lt;a href=&quot;https://arxiv.org/abs/quant-ph/9707021&quot;&gt;paper&lt;/a&gt; in which he also introduces the idea of topological quantum computing. And indeed, the surface code has deep connections to many areas of maths and physics. For instance, in condensed matter theory, the surface code (more often called &lt;em&gt;toric code&lt;/em&gt; in this context&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;) is used as a prime example of topological phase of matter and is related to the more general family of spin liquids. While this post will be mainly concerned with the quantum error correction properties of the surface code, my friend Dominik Kufel wrote an excellent &lt;a href=&quot;https://dom-kufel.github.io/blog/2023-05-13-toric_code-intro/&quot;&gt;complementary post&lt;/a&gt; which describes the condensed matter perspective.&lt;/p&gt;

&lt;p&gt;Finally, the surface code is the simplest example to illustrate the more general concept of topological quantum error-correction. While we will only consider surface codes defined on a 2D square lattice here, they can actually be generalized to the cellulation of any manifold in any dimension (including hyperbolic!). Concepts from algebraic topology (such as homology and cohomology groups, chain complexes, etc.) can then be used to understand and analyze those codes. While we will take a brief glance at topology here, I am planning to write a separate blog post fully dedicated to the maths behind topological quantum error-correction. The goal of this post is to gain a first intuitive understanding of the surface code.&lt;/p&gt;

&lt;p&gt;You got it, I love the surface code, and I’m super excited to talk about it in this post!
To do this code the honor it deserves, I’ve decided to make use of the &lt;a href=&quot;https://gui.quantumcodes.io&quot;&gt;interactive code visualizer&lt;/a&gt; I have been developing for some time with my collaborator Eric Huang. I’ve embedded it in this post&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, and you will therefore be able to play with some of the lattices presented here (e.g. by inserting errors and stabilizers, visualizing decoding, etc.). I hope you’ll enjoy!&lt;/p&gt;

&lt;p&gt;So here is the plan for today’s post. We will first look at the definition of the surface code on a torus by laying out its stabilizers, see how to detect errors, and delve into topology in order to understand the logical operators of the code. We will then study the decoding problem and see how it can be simplified to a matching problem on a graph. Next, we will introduce the planar code and the rotated code, variants of the surface code with more practical boundary conditions and a lower overhead. Finally, we will define the notion of error correction threshold and give its different values for the surface code.&lt;/p&gt;

&lt;p&gt;This post assumes familiarity with the stabilizer formalism, so don’t hesitate to read &lt;a href=&quot;/blog/2023-01-31-stabilizer-formalism-1/&quot;&gt;my blog post series&lt;/a&gt; on the topic if you need a reminder.&lt;/p&gt;

&lt;h2 id=&quot;definition-of-the-surface-code&quot;&gt;Definition of the surface code&lt;/h2&gt;

&lt;p&gt;The surface code can be defined on a square grid of size &lt;code class=&quot;MathJax_Preview&quot;&gt;L \times L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \times L&lt;/script&gt;, where qubits sit on the edges, as shown here for &lt;code class=&quot;MathJax_Preview&quot;&gt;L=4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L=4&lt;/script&gt;:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-lattice&quot; style=&quot;margin: auto; display: block; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-lattice';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init();

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-lattice.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The code is easier to analyze at first when considering periodic boundary conditions. Therefore, in the picture above, we identify the left-most and right-most qubits, as well as the top-most and bottom-most qubits. The grid is therefore equivalent to a pac-man grid, or in topological terms, a &lt;strong&gt;torus&lt;/strong&gt;. A torus as you might imagine it can be obtained from the grid by wrapping it around top to bottom (gluing the top and bottom edges together), making a cylinder, then left to right (gluing the left and right edges together) to finish the torus:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/torus-grid.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The next step is then to describe the &lt;strong&gt;stabilizers&lt;/strong&gt; of the code. The surface code is indeed an example of stabilizer codes and can therefore be completely specified by its stabilizer group. In our case, we have two types of stabilizer generators: the &lt;strong&gt;vertex stabilizers&lt;/strong&gt;, defined on every vertex of the lattice as a cross of four &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators, and the &lt;strong&gt;plaquette stabilizers&lt;/strong&gt;, defined on every face as a square of four &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operators. Examples of vertex and plaquette stabilizers are shown below, where &lt;em&gt;red&lt;/em&gt; means &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;em&gt;blue&lt;/em&gt; mean &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;.&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-stabilizers&quot; style=&quot;margin: auto; display: block; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-stabilizers';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([1, 4], 'X');
    gui.code.insertError([0, 5], 'X');
    gui.code.insertError([1, 6], 'X');
    gui.code.insertError([2, 5], 'X');

    gui.code.insertError([3, 2], 'Z');
    gui.code.insertError([4, 3], 'Z');
    gui.code.insertError([4, 1], 'Z');
    gui.code.insertError([5, 2], 'Z');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-stabilizers.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;To define a valid code, &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers must commute. Since they are Pauli operators, it means that they must always intersect on an even number of qubits. You can check that this is the case here: vertex and plaquette operators always intersect on either zero or two qubits.&lt;/p&gt;

&lt;p&gt;Since the stabilizer group is a group, it means that the product of stabilizers is also a stabilizer. Therefore, any product of plaquettes is also a stabilizer. Here is an example of product of three plaquettes:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-x-loops&quot; style=&quot;margin: auto; display: block; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-x-loops'

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([0, 3], 'X');
    gui.code.insertError([0, 5], 'X');
    gui.code.insertError([1, 6], 'X');
    gui.code.insertError([2, 5], 'X');
    gui.code.insertError([3, 4], 'X');
    gui.code.insertError([4, 3], 'X');
    gui.code.insertError([3, 2], 'X');
    gui.code.insertError([1, 2], 'X');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-x-loops.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;You can notice that this forms a loop! The reason is that when multiplying the plaquette operators, there are always two &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operators applied on each qubit of the bulk, which cancel each other. This observation is true in general: all the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizers are loops in the lattice! To convince yourself of that fact, try inserting plaquette stabilizers in the following panel:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 10px; color: gray; font-size: 15px&quot;&gt;
    Click on faces to add plaquette stabilizers
&lt;/div&gt;

&lt;div id=&quot;surface-code-insert-plaquettes&quot; style=&quot;margin: auto; display: block; max-width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 20px; font-size: 15px&quot;&gt;
    &lt;button id=&quot;button-surface-code-plaquette-reset&quot;&gt;Remove all plaquettes&lt;/button&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'https://gui.quantumcodes.io/js/gui.js'

    let id = 'surface-code-insert-plaquettes'

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'https://gui.quantumcodes.io', id);

    let button = document.getElementById('button-surface-code-plaquette-reset');
    button.onclick = () =&gt; gui.removeAllErrors();

    gui.onDocumentMouseDown = function(event) {
        let canvasBound = gui.renderer.getContext().canvas.getBoundingClientRect();

        gui.mouse.x = ( (event.clientX  - canvasBound.left) / gui.width ) * 2 - 1;
        gui.mouse.y = - ( (event.clientY - canvasBound.top) / gui.height ) * 2 + 1;

        gui.raycaster.setFromCamera(gui.mouse, gui.camera);

        gui.intersects = gui.raycaster.intersectObjects(gui.code.stabilizers);
        if (this.intersects.length == 0) return;

        let selectedStabilizer = this.intersects[0].object;

        if (selectedStabilizer.type == 'face' &amp;&amp; event.button == 0) {
            let x = selectedStabilizer.location[0];
            let y = selectedStabilizer.location[1];
            let z = selectedStabilizer.location[2];

            gui.code.insertError([(x+1).mod(8), y], 'X');
            gui.code.insertError([(x-1).mod(8), y], 'X');
            gui.code.insertError([x, (y+1).mod(8)], 'X');
            gui.code.insertError([x, (y-1).mod(8)], 'X');
        }
    }

    await gui.init()
&lt;/script&gt;

&lt;p&gt;What about &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers? They also form loops… if we look at them the right way! Try to understand why by inserting vertex stabilizers in the following panel:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 10px; color: gray; font-size: 15px&quot;&gt;
    Click on vertices to add vertex stabilizers
&lt;/div&gt;

&lt;div id=&quot;surface-code-insert-vertex&quot; style=&quot;margin: auto; display: block; max-width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 20px; font-size: 15px&quot;&gt;
    &lt;button id=&quot;button-surface-code-vertex-reset&quot;&gt;Remove all vertex stabilizers&lt;/button&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'https://gui.quantumcodes.io/js/gui.js'

    let id = 'surface-code-insert-vertex'

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'https://gui.quantumcodes.io', id);

    let button = document.getElementById('button-surface-code-vertex-reset');
    button.onclick = () =&gt; gui.removeAllErrors();

    gui.onDocumentMouseDown = function(event) {
        let canvasBound = gui.renderer.getContext().canvas.getBoundingClientRect();

        gui.mouse.x = ( (event.clientX  - canvasBound.left) / gui.width ) * 2 - 1;
        gui.mouse.y = - ( (event.clientY - canvasBound.top) / gui.height ) * 2 + 1;

        gui.raycaster.setFromCamera(gui.mouse, gui.camera);

        gui.intersects = gui.raycaster.intersectObjects(gui.code.stabilizers);
        if (this.intersects.length == 0) return;

        let selectedStabilizer = this.intersects[0].object;

        if (selectedStabilizer.type == 'vertex' &amp;&amp; event.button == 0) {
            let x = selectedStabilizer.location[0];
            let y = selectedStabilizer.location[1];
            let z = selectedStabilizer.location[2];

            gui.code.insertError([(x+1).mod(8), y], 'Z');
            gui.code.insertError([(x-1).mod(8), y], 'Z');
            gui.code.insertError([x, (y+1).mod(8)], 'Z');
            gui.code.insertError([x, (y-1).mod(8)], 'Z');
        }
    }

    await gui.init()
&lt;/script&gt;

&lt;p&gt;For instance, here is the product of three vertex operators:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-z-loops&quot; style=&quot;margin: auto; display: block; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-z-loops'

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([4, 5], 'Z');
    gui.code.insertError([5, 4], 'Z');
    gui.code.insertError([5, 2], 'Z');
    gui.code.insertError([4, 1], 'Z');
    gui.code.insertError([2, 1], 'Z');
    gui.code.insertError([1, 2], 'Z');
    gui.code.insertError([2, 3], 'Z');
    gui.code.insertError([3, 4], 'Z');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-z-loops.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Can you see the loop? If no, this picture should make it clearer:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-z-loops-dual.png&quot; height=&quot;320&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The trick was to draw an edge orthogonal to every blue edge (dashed purple lines on the figure). Formally, this corresponds to representing the operator in the so-called &lt;strong&gt;dual lattice&lt;/strong&gt;, a lattice formed by rotating each edge by 90° (dashed grey lattice in the figure). In this lattice, vertex stabilizers have a square-like shape, similar to the plaquette stabilizers of the primal lattice. Therefore, all the properties we can derive for &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizers, errors and logicals can be directly translated to &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators by simply considering the dual lattice, where &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators behave exactly like &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operators.&lt;/p&gt;

&lt;p&gt;So we’ve seen that all the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers are loops in the lattice. But is the converse true, that is, do all the loops define stabilizers? Try to think about this question, we will come back to it later.&lt;/p&gt;

&lt;h2 id=&quot;detecting-errors&quot;&gt;Detecting errors&lt;/h2&gt;

&lt;p&gt;So what happens when errors start occurring on our code? Use the panel below to insert &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors in the code:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 10px; color: gray; font-size: 15px&quot;&gt;
    Click on edges to add
    &lt;select id=&quot;select-surface-code-error-type&quot;&gt;
        &lt;option value=&quot;x&quot;&gt;X errors&lt;/option&gt;
        &lt;option value=&quot;z&quot;&gt;Z errors&lt;/option&gt;
    &lt;/select&gt;
&lt;/div&gt;

&lt;div id=&quot;surface-code-insert-errors&quot; style=&quot;margin: auto; display: block; max-width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 20px; font-size: 15px&quot;&gt;
    &lt;button id=&quot;button-surface-code-random&quot;&gt;Insert random errors&lt;/button&gt;
    &lt;button id=&quot;button-surface-code-reset&quot;&gt;Remove all errors&lt;/button&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'https://gui.quantumcodes.io/js/gui.js'

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        errorModel: 'Pure X',
        rotated: false
    };

    let gui = new Interface(params, {}, keycode, 'https://gui.quantumcodes.io', 'surface-code-insert-errors');

    await gui.init()
    gui.addRandomErrors();

    let button1 = document.getElementById('button-surface-code-random');
    button1.onclick = () =&gt; gui.addRandomErrors();

    let button2 = document.getElementById('button-surface-code-reset');
    button2.onclick = () =&gt; gui.removeAllErrors();

    let selectErrorType = document.getElementById('select-surface-code-error-type');
    selectErrorType.onchange = function() {
        if (selectErrorType.value == 'x') {
            gui.keycode['x-error'] = 0;
            gui.keycode['z-error'] = -1;
            gui.params.errorModel = 'Pure X';
        }
        else {
            gui.keycode['x-error'] = -1;
            gui.keycode['z-error'] = 0;
            gui.params.errorModel = 'Pure Z';
        }
    }
&lt;/script&gt;

&lt;p&gt;Vertices lighted up in yellow are the ones which anticommute with the error and are equal to &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;. They are part of the &lt;strong&gt;syndrome&lt;/strong&gt; (set of measured stabilizer values) and are often called &lt;strong&gt;excitations&lt;/strong&gt; or &lt;strong&gt;defects&lt;/strong&gt;. Can you spot a pattern in the way excitations relates to errors? Let me help you. Start by removing all the errors. Then, draw a path of errors. Can you see what happens?&lt;/p&gt;

&lt;p&gt;Excitations only appear at the boundary of error paths! Here is an example of pattern that should make that clear:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-z-paths&quot; style=&quot;margin: auto; display: block; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-z-paths';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([2, 3], 'Z');
    gui.code.insertError([4, 3], 'Z');
    gui.code.insertError([5, 4], 'Z');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-x-paths.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;We can see that excitations are always created in pairs, and move through the lattice when increasing the size of the error string. What about &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors? The same phenomenon occurs if errors paths are created by adding errors on parallel edges:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-z-paths.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;As expected, when seen in the dual lattice (i.e. when rotating each edge by 90°), those &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; paths correspond to regular strings of errors.&lt;/p&gt;

&lt;p&gt;The fact that excitations live at the boundary of error paths also means that when a path forms a loop, the excitations disappear. In other words, loops always commute with all the stabilizers. And what is an operator that commutes with all the stabilizers? A &lt;a href=&quot;/blog/2023-03-16-stabilizer-formalism-2/&quot;&gt;logical operator&lt;/a&gt;!&lt;/p&gt;

&lt;h2 id=&quot;logical-operators-loops-and-topology&quot;&gt;Logical operators, loops and topology&lt;/h2&gt;

&lt;p&gt;A logical operator can either be trivial, in which case it is a stabilizer, or non-trivial, in which case it performs an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; logical operation on any of the &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; qubits encoded in the code. For the surface code, the distinction between all those different operators depends on the types of loop they form. And this where the connection with topology really begins. Let’s first study the structure of loops on a general smooth manifold, before applying it to the surface code.&lt;/p&gt;

&lt;h3 id=&quot;loops-on-a-smooth-manifold&quot;&gt;Loops on a smooth manifold&lt;/h3&gt;

&lt;p&gt;Let’s consider a smooth manifold &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{M}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{M}&lt;/script&gt; (e.g. a torus). We say that two loops on &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{M}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{M}&lt;/script&gt; are &lt;strong&gt;equivalent&lt;/strong&gt; if there exists a smooth deformation of one loop to the other, meaning that we can smoothly move the first loop to the other loop without cutting it&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;. For instance, the following four loops (green) on the torus are equivalent:&lt;/p&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/torus-trivial-loops.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Moreover, we say that a loop is &lt;strong&gt;contractible&lt;/strong&gt;, or &lt;strong&gt;trivial&lt;/strong&gt;, if it is equivalent to a point, that is, we can smoothly reduce it until it becomes a single point. All the loops in the figure above are examples of contractible loops on the torus. So what do non-contractible loops look like? Here are examples of non-contractible loops:&lt;/p&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/torus-non-trivial-loops.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;One loop (blue) goes around the middle hole, while two loops (red) goes around the hole formed by the inside of the donut. Note that those types of loop (red and blue) are not equivalent to each other, and cannot be deformed to obtain any of the green loops of the first figure neither.&lt;/p&gt;

&lt;p&gt;As always when we define a notion of equivalence, it can be interesting to look at all the different equivalence classes that they lead to. As a reminder, an &lt;strong&gt;equivalence class&lt;/strong&gt;, or &lt;strong&gt;coset&lt;/strong&gt;, is a set containing all the objects equivalent to a reference object. So let’s enumerate all the equivalence classes of loops on the torus. First, we have the contractible loops. They are all equivalent, since each of them can be reduced to a point, and two points can always be smoothly moved to each other. So that’s our first equivalent class, that we can call the &lt;strong&gt;trivial class&lt;/strong&gt;. Then, we have the red and blue loops of the figure above: one that goes around the middle hole and the other that goes around the hole formed by the inside of the donut. That’s two other equivalent classes. Note that a pair of loops is also technically a loop itself, so taking the red and blue loops together forms its own loop, which is not equivalent to either one of them separately. This “double loop” can also be understood as (and is equivalent to) a single loop that goes around both holes, like the orange line in the picture below:&lt;/p&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/torus-double-cycle.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;So that’s a fourth equivalence class. Do we have more?&lt;/p&gt;

&lt;p&gt;Yes! Loops going around a hole twice are not equivalent to loops going around the hole once. Therefore, for each &lt;code class=&quot;MathJax_Preview&quot;&gt;k \in \mathbb{N}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k \in \mathbb{N}&lt;/script&gt;, we have a new class of loops going around one of the holes &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; times. Since in general loops are given a direction, we can also consider loops going around each hole in the opposite direction and take &lt;code class=&quot;MathJax_Preview&quot;&gt;k \in \mathbb{Z}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k \in \mathbb{Z}&lt;/script&gt;. Overall, there are infinitely-many equivalence classes which can be labeled by two integers &lt;code class=&quot;MathJax_Preview&quot;&gt;(k_1,k_2) \in \mathbb{Z}^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(k_1,k_2) \in \mathbb{Z}^2&lt;/script&gt;, where each integer indicates how many times the loops go around the corresponding hole. In this notation, the trivial class corresponds to &lt;code class=&quot;MathJax_Preview&quot;&gt;(0,0)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(0,0)&lt;/script&gt;, the blue and red non-trivial loops correspond to &lt;code class=&quot;MathJax_Preview&quot;&gt;(0,1)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(0,1)&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;(1,0)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(1,0)&lt;/script&gt;, and the orange loop corresponds to &lt;code class=&quot;MathJax_Preview&quot;&gt;(1,1)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(1,1)&lt;/script&gt;.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;: What is the equivalence class of the following (purple) loop? &lt;a href=&quot;#solution-of-the-exercise&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/torus-exercise.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;h3 id=&quot;loops-on-the-surface-code&quot;&gt;Loops on the surface code&lt;/h3&gt;

&lt;p&gt;How can we apply what we have learned to the surface code? Compared to general smooth manifolds, the surface code has a more discrete structure, and the notion of &lt;em&gt;smoothly deforming a loop&lt;/em&gt; does not directly apply here. We need a slightly different notion of equivalence&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. We say that two loops &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell_1,\ell_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell_1,\ell_2&lt;/script&gt; on the surface code are equivalent if there exists a stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;S \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S \in \mathcal{S}&lt;/script&gt; such that &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell_1 = S \ell_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell_1 = S \ell_2&lt;/script&gt;. For instance, if we consider &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors and &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizers, two loops of errors are equivalent if we can apply a series of plaquettes to go from one to the other. As an exercise, show that the following two loops are equivalent, by finding some plaquettes that move one loop to the other:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-equivalent-loops-1&quot; style=&quot;display: block;float: left; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;
&lt;div id=&quot;surface-code-equivalent-loops-2&quot; style=&quot;display: block;float: right; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-equivalent-loops-1';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([2, 7], 'X');
    gui.code.insertError([2, 1], 'X');
    gui.code.insertError([3, 2], 'X');
    gui.code.insertError([4, 1], 'X');
    gui.code.insertError([4, 7], 'X');
    gui.code.insertError([3, 6], 'X');

    drawImage(gui, id, true);
&lt;/script&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-equivalent-loops-2'

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([1, 4], 'X');
    gui.code.insertError([0, 3], 'X');
    gui.code.insertError([0, 1], 'X');
    gui.code.insertError([1, 0], 'X');
    gui.code.insertError([3, 0], 'X');
    gui.code.insertError([4, 1], 'X');
    gui.code.insertError([3, 2], 'X');
    gui.code.insertError([2, 3], 'X');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-equivalent-loops-1.png&quot; style=&quot;display: block; float: left;&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-equivalent-loops-2.png&quot; style=&quot;display: block; float: right;&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;p&gt;Note that this notion of equivalence is exactly the same as the notion of logical equivalence defined in &lt;a href=&quot;/blog/2023-03-16-stabilizer-formalism-2/&quot;&gt;Part II of the stabilizer formalism series&lt;/a&gt;: applying a stabilizer to a logical gives another representation of the same logical. So operationally, two loops are equivalent if they correspond to the same logical operator. Therefore, by looking at all the equivalence classes of loops, we will be able to classify the different logical operators of the code.&lt;/p&gt;

&lt;p&gt;Now, we say that a loop is &lt;strong&gt;contractible&lt;/strong&gt;, or &lt;strong&gt;trivial&lt;/strong&gt;, if it is equivalent to the empty loop (no error). In other words, a loop is trivial if it is a stabilizer. In the case of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors, a trivial loop corresponds to the boundary of a set of faces (the plaquettes that form the stabilizer).&lt;/p&gt;

&lt;p&gt;We are now ready to answer our main question. What are the non-trivial loops of the surface code, or in other words, the non-trivial logical operators? For &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors, they look like this:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-x-logical-1&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-x-logical-1';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([2, 7], 'X');
    gui.code.insertError([2, 1], 'X');
    gui.code.insertError([2, 3], 'X');
    gui.code.insertError([2, 5], 'X');

    // drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;!-- &lt;div id=&quot;surface-code-x-logical-2&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-x-logical-2';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([7, 2], 'X');
    gui.code.insertError([1, 2], 'X');
    gui.code.insertError([5, 2], 'X');
    gui.code.insertError([3, 2], 'X');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-x-logical-1.png&quot; style=&quot;display: block; float: left&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-x-logical-2.png&quot; style=&quot;display: block; float: right&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;p&gt;And since applying plaquette stabilizers does not change the logical operator, the following strings give other valid representatives of the same logicals:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-x-logical-1-other&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-x-logical-1-other';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([4, 7], 'X');
    gui.code.insertError([4, 5], 'X');
    gui.code.insertError([3, 4], 'X');
    gui.code.insertError([1, 4], 'X');
    gui.code.insertError([0, 3], 'X');
    gui.code.insertError([1, 2], 'X');
    gui.code.insertError([2, 1], 'X');
    gui.code.insertError([3, 0], 'X');

    // drawImage(gui, id, true);
&lt;/script&gt;

&lt;div id=&quot;surface-code-x-logical-2-other&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-x-logical-2-other';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([7, 2], 'X');
    gui.code.insertError([1, 2], 'X');
    gui.code.insertError([2, 3], 'X');
    gui.code.insertError([3, 4], 'X');
    gui.code.insertError([4, 3], 'X');
    gui.code.insertError([4, 1], 'X');
    gui.code.insertError([5, 0], 'X');
    gui.code.insertError([6, 1], 'X');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-x-logical-1-other.png&quot; style=&quot;display: block; float: left&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-x-logical-2-other.png&quot; style=&quot;display: block; float: right&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;p&gt;As in the smooth case, what matters is that the non-trivial loops go around the torus. Indeed, you will not be able to write those operators as products of plaquette stabilizers. Operationally, each of those two loops (the “horizontal” and the “vertical” ones) correspond to applying a logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operator to the code, and since they are not equivalent, they are applying it to different logical qubits. Therefore, we have at least two logical qubits, one for the horizontal loop and one for the vertical loop. Do we have more?&lt;/p&gt;

&lt;p&gt;This time, we only have four different cosets of loops. Indeed, contrary to the smooth case, looping around the lattice twice always gives a trivial loop. This can be seen in two ways. The first way consists in observing that a loop going around the lattice twice is always equivalent to two disjoint loops (this was also true in the smooth case).&lt;/p&gt;

&lt;p&gt;The next step is then to show that such a two-loop pattern is always a stabilizer. For instance, try to find the plaquette stabilizers that give rise to the two loops on the right picture:&lt;/p&gt;

&lt;div style=&quot;float: left&quot;&gt;
    &lt;div style=&quot;text-align: center; margin-bottom: 10px; color: gray; font-size: 15px&quot;&gt;
        Click on faces to add plaquette stabilizers
    &lt;/div&gt;

    &lt;div id=&quot;surface-code-insert-plaquettes-two-loops&quot; style=&quot;margin: auto; display: block; max-width: 350px; height: 350px&quot;&gt;
    &lt;/div&gt;

    &lt;div style=&quot;text-align: center; margin-bottom: 20px; font-size: 15px&quot;&gt;
        &lt;button id=&quot;button-surface-code-plaquette-two-loops-reset&quot;&gt;Remove all plaquettes&lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;!-- Hidden text for positioning--&gt;
&lt;div style=&quot;float: right&quot;&gt;
    &lt;div style=&quot;text-align: center; margin-bottom: 10px; visibility: hidden; font-size: 15px&quot;&gt;
        Click on faces to add plaquette stabilizers
    &lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-two-loops.png&quot; style=&quot;float: right&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'https://gui.quantumcodes.io/js/gui.js'

    let id = 'surface-code-insert-plaquettes-two-loops'

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, keycode, 'https://gui.quantumcodes.io', id);

    let button = document.getElementById('button-surface-code-plaquette-two-loops-reset');
    button.onclick = () =&gt; gui.removeAllErrors();

    gui.onDocumentMouseDown = function(event) {
        let canvasBound = gui.renderer.getContext().canvas.getBoundingClientRect();

        gui.mouse.x = ( (event.clientX  - canvasBound.left) / gui.width ) * 2 - 1;
        gui.mouse.y = - ( (event.clientY - canvasBound.top) / gui.height ) * 2 + 1;

        gui.raycaster.setFromCamera(gui.mouse, gui.camera);

        gui.intersects = gui.raycaster.intersectObjects(gui.code.stabilizers);
        if (this.intersects.length == 0) return;

        let selectedStabilizer = this.intersects[0].object;

        if (selectedStabilizer.type == 'face' &amp;&amp; event.button == 0) {
            let x = selectedStabilizer.location[0];
            let y = selectedStabilizer.location[1];
            let z = selectedStabilizer.location[2];

            gui.code.insertError([(x+1).mod(8), y], 'X');
            gui.code.insertError([(x-1).mod(8), y], 'X');
            gui.code.insertError([x, (y+1).mod(8)], 'X');
            gui.code.insertError([x, (y-1).mod(8)], 'X');
        }
    }

    await gui.init()
&lt;/script&gt;

&lt;!-- &lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-two-loops';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([2, 7], 'X');
    gui.code.insertError([2, 1], 'X');
    gui.code.insertError([2, 3], 'X');
    gui.code.insertError([2, 5], 'X');
    gui.code.insertError([4, 7], 'X');
    gui.code.insertError([4, 1], 'X');
    gui.code.insertError([4, 3], 'X');
    gui.code.insertError([4, 5], 'X');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;!-- &lt;div id=&quot;surface-code-two-loops-solution&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-two-loops-solution';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([2, 7], 'X');
    gui.code.insertError([2, 1], 'X');
    gui.code.insertError([2, 3], 'X');
    gui.code.insertError([2, 5], 'X');
    gui.code.insertError([4, 7], 'X');
    gui.code.insertError([4, 1], 'X');
    gui.code.insertError([4, 3], 'X');
    gui.code.insertError([4, 5], 'X');

    gui.code.stabilizerMap[[3, 1]].material.color.setHex('0xf9690e');
    gui.code.stabilizerMap[[3, 1]].material.opacity = 1;
    gui.code.stabilizerMap[[3, 1]].visible = true;

    gui.code.stabilizerMap[[3, 3]].material.color.setHex('0xf9690e');
    gui.code.stabilizerMap[[3, 3]].material.opacity = 1;
    gui.code.stabilizerMap[[3, 3]].visible = true;

    gui.code.stabilizerMap[[3, 5]].material.color.setHex('0xf9690e');
    gui.code.stabilizerMap[[3, 5]].material.opacity = 1;
    gui.code.stabilizerMap[[3, 5]].visible = true;

    gui.code.stabilizerMap[[3, 7]].material.color.setHex('0xf9690e');
    gui.code.stabilizerMap[[3, 7]].material.opacity = 1;
    gui.code.stabilizerMap[[3, 7]].visible = true;

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p&gt;The second way to see this is to remember that a loop applies a logical operator &lt;code class=&quot;MathJax_Preview&quot;&gt;P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt;, and applying this logical operator twice gives &lt;code class=&quot;MathJax_Preview&quot;&gt;P^2=I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P^2=I&lt;/script&gt;. It means that any double loop lives in the identity coset, and is therefore a stabilizer.&lt;/p&gt;

&lt;p&gt;Thus, our equivalence classes for &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors can be labeled by two bits &lt;code class=&quot;MathJax_Preview&quot;&gt;(k_1,k_2) \in \mathbb{Z}_2 \times \mathbb{Z}_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(k_1,k_2) \in \mathbb{Z}_2 \times \mathbb{Z}_2&lt;/script&gt;. The corresponding logical operators are &lt;code class=&quot;MathJax_Preview&quot;&gt;I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;I&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;X_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_2&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1 X_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1 X_2&lt;/script&gt;. The fact that our sets are &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathbb{Z}_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbb{Z}_2&lt;/script&gt; instead of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathbb{Z}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbb{Z}&lt;/script&gt; can also be interpreted as a consequence of the fact that we have qubits. For qudits, the generalization of Pauli operators obey &lt;code class=&quot;MathJax_Preview&quot;&gt;P^d=I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P^d=I&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathbb{Z}_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbb{Z}_2&lt;/script&gt; is replaced by &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathbb{Z}_d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbb{Z}_d&lt;/script&gt;. For error-correcting codes on continuous-variable systems (roughly, qudits with &lt;code class=&quot;MathJax_Preview&quot;&gt;d=\infty&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=\infty&lt;/script&gt;), we recover &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathbb{Z}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathbb{Z}&lt;/script&gt; as our space of equivalence classes&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;

&lt;p&gt;Let’s summarize what we have learned. Loops of the surface code define logical operators. There are four non-equivalent types of loops: the trivial ones (stabilizers), the horizontal ones (&lt;code class=&quot;MathJax_Preview&quot;&gt;X_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1&lt;/script&gt; operator), the vertical ones (&lt;code class=&quot;MathJax_Preview&quot;&gt;X_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_2&lt;/script&gt; operator), and those two at the same time (&lt;code class=&quot;MathJax_Preview&quot;&gt;X_1 X_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1 X_2&lt;/script&gt; operator). Therefore, the surface code encodes &lt;code class=&quot;MathJax_Preview&quot;&gt;k=2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=2&lt;/script&gt; logical qubits.&lt;/p&gt;

&lt;p&gt;Note that in general, the surface code can be defined on any smooth manifold &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{M}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{M}&lt;/script&gt; by discretizing it. The number of logical qubits of the code is then directly connected to the topological properties of the manifold, and in particular, to the number of holes, or in more technical terms, the &lt;strong&gt;first Betti number&lt;/strong&gt; of the manifold. For instance, for the torus, the fact that &lt;code class=&quot;MathJax_Preview&quot;&gt;k=2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=2&lt;/script&gt; is a consequence of the presence of two holes.&lt;/p&gt;

&lt;p&gt;So far, we have mainly discussed loops of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors, but what about &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors? As expected, the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_2&lt;/script&gt; logicals correspond to loops going around the torus when considered in the dual lattice:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-z-logical-1&quot; style=&quot;margin: auto; display: block; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-z-logical-1';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([3, 0], 'Z');
    gui.code.insertError([3, 2], 'Z');
    gui.code.insertError([3, 4], 'Z');
    gui.code.insertError([3, 6], 'Z');

    // drawImage(gui, id, true);
&lt;/script&gt;

&lt;div id=&quot;surface-code-z-logical-2&quot; style=&quot;margin: auto; display: block; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-z-logical-2';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()

    gui.code.insertError([0, 3], 'Z');
    gui.code.insertError([2, 3], 'Z');
    gui.code.insertError([4, 3], 'Z');
    gui.code.insertError([6, 3], 'Z');

    // drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-z-logical-1.png&quot; style=&quot;display: block; float: left&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-z-logical-2.png&quot; style=&quot;display: block; float: right&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;p&gt;On the left is the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1&lt;/script&gt; logical (which anticommute with &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1&lt;/script&gt;) and on the right is the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_2&lt;/script&gt; logical (which anticommute with &lt;code class=&quot;MathJax_Preview&quot;&gt;X_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_2&lt;/script&gt;). Those anticommutation relation between &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1&lt;/script&gt; can be seen in this picture:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-anticommutation&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-anticommutation';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([2, 7], 'X');
    gui.code.insertError([2, 1], 'X');
    gui.code.insertError([2, 3], 'X');
    gui.code.insertError([2, 5], 'X');

    gui.code.insertError([0, 3], 'Z');
    gui.code.insertError([2, 3], 'Z');
    gui.code.insertError([4, 3], 'Z');
    gui.code.insertError([6, 3], 'Z');

    // drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-anticommutation.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Indeed, we can see that the &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1&lt;/script&gt; logicals intersect on exactly one qubit (green), meaning that they anticommute. This property is independent on the specific logical representatives you choose: a “horizontal” &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; loop will always intersect with a “vertical” &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; loop on a single qubit.&lt;/p&gt;

&lt;p&gt;You now have all you need to determine the parameters of the surface code!&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;: What are the &lt;code class=&quot;MathJax_Preview&quot;&gt;[[n,k,d]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[n,k,d]]&lt;/script&gt; parameters of a surface code with lattice size &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;? &lt;a href=&quot;#solution-of-the-exercise&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;decoding-the-surface-code&quot;&gt;Decoding the surface code&lt;/h2&gt;

&lt;p&gt;Let’s imagine that you observe the following syndrome, and want to find a good correction operator.&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-syndrome&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-syndrome';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.toggleStabilizer(gui.code.stabilizerMap[[4, 4]], true);
    gui.code.toggleStabilizer(gui.code.stabilizerMap[[2, 2]], true);

    drawImage(gui, id, false);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-syndrome.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;We know that excitations always appear in pairs, and correspond to the boundary of strings of errors.
So the error must be a string that links those two excitations. However, the number of strings that could have given this syndrome is very large! Here are three examples of errors leading to the syndrome shown above:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-decoding-1&quot; style=&quot;display: block; float: left; width: 250px; height: 250px&quot;&gt;
&lt;/div&gt;
&lt;div id=&quot;surface-code-decoding-3&quot; style=&quot;display: block; float: right; width: 250px; height: 250px&quot;&gt;
&lt;/div&gt;
&lt;div id=&quot;surface-code-decoding-2&quot; style=&quot;display: block; float: right; width: 250px; height: 250px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js';

    let id = 'surface-code-decoding-1';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([3, 4], 'X');
    gui.code.insertError([2, 3], 'X');

    // drawImage(gui, id, true);
&lt;/script&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js';

    let id = 'surface-code-decoding-2';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([4, 3], 'X');
    gui.code.insertError([3, 2], 'X');

    drawImage(gui, id, true);
&lt;/script&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js';

    let id = 'surface-code-decoding-3';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([5, 4], 'X');
    gui.code.insertError([6, 3], 'X');
    gui.code.insertError([7, 2], 'X');
    gui.code.insertError([0, 1], 'X');
    gui.code.insertError([1, 0], 'X');
    gui.code.insertError([2, 1], 'X');

    // drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-decoding-1.png&quot; style=&quot;display: block; float: left&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-decoding-3.png&quot; style=&quot;display: block; float: right&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/surface-code/surface-code-decoding-2.png&quot; style=&quot;display: block; float: right&quot; /&gt;&lt;/p&gt;

&lt;div style=&quot;clear: both&quot;&gt;&lt;/div&gt;

&lt;p&gt;Let’s suppose that the first pattern was our actual error, but we chose the middle pattern instead as our correction operator. This is what the final pattern, corresponding to the error (red) plus the correction operator (yellow), would look like:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-correction-1&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-correction-1';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([3, 4], 'X');
    gui.code.insertError([2, 3], 'X');
    gui.code.insertError([4, 3], 'X');
    gui.code.insertError([3, 2], 'X');

    gui.code.qubitMap[[4, 3]].material.color.setHex('0xffdf00');
    gui.code.qubitMap[[3, 2]].material.color.setHex('0xffdf00');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-correction-1.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;And as you can see, this is a stabilizer! So applying this correction operator puts us back in the original state and the correction is a success. On the other hand, here is what would happen if we had applied the last correction operator instead:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-correction-2&quot; style=&quot;display: block; margin: auto; width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-correction-2'

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([3, 4], 'X');
    gui.code.insertError([2, 3], 'X');

    gui.code.insertError([5, 4], 'X');
    gui.code.insertError([6, 3], 'X');
    gui.code.insertError([7, 2], 'X');
    gui.code.insertError([0, 1], 'X');
    gui.code.insertError([1, 0], 'X');
    gui.code.insertError([2, 1], 'X');

    gui.code.qubitMap[[5, 4]].material.color.setHex('0xffdf00');
    gui.code.qubitMap[[6, 3]].material.color.setHex('0xffdf00');
    gui.code.qubitMap[[7, 2]].material.color.setHex('0xffdf00');
    gui.code.qubitMap[[0, 1]].material.color.setHex('0xffdf00');
    gui.code.qubitMap[[1, 0]].material.color.setHex('0xffdf00');
    gui.code.qubitMap[[2, 1]].material.color.setHex('0xffdf00');

    drawImage(gui, id, false);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-correction-2.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;As you can see, this is a logical operator! So this is an example of correction failure, where we have changed the logical state of our code when applying the correction.&lt;/p&gt;

&lt;p&gt;What lessons can we draw from this example? The goal of the surface code decoding problem is to match the excitations such that the final operator is a stabilizer. Let’s try to formalize this a little bit. I described the general decoding problem for stabilizer codes in a &lt;a href=&quot;/blog/2023-03-28-stabilizer-formalism-3/&quot;&gt;previous post&lt;/a&gt;, but a short reminder is probably warranted.&lt;/p&gt;

&lt;p&gt;Similarly to how logical operators can be partitioned into cosets, we can also enumerate equivalent classes for errors fitting a given syndrome. For instance, the first and middle patterns in our example above are part of the same equivalent class, as they can be related by a plaquette stabilizer. On the other hand, the last string belongs to a different class. The goal of decoding is to find a correction operator that belongs to the same coset as the actual error. Indeed, the product &lt;code class=&quot;MathJax_Preview&quot;&gt;CE&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;CE&lt;/script&gt; of the correction operator with the error is equal to a stabilizer if and only if there is a stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; such that &lt;code class=&quot;MathJax_Preview&quot;&gt;C=ES&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C=ES&lt;/script&gt;, that is, if &lt;code class=&quot;MathJax_Preview&quot;&gt;C&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;E&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt; belong to the same class. To solve this problem with the information we have, that is, only the syndrome and the error probabilities, the optimal decoding problem, also called &lt;strong&gt;maximum-likelihood decoding&lt;/strong&gt;, can be formulated as finding the coset &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{\bar{C}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{\bar{C}}&lt;/script&gt; with the highest probability:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \max_{\bm{\bar{C}}} P(\bm{\bar{C}})
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \max_{\bm{\bar{C}}} P(\bm{\bar{C}})
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{\bar{C}})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{\bar{C}})&lt;/script&gt; can be calculated as a sum over all the operators in the coset: &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{\bar{C}}) = \sum_{\bm{C} \in \bm{\bar{C}}} P(\bm{C})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{\bar{C}}) = \sum_{\bm{C} \in \bm{\bar{C}}} P(\bm{C})&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Solving this problem exactly is computationally very hard, as it requires calculating a sum over an exponential number of terms (in the size of the lattice). But for the surface code, it can be approximated very well using &lt;a href=&quot;https://arxiv.org/abs/2101.04125&quot;&gt;tensor network decoders&lt;/a&gt;, which have a complexity of &lt;code class=&quot;MathJax_Preview&quot;&gt;O(n \chi^3)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n \chi^3)&lt;/script&gt; (up to some logarithmic factor), with &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; the number of qubits and &lt;code class=&quot;MathJax_Preview&quot;&gt;\chi&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\chi&lt;/script&gt; a parameter quantifying the degree of approximation of the decoder (corresponding to the bound dimension of the tensor network). The main downside of this decoder is that it generalizes poorly to the case of imperfect syndrome measurements. In this case, measurements need to be repeated in time, leading to a 3D decoding problem that tensor networks cannot solve efficiently at the moment.&lt;/p&gt;

&lt;p&gt;As discussed in my &lt;a href=&quot;/blog/2023-03-28-stabilizer-formalism-3/&quot;&gt;stabilizer decoding post&lt;/a&gt;, the maximum-likelihood decoding problem can also be approximated by solving for the error with the highest probability, instead of the whole coset. Assuming i.i.d. noise, finding the error with the highest probability is equivalent to finding the smallest error that fits the syndrome. In the case of the surface code, this corresponds to matching the excitations with chains of minimum weight.&lt;/p&gt;

&lt;p&gt;As it happens, this is completely equivalent to solving a famous graph problem, known as &lt;a href=&quot;https://en.wikipedia.org/wiki/Maximum_weight_matching&quot;&gt;&lt;strong&gt;minimum-weight perfect matching&lt;/strong&gt;&lt;/a&gt;! This problem can be expressed as matching all the vertices of a weighted graph (with an even number of vertices), such that the total weight is minimized. In our case, the graph is constructed as a complete graph with a vertex for each excitation. The weight of each edge between two vertices is then given by the Manhattan distance between the two corresponding excitations. For instance, let’s consider the following decoding problem:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-matching&quot; style=&quot;display: block; margin: auto; width: 400px; height: 400px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-matching';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 5,
        Ly: 5,
        Lz: 5,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.toggleStabilizer(gui.code.stabilizerMap[[2, 0]], true);
    gui.code.toggleStabilizer(gui.code.stabilizerMap[[2, 4]], true);
    gui.code.toggleStabilizer(gui.code.stabilizerMap[[6, 4]], true);
    gui.code.toggleStabilizer(gui.code.stabilizerMap[[8, 8]], true);

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-matching.png&quot; height=&quot;350&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The associated graph is then the following:&lt;/p&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/matching-graph.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;By enumerating all the possible matchings, you can quickly see that the one of minimum weight links vertices 1 and 2, and 3 and 4, with a total weight of 5:&lt;/p&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/matching-graph-solution.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;From there, we can deduce our decoding solution:&lt;/p&gt;

&lt;!-- &lt;div id=&quot;surface-code-decoding-solution&quot; style=&quot;display: block; margin: auto; width: 400px; height: 400px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    let id = 'surface-code-decoding-solution';

    const params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 5,
        Ly: 5,
        Lz: 5,
        rotated: false
    };

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([2, 1], 'X');
    gui.code.insertError([2, 3], 'X');
    gui.code.insertError([7, 4], 'X');
    gui.code.insertError([8, 5], 'X');
    gui.code.insertError([8, 7], 'X');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-decoding-solution.png&quot; height=&quot;350&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;It happens that minimum-weight perfect-matching can be solved in polynomial time using the &lt;a href=&quot;https://en.wikipedia.org/wiki/Blossom_algorithm&quot;&gt;Blossom algorithm&lt;/a&gt;, which has a worst-case complexity of &lt;code class=&quot;MathJax_Preview&quot;&gt;O(n^3)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n^3)&lt;/script&gt;. While this complexity might seem quite high, a &lt;a href=&quot;https://arxiv.org/abs/2303.15933&quot;&gt;recent modification&lt;/a&gt; of the Blossom algorithm, proposed by Oscar Higgott and Craig Gidney, seems to have an average complexity of &lt;code class=&quot;MathJax_Preview&quot;&gt;O(n)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;O(n)&lt;/script&gt;. It also generalizes very well to the imperfect syndrome case, making it one of the best decoders out there in terms of trade-off between speed and performance (the performance will be reviewed when talking about thresholds in the last section of the post).&lt;/p&gt;

&lt;p&gt;You can play with the matching decoder in the following visualization&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 10px; color: gray; font-size: 15px&quot;&gt;
    Click on edges to add
    &lt;select id=&quot;select-surface-code-decoding-error-type&quot;&gt;
        &lt;option value=&quot;x&quot;&gt;X errors&lt;/option&gt;
        &lt;option value=&quot;z&quot;&gt;Z errors&lt;/option&gt;
    &lt;/select&gt;
&lt;/div&gt;

&lt;div id=&quot;surface-code-decoding-insert-errors&quot; style=&quot;margin: auto; display: block; max-width: 350px; height: 350px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 20px; font-size: 15px&quot;&gt;
    &lt;button id=&quot;button-surface-code-decoding-decode&quot;&gt;Decode&lt;/button&gt;
    &lt;button id=&quot;button-surface-code-decoding-reset&quot;&gt;Remove all errors&lt;/button&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'https://gui.quantumcodes.io/js/gui.js'

    let params = {
        dimension: 2,
        codeName: 'Toric 2D',
        Lx: 4,
        Ly: 4,
        Lz: 4,
        decoder: 'Matching',
        rotated: false
    };

    let gui = new Interface(params, {}, keycode, 'https://gui.quantumcodes.io', 'surface-code-decoding-insert-errors');

    await gui.init();

    let button1 = document.getElementById('button-surface-code-decoding-decode');
    button1.onclick = () =&gt; gui.decode();

    let button2 = document.getElementById('button-surface-code-decoding-reset');
    button2.onclick = () =&gt; gui.removeAllErrors();

    let selectErrorType = document.getElementById('select-surface-code-decoding-error-type');
    selectErrorType.onchange = function() {
        if (selectErrorType.value == 'x') {
            gui.keycode['x-error'] = 0;
            gui.keycode['z-error'] = -1;
            gui.params.errorModel = 'Pure X';
        }
        else {
            gui.keycode['x-error'] = -1;
            gui.keycode['z-error'] = 0;
            gui.params.errorModel = 'Pure Z';
        }
    }
&lt;/script&gt;

&lt;p&gt;There are many other surface code decoders out there with their own pros and cons, such as &lt;a href=&quot;https://arxiv.org/abs/1709.06218&quot;&gt;union-find&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1811.12456&quot;&gt;neural network-based decoders&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/2005.07016&quot;&gt;belief propagation&lt;/a&gt;, etc. Describing them all in detail is out of scope for this blog post, but I hope to write a separate post one day dedicated to decoding. I also haven’t talked much about the decoding problem for imperfect syndrome, which I also leave for a separate blog post.&lt;/p&gt;

&lt;p&gt;Let’s now answer a question that you might have been wondering this whole time: how the hell do we implement a toric lattice in practice? While it’s in principle possible to implement an actual torus experimentally (for example with &lt;a href=&quot;https://www.nature.com/articles/s41586-018-0450-2/figures/2&quot;&gt;cold atoms&lt;/a&gt;), it is impractical for many quantum computing architecture. Fortunately, there exists a purely planar version of the surface code, that we will discuss now!&lt;/p&gt;

&lt;h2 id=&quot;surface-code-with-open-boundaries&quot;&gt;Surface code with open boundaries&lt;/h2&gt;

&lt;p&gt;Consider the following version of the surface code, where vertex stabilizers on the top and bottom boundaries, and plaquette stabilizers on the left and right boundaries, are now supported on three qubits instead of four:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 0px; color: gray; font-size: 15px&quot;&gt;
    Click on edges to add
    &lt;select id=&quot;select-planar-code-error-type&quot;&gt;
        &lt;option value=&quot;x&quot;&gt;X errors&lt;/option&gt;
        &lt;option value=&quot;z&quot;&gt;Z errors&lt;/option&gt;
    &lt;/select&gt;
&lt;/div&gt;

&lt;div id=&quot;planar-code-lattice&quot; style=&quot;margin: auto; display: block; max-width: 450px; height: 450px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 20px; font-size: 15px&quot;&gt;
    &lt;button id=&quot;button-planar-code-random&quot;&gt;Insert random errors&lt;/button&gt;
    &lt;button id=&quot;button-planar-code-reset&quot;&gt;Remove all errors&lt;/button&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'https://gui.quantumcodes.io/js/gui.js'

    let id = 'planar-code-lattice';

    const params = {
        dimension: 2,
        codeName: 'Planar 2D',
        Lx: 5,
        Ly: 5,
        Lz: 5,
        rotated: false
    };

    let gui = new Interface(params, {}, keycode, 'https://gui.quantumcodes.io', 'planar-code-lattice');

    let button1 = document.getElementById('button-planar-code-random');
    button1.onclick = () =&gt; gui.addRandomErrors();

    let button2 = document.getElementById('button-planar-code-reset');
    button2.onclick = () =&gt; gui.removeAllErrors();

    let selectErrorType = document.getElementById('select-planar-code-error-type');
    selectErrorType.onchange = function() {
        if (selectErrorType.value == 'x') {
            gui.keycode['x-error'] = 0;
            gui.keycode['z-error'] = -1;
            gui.params.errorModel = 'Pure X';
        }
        else {
            gui.keycode['x-error'] = -1;
            gui.keycode['z-error'] = 0;
            gui.params.errorModel = 'Pure Z';
        }
    }

    await gui.init()
&lt;/script&gt;

&lt;p&gt;We call the top and bottom boundaries &lt;strong&gt;smooth boundaries&lt;/strong&gt;, and the left and right boundaries &lt;strong&gt;rough boundaries&lt;/strong&gt;. Feel free to play with this lattice and try to figure out what the main differences are, compared to the toric code. In particular, can you identify the logical operators of this code? How many equivalent classes, or logical qubits, can you spot?&lt;/p&gt;

&lt;p&gt;The first difference to notice is that excitations can now be created at the boundary!&lt;/p&gt;

&lt;!-- &lt;div id=&quot;planar-code-boundary-errors&quot; style=&quot;margin: auto; display: block; width: 450px; height: 450px&quot;&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'http://127.0.0.1:5001/js/gui.js'

    const params = {
        dimension: 2,
        codeName: 'Planar 2D',
        Lx: 5,
        Ly: 5,
        Lz: 5,
        rotated: false
    };

    let id = 'planar-code-boundary-errors';

    let gui = new Interface(params, {}, {}, 'http://127.0.0.1:5001', id);

    await gui.init()
    gui.code.insertError([1, 2], 'X');
    gui.code.insertError([3, 2], 'X');
    gui.code.insertError([7, 8], 'Z');
    gui.code.insertError([7, 6], 'Z');

    drawImage(gui, id, true);
&lt;/script&gt; --&gt;

&lt;p style=&quot;text-align:center;&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/planar-code-boundary-errors.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;In this example, a vertex excitation is created on the rough boundary, and a plaquette excitation is created on the smooth boundary. You can see that excitations don’t have to come in pairs anymore! This poses a slight issue when decoding using minimum-weight perfect matching, but this can easily be overcome by adding some new boundary nodes to the matching graph.&lt;/p&gt;

&lt;p&gt;More importantly, we can observe that vertex excitations can only be created or annihilated at the rough boundaries, and plaquette excitations only at the smooth boundaries. This means that &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; logicals have to join the rough boundaries, and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; logicals have to join the smooth boundaries. This is illustrated in the following figure, where we can see that there is no “vertical” &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; logical or “horizontal” &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; logical.&lt;/p&gt;

&lt;p&gt;Therefore, there are only two equivalence classes of logicals for each error type: the strings that join opposite boundaries, and the trivial loops. As a consequence, this non-periodic version of the surface code, also called &lt;strong&gt;planar code&lt;/strong&gt;, only encodes a single qubit. It is a &lt;code class=&quot;MathJax_Preview&quot;&gt;[[2L^2 - 2L + 1, 1, L]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[2L^2 - 2L + 1, 1, L]]&lt;/script&gt;-code. While we have lost one qubit compared to the toric version, the fact that it can be laid out on a 2D surface makes it much more practical.&lt;/p&gt;

&lt;h2 id=&quot;a-more-compact-version-the-rotated-surface-code&quot;&gt;A more compact version: the rotated surface code&lt;/h2&gt;

&lt;p&gt;If you have started looking at the surface code literature, you might have noticed that people often use a different representation, which looks roughly like the following:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 0px; color: gray; font-size: 15px&quot;&gt;
    Click on vertices to add
    &lt;select id=&quot;select-rectified-code-error-type&quot;&gt;
        &lt;option value=&quot;x&quot;&gt;X errors&lt;/option&gt;
        &lt;option value=&quot;z&quot;&gt;Z errors&lt;/option&gt;
    &lt;/select&gt;
&lt;/div&gt;

&lt;div id=&quot;surface-code-rectified-picture&quot; style=&quot;margin: auto; display: block; max-width: 450px; height: 450px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 20px; font-size: 15px&quot;&gt;
    &lt;button id=&quot;button-rectified-code-random&quot;&gt;Insert random errors&lt;/button&gt;
    &lt;button id=&quot;button-rectified-code-reset&quot;&gt;Remove all errors&lt;/button&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'https://gui.quantumcodes.io/js/gui.js'

    let id = 'surface-code-rectified-picture';

    const params = {
        dimension: 2,
        codeName: 'Planar 2D',
        Lx: 5,
        Ly: 5,
        Lz: 5,
        rotated: true
    };

    let gui = new Interface(params, {}, keycode, 'https://gui.quantumcodes.io', id);

    let button1 = document.getElementById('button-rectified-code-random');
    button1.onclick = () =&gt; gui.addRandomErrors();

    let button2 = document.getElementById('button-rectified-code-reset');
    button2.onclick = () =&gt; gui.removeAllErrors();

    let selectErrorType = document.getElementById('select-rectified-code-error-type');
    selectErrorType.onchange = function() {
        if (selectErrorType.value == 'x') {
            gui.keycode['x-error'] = 0;
            gui.keycode['z-error'] = -1;
            gui.params.errorModel = 'Pure X';
        }
        else {
            gui.keycode['x-error'] = -1;
            gui.keycode['z-error'] = 0;
            gui.params.errorModel = 'Pure Z';
        }
    }

    await gui.init()
&lt;/script&gt;

&lt;p&gt;In this representation, qubits are on the vertices, and all the stabilizers are on the plaquette. Feel free to play with this lattice to understand what’s going on.&lt;/p&gt;

&lt;p&gt;It happens that this lattice represents exactly the planar code that we saw before! Here are the two lattices on top of each other:&lt;/p&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-both-pictures.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The idea is to turn every edge of the original representation into a vertex, each vertex into yellow face, and each face into a rose face. As a result, both vertices and plaquettes become rotated squares, and qubits become vertices. This representation is called the &lt;a href=&quot;https://en.wikipedia.org/wiki/Rectification_(geometry)&quot;&gt;&lt;strong&gt;rectified lattice&lt;/strong&gt;&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;One advantage of this representation is that it allows to come up with a different, more compact, version of the surface code. The idea is to take to following central piece of the rectified lattice:&lt;/p&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/surface-code-rotated-construction.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;We then rotate it and add a few boundary stabilizers. This gives the following code, called the &lt;strong&gt;rotated surface code&lt;/strong&gt;:&lt;/p&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 0px; color: gray; font-size: 15px&quot;&gt;
    Click on vertices to add
    &lt;select id=&quot;select-rotated-code-error-type&quot;&gt;
        &lt;option value=&quot;x&quot;&gt;X errors&lt;/option&gt;
        &lt;option value=&quot;z&quot;&gt;Z errors&lt;/option&gt;
    &lt;/select&gt;
&lt;/div&gt;

&lt;div id=&quot;rotated-surface-code&quot; style=&quot;margin: auto; display: block; max-width: 450px; height: 450px&quot;&gt;
&lt;/div&gt;

&lt;div style=&quot;text-align: center; margin-bottom: 20px; font-size: 15px&quot;&gt;
    &lt;button id=&quot;button-rotated-code-random&quot;&gt;Insert random errors&lt;/button&gt;
    &lt;button id=&quot;button-rotated-code-reset&quot;&gt;Remove all errors&lt;/button&gt;
&lt;/div&gt;

&lt;script type=&quot;module&quot;&gt;
    import { Interface } from 'https://gui.quantumcodes.io/js/gui.js'

    const params = {
        dimension: 2,
        codeName: 'Rotated Planar 2D',
        Lx: 5,
        Ly: 5,
        Lz: 5,
        rotated: true
    };

    let gui = new Interface(params, {}, keycode, 'https://gui.quantumcodes.io', 'rotated-surface-code');

    let button1 = document.getElementById('button-rotated-code-random');
    button1.onclick = () =&gt; gui.addRandomErrors();

    let button2 = document.getElementById('button-rotated-code-reset');
    button2.onclick = () =&gt; gui.removeAllErrors();

    let selectErrorType = document.getElementById('select-rotated-code-error-type');
    selectErrorType.onchange = function() {
        if (selectErrorType.value == 'x') {
            gui.keycode['x-error'] = 0;
            gui.keycode['z-error'] = -1;
            gui.params.errorModel = 'Pure X';
        }
        else {
            gui.keycode['x-error'] = -1;
            gui.keycode['z-error'] = 0;
            gui.params.errorModel = 'Pure Z';
        }
    }

    gui.init()
&lt;/script&gt;

&lt;p&gt;As always, feel free to familiarize yourself with this new code by playing with it on the visualization. You should be able to see that it also encodes a single logical qubit, and has a distance of &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;. However, this time, the number of physical qubits is exactly &lt;code class=&quot;MathJax_Preview&quot;&gt;L^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^2&lt;/script&gt;. The rotated surface code is therefore a &lt;code class=&quot;MathJax_Preview&quot;&gt;[[L^2, 1, L]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[L^2, 1, L]]&lt;/script&gt;-code, which is a factor two improvement in the overhead compared to the original surface code. This version of the surface code is therefore the preferred one to realize experimentally. For instance, its two smallest instances, the &lt;code class=&quot;MathJax_Preview&quot;&gt;[[9,1,3]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[9,1,3]]&lt;/script&gt; code and the &lt;code class=&quot;MathJax_Preview&quot;&gt;[[16,1,4]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[16,1,4]]&lt;/script&gt; code are the ones recently realized by the Google lab.&lt;/p&gt;

&lt;p&gt;When considering a code family such as the surface code, the &lt;code class=&quot;MathJax_Preview&quot;&gt;[[n,k,d]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[n,k,d]]&lt;/script&gt; parameters only give part of the story. Another very important characteristics of a code family is its set of thresholds.&lt;/p&gt;

&lt;h2 id=&quot;thresholds-of-the-surface-code&quot;&gt;Thresholds of the surface code&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;threshold&lt;/strong&gt; of a code family for a given noise model and decoder is the maximal physical error rate &lt;code class=&quot;MathJax_Preview&quot;&gt;p_{th}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;p_{th}&lt;/script&gt; such that for all &lt;code class=&quot;MathJax_Preview&quot;&gt;p &amp;lt; p_{th}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
p &lt; p_{th} %]]&gt;&lt;/script&gt;, increasing the code size decreases the logical error rate. The threshold is typically calculated numerically using plots that look like the following:&lt;/p&gt;

&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/threshold-example.png&quot; height=&quot;400&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;To make this figure, codes with distance &lt;code class=&quot;MathJax_Preview&quot;&gt;10,20,30&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;10,20,30&lt;/script&gt; are simulated under noise channel with varying physical error rate. Errors are then decoded, and logical errors are enumerated. We can see that above &lt;code class=&quot;MathJax_Preview&quot;&gt;p_{th} \approx 15.5\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;p_{th} \approx 15.5\%&lt;/script&gt;, increasing the code distance increases the logical error rate, while below &lt;code class=&quot;MathJax_Preview&quot;&gt;p_{th}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;p_{th}&lt;/script&gt;, the logical error rate decreases with the code distance.&lt;/p&gt;

&lt;p&gt;So what is the threshold of the surface code? First of all, very importantly, there isn’t a single threshold for the surface code: it highly depends on which noise channel and which decoder we are using. Let’s start by discussing noise models.&lt;/p&gt;

&lt;p&gt;We often make the distinction between three types of noise models:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;code-capacity&lt;/strong&gt; model, in which errors can occur on all the physical qubits of the code, but measurements are assumed to be perfect.&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;phenomenological&lt;/strong&gt; noise model, in which each stabilizer measurement can also fail with a fixed probability.&lt;/li&gt;
  &lt;li&gt;The &lt;strong&gt;circuit-level&lt;/strong&gt; noise model, in which the circuits to prepare the code and extract the syndrome are considered, and errors are assumed to occur with a certain probability after each physical gate.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The code-capacity threshold is the easiest to estimate, both in terms of implementation time and computational time, and allows to get a rough idea of the performance of a given code or decoder. The phenomenological threshold gets us closer to the true threshold value and can be useful when comparing decoders that deal with measurement errors in interesting ways (such as single-shot decoders). Finally, circuit-level thresholds are the most realistic ones and approximate the most accurately the actual noise level that experimentalists need to reach to make error correction work with a given code. While circuit-level thresholds have been considered very hard to estimate for a long time, mainly due to the lack of very fast noisy Clifford circuit simulators, recent tools such as &lt;a href=&quot;https://github.com/quantumlib/Stim&quot;&gt;Stim&lt;/a&gt; have made those simulations much less cumbersome.&lt;/p&gt;

&lt;p&gt;For each of those three models, we also need to specify the distribution of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;. There are two very common choices here. The first is the depolarizing noise model, in which those three Paulis are assumed to occur with the same probability. Since &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; is made of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;, it means that &lt;code class=&quot;MathJax_Preview&quot;&gt;P(Y)=P(X,Z) \neq P(X)P(Z)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(Y)=P(X,Z) \neq P(X)P(Z)&lt;/script&gt;, or in other words, &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; are correlated. Another noise model is the independent &lt;code class=&quot;MathJax_Preview&quot;&gt;X/Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X/Z&lt;/script&gt; model, in which &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; are independent and occur with the same probability. The probability of getting &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; errors is fixed as &lt;code class=&quot;MathJax_Preview&quot;&gt;P(Y)=P(X)P(Z)=P(X)^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(Y)=P(X)P(Z)=P(X)^2&lt;/script&gt; and is therefore lower than for depolarizing noise.&lt;/p&gt;

&lt;p&gt;Regarding the decoders, we will consider two of them here for simplicity: the maximum-likelihood decoder, and the matching decoder. As it happens, the code-capacity threshold for the maximum likelihood decoder corresponds exactly to the phase transition of a certain statistical mechanics model. This &lt;em&gt;stat mech mapping&lt;/em&gt; was established in &lt;a href=&quot;https://arxiv.org/abs/quant-ph/0110143&quot;&gt;Dennis et al.&lt;/a&gt; (a classic of the quantum error correction literature) in 2002. For the surface code subjected to independent &lt;code class=&quot;MathJax_Preview&quot;&gt;X/Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X/Z&lt;/script&gt; errors, the equivalent stat mech model is the random-bond Ising model, whose phase transition had just been calculated at that time. They were therefore able to give this first surface code threshold without doing any simulation themselves!&lt;/p&gt;

&lt;p&gt;We are now ready to give the actual threshold values for the surface code! Here is a table with the code-capacity thresholds of the different noise models and decoder discussed previously:&lt;/p&gt;

&lt;table style=&quot;margin: auto; width: 60%; text-align: center; margin-bottom: 1em&quot;&gt;
&lt;th&gt;
    &lt;td&gt;Maximum-likelihood&lt;/td&gt;
    &lt;td&gt;Matching&lt;/td&gt;
&lt;/th&gt;
&lt;tr&gt;
    &lt;td&gt;Depolarizing noise&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/1202.1852&quot;&gt;18.9%&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/0905.0531&quot;&gt;15.5%&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
    &lt;td&gt;Independent noise&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/quant-ph/0110143&quot;&gt;10.9%&lt;/a&gt;&lt;/td&gt;
    &lt;td&gt;&lt;a href=&quot;https://arxiv.org/abs/quant-ph/0110143&quot;&gt;10.5%&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p class=&quot;figure&quot;&gt;Table 1: Code-capacity thresholds of the surface code&lt;/p&gt;

&lt;p&gt;For phenomenological and circuit-level noise, I am only aware of some matching decoder thresholds under depolarizing noise. For phenomenological noise, we have a threshold of about &lt;a href=&quot;https://arxiv.org/abs/1907.02554&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;3\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3\%&lt;/script&gt;&lt;/a&gt;. For circuit-level noise, the threshold goes down to about &lt;a href=&quot;https://arxiv.org/abs/0905.0531&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;1\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1\%&lt;/script&gt;&lt;/a&gt;, which is often the cited value for “the threshold of the surface code”.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this post, we have defined the surface code and its different variants (toric, planar, rotated) and tried to understand its most important properties visually. We have seen that it encodes one or two logical qubits depending on the boundary conditions, and has a distance scaling as &lt;code class=&quot;MathJax_Preview&quot;&gt;\sqrt{N}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\sqrt{N}&lt;/script&gt;. Stabilizers can be thought as trivial (or contractible) loops on the underlying manifold, while the logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators are the non-trivial loops going around the torus or joining the boundaries, drawing a connection between topology and codes. We have also studied the decoding problem for the surface code and how minimum-weight perfect matching can be used for this purpose. Finally, I have introduced the notion of error-correction threshold and given its value for different decoders and noise models.&lt;/p&gt;

&lt;p&gt;The surface code is by far one of the most studied codes of the quantum error-correction literature and there is a lot more to say about it! I haven’t told you how to deal with measurement errors, how to prepare the code and measure the syndrome using quantum circuits, how to run logical gates on it, how to generalize it to different lattices and dimensions, how to make precise the connection with topology, etc. The surface code is also a stepping stone to understand more complicated codes, from the color code (the second most famous family of 2D codes) to hypergraph product codes and all the way to good LDPC codes. Now that you are equipped with the stabilizer formalism and have a good grasp of the surface code, the tree of possible learning trajectories has suddenly acquired many branches, and I hope to cover as many of those in subsequent blog posts!&lt;/p&gt;

&lt;p&gt;In the meantime, one direct follow-up from this post is &lt;a href=&quot;https://dom-kufel.github.io/blog/2023-04-15-toric_code-intro/&quot;&gt;Dominik Kufel’s post&lt;/a&gt; on the condensed matter aspects of the toric code, where you will learn about the connection between codes and Hamiltonians, why &lt;em&gt;excitations&lt;/em&gt; are called excitations and can be thought of as quasi-particles called &lt;em&gt;anyons&lt;/em&gt;, what the state of the surface code looks like and how it provides an example of topological phase of matter. This connection is crucial to learn for any practicing quantum error-correcter, as it is used extensively in the literature and allows to understand many computational aspects of the surface code (how to make gates by braiding anyons, why the circuit to prepare the surface code has polynomial size, etc.). So go read his post!&lt;/p&gt;

&lt;h2 id=&quot;solution-of-the-exercise&quot;&gt;Solution of the exercise&lt;/h2&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;: What is the equivalence class of the following (purple) loop? &lt;a href=&quot;#loops-on-a-smooth-manifold&quot;&gt;(Back to section)&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:center; margin-top: 2em; margin-bottom: 2em&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/surface-code/torus-exercise.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;
&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Correction&lt;/strong&gt;: The loops goes once around the middle hole, and three times around the hole forming the inside of the donut. Therefore, it belongs to coset labelled by &lt;code class=&quot;MathJax_Preview&quot;&gt;(1,3)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(1,3)&lt;/script&gt;.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;: What are the &lt;code class=&quot;MathJax_Preview&quot;&gt;[[n,k,d]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[n,k,d]]&lt;/script&gt; parameters of a surface code with lattice size &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt;? &lt;a href=&quot;#loops-on-the-surface-code&quot;&gt;(Back to section)&lt;/a&gt;&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Correction&lt;/strong&gt;: Since there are &lt;code class=&quot;MathJax_Preview&quot;&gt;L^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^2&lt;/script&gt; horizontal and &lt;code class=&quot;MathJax_Preview&quot;&gt;L^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^2&lt;/script&gt; vertical edges, we have &lt;code class=&quot;MathJax_Preview&quot;&gt;n=2L^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n=2L^2&lt;/script&gt;. Then, we saw that there are exactly two non-equivalent types of logical operators, meaning that there are &lt;code class=&quot;MathJax_Preview&quot;&gt;k=2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=2&lt;/script&gt; qubits. Finally, the distance is the minimum size of a logical operator, which in our case is &lt;code class=&quot;MathJax_Preview&quot;&gt;d=L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=L&lt;/script&gt;. Therefore, the surface code is a &lt;code class=&quot;MathJax_Preview&quot;&gt;[[2L^2, 2, L]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[2L^2, 2, L]]&lt;/script&gt;-code.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;I tend to use the names &lt;em&gt;surface code&lt;/em&gt; and &lt;em&gt;toric code&lt;/em&gt; interchangeably. Some people use &lt;em&gt;surface code&lt;/em&gt; to talk about the open-boundary version and &lt;em&gt;toric code&lt;/em&gt; to talk about the periodic-boundary one, but this is not a universal convention, and the name &lt;em&gt;planar code&lt;/em&gt; is also often used to talk about the open-boundary version. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;The final version of this embedding is just a few lines of Javascript, which use &lt;a href=&quot;gui.quantumcodes.io&quot;&gt;https://gui.quantumcodes.io&lt;/a&gt; as an API. So if &lt;strong&gt;you&lt;/strong&gt; would like to embed some codes (both 2D and 3D) in your website, feel free to contact me and I’ll give you the instructions to do it (I might add an official tutorial in the PanQEC documentation later). &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;For the interested reader, the rigorous definition is that two loops are equivalent if there exists a &lt;strong&gt;homotopy&lt;/strong&gt; between them. More precisely, we can define a loop as a continuous map &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell: S^1 \rightarrow \mathcal{M}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell: S^1 \rightarrow \mathcal{M}&lt;/script&gt; (an embedding of the circle onto the manifold). A homotopy between two loops &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell_1, \ell_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell_1, \ell_2&lt;/script&gt; is then a continuous function &lt;code class=&quot;MathJax_Preview&quot;&gt;L:S^1 \times [0,1] \rightarrow \mathcal{M}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L:S^1 \times [0,1] \rightarrow \mathcal{M}&lt;/script&gt; such that &lt;code class=&quot;MathJax_Preview&quot;&gt;L(\cdot, 0)=\ell_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L(\cdot, 0)=\ell_1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;L(\cdot, 1)=\ell_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L(\cdot, 1)=\ell_2&lt;/script&gt;. In other words, each &lt;code class=&quot;MathJax_Preview&quot;&gt;L(\cdot, t)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L(\cdot, t)&lt;/script&gt; for &lt;code class=&quot;MathJax_Preview&quot;&gt;t \in [0,1]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;t \in [0,1]&lt;/script&gt; defines a different loop on the path from &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell_1&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell_2&lt;/script&gt;. The equivalence relation defined here is called &lt;strong&gt;homotopy equivalence&lt;/strong&gt;, and is one of the most important notions of equivalence in topology. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;This other notion of equivalence is called &lt;strong&gt;homological equivalence&lt;/strong&gt;. Technically, two loops are homologically-equivalent if they can be seen as the boundary of a higher-dimensional object (in our case, the boundary of some plaquettes). In particular, trivial loops are the ones that are themselves boundaries of some objects (they are equivalent to the zero loop) and non-trivial loops are the ones that cannot be seen as boundaries. While the notion of homotopy is more powerful in general (it gives more information about a topological manifold), homology classes are usually simpler to calculate and are the right topological invariants for many practical applications. I will try to dedicate a post to the notion homology and its applications in quantum error correction. &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/2303.13723&quot;&gt;Rotor codes&lt;/a&gt; are example of such continuous-variable codes. &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;The backend is using &lt;a href=&quot;https://github.com/oscarhiggott/PyMatching&quot;&gt;PyMatching&lt;/a&gt;, Oscar Higgott’s fast implementation of minimum-weight perfect matching. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;We assume here that we have a Pauli error model. The reasons for this choice are actually quite technical and I hope to write a post about it one day. In the meantime, you can have a look at Section 10.3 of Nielsen &amp;amp; Chuang to get an idea of the argument. &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="quantum-computing" /><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/surface-code/thumbnail.png" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/surface-code/thumbnail.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The stabilizer trilogy III — Parity-check matrices and decoding</title><link href="https://arthurpesah.me/blog/2023-03-28-stabilizer-formalism-3/" rel="alternate" type="text/html" title="The stabilizer trilogy III — Parity-check matrices and decoding" /><published>2023-03-28T00:00:00+02:00</published><updated>2023-03-28T00:00:00+02:00</updated><id>https://arthurpesah.me/blog/stabilizer-formalism-3</id><content type="html" xml:base="https://arthurpesah.me/blog/2023-03-28-stabilizer-formalism-3/">&lt;p&gt;Welcome to the third and last post of the stabilizer trilogy! In &lt;a href=&quot;/blog/2023-01-31-stabilizer-formalism-1/&quot;&gt;Parts I&lt;/a&gt; and &lt;a href=&quot;/blog/2023-03-16-stabilizer-formalism-2/&quot;&gt;II&lt;/a&gt;, we introduced the stabilizer formalism using a group theoretic language: stabilizer codes are abelian subgroups of the Pauli group, logicals are elements of the centralizers, etc. While this formulation has a lot of merit, it might not be immediately obvious how to implement it in practice if you want to
simulate a code. Fortunately, the whole formalism can be reexpressed using vectors, matrices and the whole linear algebra toolbox that comes with them: this is the parity-check matrix formulation! Parity-check matrices make it not only easy to implement stabilizer codes in your favorite programming language, they are also a very powerful tools to prove theorems about them, to classify them, to decode them, and more!&lt;/p&gt;

&lt;p&gt;In this post, we will see how to define the parity-check matrix of a stabilizer code in the binary symplectic format, and how to express the decoding problem using it. After a short motivation section to remind you about classical parity-check matrices, we will delve into the binary symplectic format, a way to express Pauli operators using vectors. We will then define quantum parity-check matrices in this format and see how syndromes and logical operators can be expressed using them. With those tools in our hand, we will finally be able to define the decoding problem for quantum codes, and in particular see how to decode the Steane code. We will finish this post by defining quantum Tanner graphs, a graphical representation of parity-check matrices, often used in the literature to study the properties of codes and decoders.&lt;/p&gt;

&lt;h2 id=&quot;motivation&quot;&gt;Motivation&lt;/h2&gt;

&lt;p&gt;When studying classical coding theory, we saw that a code can be defined as a binary matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt;, called the parity-check matrix, such that any codeword &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; satisfies&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} \bm{x} = \bm{0}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\bm{H} \bm{x} = \bm{0}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Thus, a codeword &lt;code class=&quot;MathJax_Preview&quot;&gt;x&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; corrupted by an error &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt;, denoted &lt;code class=&quot;MathJax_Preview&quot;&gt;\widetilde{\bm{x}}=\bm{x} + \bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\widetilde{\bm{x}}=\bm{x} + \bm{e}&lt;/script&gt;, obeys&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} \widetilde{\bm{x}} = \bm{H} \bm{e} = \bm{s}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\bm{H} \widetilde{\bm{x}} = \bm{H} \bm{e} = \bm{s}
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{s}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{s}&lt;/script&gt; is the syndrome. This formulation of linear coding theory was useful for many reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It allows to express the decoding problem as a constrained optimization problem&lt;/li&gt;
&lt;/ul&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\max_{\bm{e} \in \mathbb{Z}_2^n} P(\bm{e}) \; \text{ s.t. } \; \bm{H} \bm{e} = \bm{s}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\max_{\bm{e} \in \mathbb{Z}_2^n} P(\bm{e}) \; \text{ s.t. } \; \bm{H} \bm{e} = \bm{s}
\end{aligned}&lt;/script&gt;

&lt;ul&gt;
  &lt;li&gt;It makes syndrome calculations straightforward, as a simple matrix multiplication&lt;/li&gt;
  &lt;li&gt;Many properties of a code can be deduced directly from its parity-check (such as the weight of its checks via the sparsity of the matrix, the number of encoded qubits via its rank, etc.)&lt;/li&gt;
  &lt;li&gt;The parity-check matrix can be seen as the adjacency matrix of a graph, the Tanner graph, which is used for instance when solving the decoding problem with belief propagation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We will now see that such a formulation is possible in the stabilizer formalism.
There are two different methods to arrive at a definition of a quantum parity-check matrix:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The &lt;code class=&quot;MathJax_Preview&quot;&gt;GF(4)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;GF(4)&lt;/script&gt; format, where the elements of the parity-check matrix belong to a Galois field with four elements (instead of the binary field in the classical case).&lt;/li&gt;
  &lt;li&gt;The binary symplectic format, where the parity-check matrix remains binary, but doubles in size compared to the classical one.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Even though the &lt;code class=&quot;MathJax_Preview&quot;&gt;GF(4)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;GF(4)&lt;/script&gt; format has some useful applications&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, the binary symplectic one is simpler, more popular, and used in most quantum error correction libraries&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.
This is therefore the one I will present in this post.
Until I do a separate post on &lt;code class=&quot;MathJax_Preview&quot;&gt;GF(4)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;GF(4)&lt;/script&gt;, feel free to take a look at Section 3.2 of Daniel Gottesman’s lecture notes in the meantime.&lt;/p&gt;

&lt;h2 id=&quot;binary-symplectic-format&quot;&gt;Binary symplectic format&lt;/h2&gt;

&lt;p&gt;The core idea behind the binary symplectic format is the observation that Paulis can be mapped to two-bit words using the following dictionary:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
(0\vert0) &amp;amp; \rightarrow I \\
(1\vert0) &amp;amp; \rightarrow X \\
(0\vert1) &amp;amp; \rightarrow Z \\
(1\vert1) &amp;amp; \rightarrow Y
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
(0\vert0) &amp; \rightarrow I \\
(1\vert0) &amp; \rightarrow X \\
(0\vert1) &amp; \rightarrow Z \\
(1\vert1) &amp; \rightarrow Y
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;In this representation, the first bit indicates the presence of an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and the second bit the presence of a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;.
So &lt;code class=&quot;MathJax_Preview&quot;&gt;(0\vert0)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(0\vert0)&lt;/script&gt; is the identity operator (no &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;, no &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;) and &lt;code class=&quot;MathJax_Preview&quot;&gt;(1\vert1)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(1\vert1)&lt;/script&gt; is the &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; operator (as it can be written &lt;code class=&quot;MathJax_Preview&quot;&gt;XZ&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XZ&lt;/script&gt;).
We can also write this more formally as &lt;code class=&quot;MathJax_Preview&quot;&gt;(x \vert z) \leftrightarrow X^{x} Z^{z}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(x \vert z) \leftrightarrow X^{x} Z^{z}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Since Pauli elements can also have a phase (which can be &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;+i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+i&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;-i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-i&lt;/script&gt;), we should in principle include two more bits in our dictionary in order to represent it. While some applications do require those two bits, e.g. the &lt;a href=&quot;https://arxiv.org/abs/quant-ph/0406196&quot;&gt;stabilizer tableau method&lt;/a&gt; for simulating Clifford circuits efficiently, the phase is often ignored in the context of quantum error correction. To understand why, let’s consider a quantum code characterized by a stabilizer group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; generated by some elements &lt;code class=&quot;MathJax_Preview&quot;&gt;\{S_i\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{S_i\}&lt;/script&gt;. Since Pauli elements with a phase of &lt;code class=&quot;MathJax_Preview&quot;&gt;+i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+i&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;-i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-i&lt;/script&gt; are not Hermitian (and furthermore, square to &lt;code class=&quot;MathJax_Preview&quot;&gt;-I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-I&lt;/script&gt;), they cannot be included in the stabilizer group. Moreover, any time a stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;S_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_i&lt;/script&gt; has a phase of &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;, it’s possible to replace it by &lt;code class=&quot;MathJax_Preview&quot;&gt;-S_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-S_i&lt;/script&gt; without changing any property of the code. So choosing to have stabilizer generators with a phase of &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt; is a matter of convention, and the choice of &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; for every generator is often adopted. Furthermore, Pauli errors can also be considered to have a phase of &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; (in that case, the phase is global and can safely be ignored), and all the important operations considered in this post (such as commutation and anticommutation of Paulis) are phase-independent as well.&lt;/p&gt;

&lt;p&gt;One nice feature of our binary representation is that the multiplication of Pauli elements maps to the addition (modulo 2) of two-bit words &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;. Indeed,&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
(x \vert z) + (x' \vert z') = (x+x' \vert z+z') \leftrightarrow \left( X^{x} Z^{z} \right) \left( X^{x'} Z^{z'} \right) = X^{x+x'} Z^{z+z'}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
(x \vert z) + (x' \vert z') = (x+x' \vert z+z') \leftrightarrow \left( X^{x} Z^{z} \right) \left( X^{x'} Z^{z'} \right) = X^{x+x'} Z^{z+z'}
\end{aligned}&lt;/script&gt;

&lt;p&gt;We were able to commute things through in the last equality as Pauli operators commute up to a phase, which we’re choosing to ignore here.&lt;/p&gt;

&lt;p&gt;For instance, &lt;code class=&quot;MathJax_Preview&quot;&gt;(1\vert0) + (0\vert1) = (1\vert1) \leftrightarrow XZ = Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(1\vert0) + (0\vert1) = (1\vert1) \leftrightarrow XZ = Y&lt;/script&gt;, or &lt;code class=&quot;MathJax_Preview&quot;&gt;(1\vert0) + (1\vert0) = (0\vert0) \leftrightarrow X^2 = I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(1\vert0) + (1\vert0) = (0\vert0) \leftrightarrow X^2 = I&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;This representation can be generalized to many-qubit Pauli operators as well. A Pauli vector &lt;code class=&quot;MathJax_Preview&quot;&gt;P=P_1 \otimes \ldots \otimes P_n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P=P_1 \otimes \ldots \otimes P_n&lt;/script&gt; is mapped to the following vector in the binary symplectic format:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
(x_1 \ldots x_n \vert z_1 \ldots z_n)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
(x_1 \ldots x_n \vert z_1 \ldots z_n)
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;(x_i \vert z_i)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(x_i \vert z_i)&lt;/script&gt; is the representation of &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i&lt;/script&gt;. For example, the operator &lt;code class=&quot;MathJax_Preview&quot;&gt;Z \otimes Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z \otimes Y&lt;/script&gt; can be written &lt;code class=&quot;MathJax_Preview&quot;&gt;(01 \vert 11)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(01 \vert 11)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The next step is to express commutation relations in this format. Indeed, remember that the syndrome depends entirely on the commutation relations between stabilizers and errors (the syndrome is &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; if they commute and &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; if they anticommute). This is where the “symplectic” part of the binary symplectic format kicks in.&lt;/p&gt;

&lt;p&gt;Let’s define the &lt;strong&gt;symplectic product&lt;/strong&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;\odot&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\odot&lt;/script&gt; between two binary symplectic vectors &lt;code class=&quot;MathJax_Preview&quot;&gt;(\bm{x} \vert \bm{z})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(\bm{x} \vert \bm{z})&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;(\bm{x'} \vert \bm{z'})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(\bm{x'} \vert \bm{z'})&lt;/script&gt; as&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
(\bm{x} \vert \bm{z}) \odot (\bm{x'} \vert \bm{z'}) = (\bm{x} \vert \bm{z}) \Omega (\bm{x'} \vert \bm{z'})^T = \bm{x} \cdot \bm{z'} + \bm{z} \cdot \bm{x'}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
(\bm{x} \vert \bm{z}) \odot (\bm{x'} \vert \bm{z'}) = (\bm{x} \vert \bm{z}) \Omega (\bm{x'} \vert \bm{z'})^T = \bm{x} \cdot \bm{z'} + \bm{z} \cdot \bm{x'}
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;\Omega&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Omega&lt;/script&gt; is the &lt;strong&gt;symplectic matrix&lt;/strong&gt;, defined as:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\Omega = \left(
\begin{matrix}
0 &amp;amp; I_n \\
I_n &amp;amp; 0
\end{matrix}
\right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\Omega = \left(
\begin{matrix}
0 &amp; I_n \\
I_n &amp; 0
\end{matrix}
\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;and &lt;code class=&quot;MathJax_Preview&quot;&gt;\cdot&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\cdot&lt;/script&gt; is the usual dot product modulo &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt;. The interpretation of this product is that two Pauli operators commute if their binary symplectic product is &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt;, and anticommute if it is &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;.
To see this, notice that &lt;code class=&quot;MathJax_Preview&quot;&gt;x_i z'_i + z_i x'_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;x_i z'_i + z_i x'_i&lt;/script&gt; is equal to &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; if and only if there is an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; intersecting on qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;, but not a &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; on both (which would give &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt;, or &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; modulo &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt;). In other words, it is &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; if and only if the two Pauli elements acting on qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; anticommute. Summing over all &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;, it means that the symplectic product &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x} \cdot \bm{z'} + \bm{z} \cdot \bm{x'}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x} \cdot \bm{z'} + \bm{z} \cdot \bm{x'}&lt;/script&gt; is equal to &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; if and only if there is an odd number of Pauli elements that anticommute, or equivalently, if the two Pauli operators anticommute.&lt;/p&gt;

&lt;h2 id=&quot;the-quantum-parity-check-matrix&quot;&gt;The quantum parity-check matrix&lt;/h2&gt;

&lt;p&gt;We are now ready to talk about parity-check matrices. Let &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; a stabilizer group on &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; qubits, generated by a set of &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; stabilizers &lt;code class=&quot;MathJax_Preview&quot;&gt;\{S_i\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{S_i\}&lt;/script&gt;. The &lt;strong&gt;quantum parity-check matrix&lt;/strong&gt; of the code, associated to those generators, is the &lt;code class=&quot;MathJax_Preview&quot;&gt;m \times 2n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m \times 2n&lt;/script&gt; matrix where each row is a stabilizer written in the binary symplectic format. For example, here is the parity-check matrix of the Steane code, with the plaquette stabilizers as generators:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} = \left(
\begin{matrix}
\color{OrangeRed} 1 &amp;amp; \color{OrangeRed} 1 &amp;amp; \color{OrangeRed} 1 &amp;amp; \color{OrangeRed} 1 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \vert &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 \\
\color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 1 &amp;amp; \color{RoyalBlue} 1 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 1 &amp;amp; \color{RoyalBlue} 1 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \vert &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 \\
\color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 1 &amp;amp; \color{ForestGreen} 1 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 1 &amp;amp; \color{ForestGreen} 1 &amp;amp; \vert &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 \\

\color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \vert &amp;amp; \color{OrangeRed} 1 &amp;amp; \color{OrangeRed} 1 &amp;amp; \color{OrangeRed} 1 &amp;amp; \color{OrangeRed} 1 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 &amp;amp; \color{OrangeRed} 0 \\
\color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \vert &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 1 &amp;amp; \color{RoyalBlue} 1 &amp;amp; \color{RoyalBlue} 0 &amp;amp; \color{RoyalBlue} 1 &amp;amp; \color{RoyalBlue} 1 &amp;amp; \color{RoyalBlue} 0 \\
\color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \vert &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 1 &amp;amp; \color{ForestGreen} 1 &amp;amp; \color{ForestGreen} 0 &amp;amp; \color{ForestGreen} 1 &amp;amp; \color{ForestGreen} 1 \\
\end{matrix}
\right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\bm{H} = \left(
\begin{matrix}
\color{OrangeRed} 1 &amp; \color{OrangeRed} 1 &amp; \color{OrangeRed} 1 &amp; \color{OrangeRed} 1 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \vert &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 \\
\color{RoyalBlue} 0 &amp; \color{RoyalBlue} 1 &amp; \color{RoyalBlue} 1 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 1 &amp; \color{RoyalBlue} 1 &amp; \color{RoyalBlue} 0 &amp; \vert &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 \\
\color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 1 &amp; \color{ForestGreen} 1 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 1 &amp; \color{ForestGreen} 1 &amp; \vert &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 \\

\color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \vert &amp; \color{OrangeRed} 1 &amp; \color{OrangeRed} 1 &amp; \color{OrangeRed} 1 &amp; \color{OrangeRed} 1 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 &amp; \color{OrangeRed} 0 \\
\color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 0 &amp; \vert &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 1 &amp; \color{RoyalBlue} 1 &amp; \color{RoyalBlue} 0 &amp; \color{RoyalBlue} 1 &amp; \color{RoyalBlue} 1 &amp; \color{RoyalBlue} 0 \\
\color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \vert &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 1 &amp; \color{ForestGreen} 1 &amp; \color{ForestGreen} 0 &amp; \color{ForestGreen} 1 &amp; \color{ForestGreen} 1 \\
\end{matrix}
\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;I have colored each row in accordance to the plaquette it corresponds to. For convenience, here are the plaquette stabilizers of the Steane code again:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/stabilizer-formalism-1/steane-code-stabilizers.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Write the parity-check matrix of &lt;a href=&quot;/blog/2023-01-31-stabilizer-formalism-1/#our-first-truly-quantum-code-shors-code&quot;&gt;Shor’s code&lt;/a&gt; &lt;a href=&quot;#solution-of-the-exercise&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One important thing to notice in the matrix above is that it can be written:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} = \left(
\begin{matrix}
H_{\text{Hamming}} &amp;amp; \vert &amp;amp; \bm{0} \\
\bm{0} &amp;amp; \vert &amp;amp; H_{\text{Hamming}}
\end{matrix}
\right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\bm{H} = \left(
\begin{matrix}
H_{\text{Hamming}} &amp; \vert &amp; \bm{0} \\
\bm{0} &amp; \vert &amp; H_{\text{Hamming}}
\end{matrix}
\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;H_{\text{Hamming}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_{\text{Hamming}}&lt;/script&gt; is the parity-check matrix of the classical Hamming code.&lt;/p&gt;

&lt;p&gt;More generally, the parity-check matrix of any CSS code can be decomposed as&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} = \left(
\begin{matrix}
H_X &amp;amp; \vert &amp;amp; \bm{0} \\
\bm{0} &amp;amp; \vert &amp;amp; H_Z
\end{matrix}
\right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\bm{H} = \left(
\begin{matrix}
H_X &amp; \vert &amp; \bm{0} \\
\bm{0} &amp; \vert &amp; H_Z
\end{matrix}
\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;H_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;H_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_Z&lt;/script&gt; are the parity-check matrices of the two classical codes &lt;code class=&quot;MathJax_Preview&quot;&gt;C_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;C_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_Z&lt;/script&gt;.
The condition that all the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizers should commute with all the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers can be written as&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
H_X H_Z^T = \bm{0}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
H_X H_Z^T = \bm{0}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Indeed, each component &lt;code class=&quot;MathJax_Preview&quot;&gt;i,j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i,j&lt;/script&gt; of the product &lt;code class=&quot;MathJax_Preview&quot;&gt;H_X H_Z^T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_X H_Z^T&lt;/script&gt; is equal to the dot product (modulo &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt;) between the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;-check &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;-check &lt;code class=&quot;MathJax_Preview&quot;&gt;j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;. This dot product will be &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; if and only if the two checks intersect on an even number of bits, or in other words, if the corresponding stabilizers commute.&lt;/p&gt;

&lt;p&gt;Even more generally, the parity-check matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt; of any stabilizer code must satisfy:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} \odot \bm{H} = \bm{0}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\bm{H} \odot \bm{H} = \bm{0}
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;\odot&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\odot&lt;/script&gt; is the matrix version of the binary symplectic product, defined such that each component &lt;code class=&quot;MathJax_Preview&quot;&gt;i,j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i,j&lt;/script&gt; is the binary symplectic product between row &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; of the first matrix and row &lt;code class=&quot;MathJax_Preview&quot;&gt;j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; of the second matrix. This constraint is what makes it hard to design quantum codes by using classical constructions: most classical codes don’t satisfy this property. But that’s also what makes quantum error correction so unique and interesting, as very specific tools have been introduced in the field in order to come up with new quantum codes. For instance, the topological interpretation of this constraint (as a chain complex) explains the wide intersection between topology and quantum error correction, which doesn’t arise classically. We will start studying topological quantum error correction in the next post, but for now, let’s continue studying the properties of those parity-check matrices.&lt;/p&gt;

&lt;h2 id=&quot;syndrome-and-logical-operators&quot;&gt;Syndrome and logical operators&lt;/h2&gt;

&lt;p&gt;Given an error &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt; written in the binary symplectic format, we can obtain the syndrome &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{s}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{s}&lt;/script&gt; using&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} \odot \bm{e} = \bm{s}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\bm{H} \odot \bm{e} = \bm{s}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Indeed, each component of the syndrome tells us whether a given stabilizer commutes with the error, i.e. &lt;code class=&quot;MathJax_Preview&quot;&gt;s_i=0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;s_i=0&lt;/script&gt; if &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}_i&lt;/script&gt; commute, &lt;code class=&quot;MathJax_Preview&quot;&gt;s_i=1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;s_i=1&lt;/script&gt; if they anticommute.
Note that this is the same equation as the classical one, with the matrix product replaced by the symplectic product.
Now, we saw that for classical parity-check matrices, we had &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H} \bm{x} = \bm{0}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H} \bm{x} = \bm{0}&lt;/script&gt; for every codeword &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt;. However, we don’t really have “codewords” in quantum error correction. So what would be the equivalent of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; in this equation, or in other words, what is the kernel of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt;? Any guess?&lt;/p&gt;

&lt;p&gt;The kernel of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt; is the set of logical operators! Indeed, as we saw in the first section of this post, we can define logical operators as elements of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}(\mathcal{S})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}(\mathcal{S})&lt;/script&gt;, which by definition is the set of all the elements that commute with the stabilizers. And if you remember, this set includes both stabilizers and non-trivial logical operators.&lt;/p&gt;

&lt;p&gt;This fact is actually very useful in practice: it gives us a systematic method to find the non-trivial logicals of a given a code. Find a basis for the kernel of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt;, and keep all the elements that cannot be written as linear combinations of rows of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt;, that is, which are not stabilizers.&lt;/p&gt;

&lt;h2 id=&quot;decoding&quot;&gt;Decoding&lt;/h2&gt;

&lt;p&gt;As for classical error correction, the decoding problem for quantum codes can be expressed using parity-check matrices.
However, there is an important subtlety compared to the classical case.
Instinctively, we would like to express the decoding problem as follow:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\max_{\bm{c} \in \mathbb{Z}_2^{2n}} P(\bm{c}) \; \text{ s.t. } \; \bm{H} \odot \bm{c} = \bm{s}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\max_{\bm{c} \in \mathbb{Z}_2^{2n}} P(\bm{c}) \; \text{ s.t. } \; \bm{H} \odot \bm{c} = \bm{s}
\end{aligned}&lt;/script&gt;

&lt;p&gt;This corresponds to finding the error &lt;code class=&quot;MathJax_Preview&quot;&gt;c&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt; that fits the syndrome and has the highest probability of happening.
However, the actual goal is not quite exactly that.&lt;/p&gt;

&lt;p&gt;To see why, let’s first slightly reformulate the syndrome equation constraint from above. If &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt; is the actual error and we choose to apply a correction operator &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{c}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{c}&lt;/script&gt;, the total operator &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}+\bm{c}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}+\bm{c}&lt;/script&gt; applied to the code satisfies:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} \odot (\bm{e} + \bm{c}) = \bm{s} + \bm{s} = \bm{0}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\bm{H} \odot (\bm{e} + \bm{c}) = \bm{s} + \bm{s} = \bm{0}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Therefore &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}+\bm{c} \in \text{Ker}(\bm{H})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}+\bm{c} \in \text{Ker}(\bm{H})&lt;/script&gt; is either a stabilizer or a non-trivial logical operator.
If it is a stabilizer, it doesn’t have any effect on the codespace, and mission accomplished.
If it is a non-trivial logical operator, we have failed the decoding process and applied a logical error to the state.&lt;/p&gt;

&lt;p&gt;Now, let’s notice that if a given correction satisfies the syndrome equation, any stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x} \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x} \in \mathcal{S}&lt;/script&gt; applied on top of this correction will also satisfy the syndrome equation:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} \odot (\bm{c} + \bm{x}) = \bm{s} + \bm{0} = \bm{s}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\bm{H} \odot (\bm{c} + \bm{x}) = \bm{s} + \bm{0} = \bm{s}
\end{aligned}&lt;/script&gt;

&lt;p&gt;And not only that, but &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}+(\bm{c}+\bm{x})=(\bm{e}+\bm{c})+\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}+(\bm{c}+\bm{x})=(\bm{e}+\bm{c})+\bm{x}&lt;/script&gt;, so the final operators will be the same up to a stabilizer.
Therefore, it’s tempting to do as in the previous post and create an equivalence relation between correction operators that fit the syndrome.
We say that two operators &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{c}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{c}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{c'}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{c'}&lt;/script&gt; are equivalent if there exists a stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x} \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x} \in \mathcal{S}&lt;/script&gt; such that &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{c}=\bm{c'}+\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{c}=\bm{c'}+\bm{x}&lt;/script&gt;. Equipped with this equivalence relation, we can now partition all the correction operators into cosets: two operators belong to the same coset if they are equivalent. And here is the key of the quantum decoding problem: we only need to find a correction operator that belongs to the same coset as the error. Indeed, if &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{c}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{c}&lt;/script&gt; belong to the same coset, it means that there exists &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x} \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x} \in \mathcal{S}&lt;/script&gt; such that &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{c}=\bm{e}+\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{c}=\bm{e}+\bm{x}&lt;/script&gt;. Therefore, the total operator &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}+\bm{c}=\bm{e}+\bm{e}+\bm{x}=\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}+\bm{c}=\bm{e}+\bm{e}+\bm{x}=\bm{x}&lt;/script&gt; is a stabilizer. On the other hand, if they belong to a different coset, the sum can’t be a stabilizer, since &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}+\bm{c} = \bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}+\bm{c} = \bm{x}&lt;/script&gt; for &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x} \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x} \in \mathcal{S}&lt;/script&gt; implies that &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{c}=\bm{e}+\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{c}=\bm{e}+\bm{x}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e} \sim \bm{c}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e} \sim \bm{c}&lt;/script&gt;. This means that &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}+\bm{c}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}+\bm{c}&lt;/script&gt; is a non-trivial logical operator (i.e. a logical error).&lt;/p&gt;

&lt;p&gt;Denoting &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}_{\bm{s}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}_{\bm{s}}&lt;/script&gt; the set of operators that fit the syndrome &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{s}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{s}&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}_{\bm{s}} / \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}_{\bm{s}} / \mathcal{S}&lt;/script&gt; the set of all cosets (called a quotient space), we can express the real objective of the quantum decoding problem as finding the coset &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{\bar{c}} \in \mathcal{E}_{\bm{s}} / \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{\bar{c}} \in \mathcal{E}_{\bm{s}} / \mathcal{S}&lt;/script&gt; with the highest probability:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \max_{\bm{\bar{c}} \in \mathcal{E}_{\bm{s}} / \mathcal{S}} P(\bm{\bar{c}})
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \max_{\bm{\bar{c}} \in \mathcal{E}_{\bm{s}} / \mathcal{S}} P(\bm{\bar{c}})
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{\bar{c}})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{\bar{c}})&lt;/script&gt; can be calculated as &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{\bar{c}}) = \sum_{\bm{c} \in \bm{\bar{c}}} P(\bm{c})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{\bar{c}}) = \sum_{\bm{c} \in \bm{\bar{c}}} P(\bm{c})&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;For many codes, it’s possible to find syndromes where those two versions of the decoding problem give a different solution. This will be the case when the coset containing the most likely error have much less elements than another coset which contain slightly less likely errors. However, in practice, the two decoding problems often have the same solution, and many practical decoders only seek to solve the first optimization problem. This often results in a small decrease of performance, for a high gain in speed (this is for instance the case of the matching decoder for the surface code, that you might have heard of).&lt;/p&gt;

&lt;p&gt;As always, let’s apply what we’ve just learned to the Steane code.
As an example, let’s see how to decode a syndrome consisting of a single blue &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;-plaquette.
Here are the two cosets of &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators that fit this syndrome:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-3/steane-coset-1.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-3/steane-coset-2.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The first coset is constructed by taking the only single-qubit error that fits the syndrome, shown in the top-left triangle, and applying the seven &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers to it (blue, red, green, blue-red, blue-green, red-green, red-blue-green). The second coset is obtained in a similar way, starting with the two-qubit operator shown in the top-left triangle.&lt;/p&gt;

&lt;p&gt;Assuming an i.i.d noise, we can immediately solve the first decoding problem: the most likely error is the one of minimum weight, that is, the first error of coset 1. We can therefore choose any correction operator in this coset as our decoding solution.&lt;/p&gt;

&lt;p&gt;Solving the second decoding problem requires a bit more work. Let &lt;code class=&quot;MathJax_Preview&quot;&gt;p&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;p&lt;/script&gt; the probability that an error occurs on a given qubit, that is, the error rate of the noise channel. Each weight-&lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; error has a probability &lt;code class=&quot;MathJax_Preview&quot;&gt;\pi_k = p^k (1-p)^{7-k}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\pi_k = p^k (1-p)^{7-k}&lt;/script&gt;. Summing the probabilities of all the elements, we get&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    P(\text{coset 1}) &amp;amp;= \pi_1 + 4 \pi_3 + 3 \pi_5 \\
    P(\text{coset 2}) &amp;amp;= 3 \pi_2 + 4 \pi_4 + \pi_6
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    P(\text{coset 1}) &amp;= \pi_1 + 4 \pi_3 + 3 \pi_5 \\
    P(\text{coset 2}) &amp;= 3 \pi_2 + 4 \pi_4 + \pi_6
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Plotting those two probabilities as a function of the error rate, we can see that the first coset always has a higher probability than the second one:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-3/coset-probabilities.png&quot; height=&quot;350&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;This can also be shown analytically by noticing that&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    P(\text{coset 1}) - P(\text{coset 2}) = p (1-p) (1-2p)^3 (2p^2 - 2p + 1)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    P(\text{coset 1}) - P(\text{coset 2}) = p (1-p) (1-2p)^3 (2p^2 - 2p + 1)
\end{aligned}&lt;/script&gt;

&lt;p&gt;from which we can deduce that &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\text{coset 1}) &amp;gt; P(\text{coset 2})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\text{coset 1}) &gt; P(\text{coset 2})&lt;/script&gt; for &lt;code class=&quot;MathJax_Preview&quot;&gt;0 &amp;lt; p &amp;lt; \frac{1}{2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
0 &lt; p &lt; \frac{1}{2} %]]&gt;&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Therefore, both decoding formulations give the first coset as our decoding solution.&lt;/p&gt;

&lt;h2 id=&quot;tanner-graph&quot;&gt;Tanner graph&lt;/h2&gt;

&lt;p&gt;Many methods to design quantum codes and decoders work by representing stabilizer codes using their so-called Tanner graph.
The &lt;strong&gt;Tanner graph&lt;/strong&gt; of a code associated to an &lt;code class=&quot;MathJax_Preview&quot;&gt;m \times 2n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m \times 2n&lt;/script&gt; parity-check matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;H&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt; is built by creating &lt;code class=&quot;MathJax_Preview&quot;&gt;2n+m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2n+m&lt;/script&gt; nodes: two nodes per qubit (one for &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors and one for &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors), and one node per stabilizer.
By convention, qubit nodes are often represented by circles and stabilizer nodes by squares.
Each stabilizer node is then connected to the qubits in its support (with the right Pauli operators). In other words, &lt;code class=&quot;MathJax_Preview&quot;&gt;H&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt; is the biadjacency matrix of the Tanner graph.&lt;/p&gt;

&lt;p&gt;As an example, here is the Tanner graph of the Steane code, where I colored the stabilizer nodes to indicate to which plaquette operators they correspond.&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-3/tanner-graph-steane.png&quot; height=&quot;350&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;The fact that this graph contains two separate components (the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; part and the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; part) is due to the CSS nature of the Steane code. In general, a stabilizer node can be connected to both &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; qubit nodes.&lt;/p&gt;

&lt;p&gt;Many properties of codes and decoders can be interpreted in terms of Tanner graphs. For instance, a low-density parity-check (LDPC) code can be defined as a code whose Tanner graph has constant degree (each qubit is connected to &lt;code class=&quot;MathJax_Preview&quot;&gt;O(1)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;O(1)&lt;/script&gt; stabilizers and each stabilizer to &lt;code class=&quot;MathJax_Preview&quot;&gt;O(1)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;O(1)&lt;/script&gt; qubits). Similarly, a hypergraph-product code is best interpreted as a certain product of Tanner graphs. Finally, the performance of the belief propagation decoder on a certain code strongly depends on the size of the shortest cycle (also called the girth) of its Tanner graph.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Let’s summarize what we have learned in this post. Pauli operators acting on &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; qubits can be expressed as binary vectors with &lt;code class=&quot;MathJax_Preview&quot;&gt;2n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2n&lt;/script&gt; components: this is the binary symplectic format. The symplectic product on such vectors indicates whether two Pauli operators commute or not. Writing the generators of a stabilizer code in the binary symplectic format gives a parity-check matrix representing the code, and multiplying this parity-check matrix with an error vector gives the syndrome. As a result, logical operators (including stabilizers) are elements of the kernel of the parity-check matrix. To perform decoding, an optimal algorithm should choose a correction operator that belongs to the most likely coset of errors fitting the syndrome. However, decoders that simply output the most likely error often have acceptable performance in practice. Finally, the Tanner graph of a code is the the graph which has the parity-check matrix as its biadjacency matrix.&lt;/p&gt;

&lt;p&gt;This is it for the stabilizer trilogy, well done for having read this far! You should now be equipped with all the foundations to start delving into the quantum error correction literature and understand the most popular codes and decoders out there!&lt;/p&gt;

&lt;p&gt;While the formalism that we have developed so far is helpful to analyze any code you will encounter, you probably still have no idea how to come up with a new code on your own. The next series of posts will be dedicated to a quite general code construction that builds on top of the stabilizer formalism: topological quantum error correction. So be ready for a new journey towards the surface code and its generalizations!&lt;/p&gt;

&lt;h2 id=&quot;solution-of-the-exercise&quot;&gt;Solution of the exercise&lt;/h2&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: Write the parity-check matrix of &lt;a href=&quot;/blog/2023-01-31-stabilizer-formalism-1/#our-first-truly-quantum-code-shors-code&quot;&gt;Shor’s code&lt;/a&gt; &lt;a href=&quot;#the-quantum-parity-check-matrix&quot;&gt;(Back to section)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;
&lt;strong&gt;Correction&lt;/strong&gt;: Shor’s code can be generated by the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;-stabilizers &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1 Z_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1 Z_2&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_2 Z_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_2 Z_3&lt;/script&gt; on each 3-qubit block, as well as the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;-stabilizers &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_1} \overline{X_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_1} \overline{X_2}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_2} \overline{X_3}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_2} \overline{X_3}&lt;/script&gt; (using the notations defined in first post of the series). This gives the following parity-check matrix:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bm{H} = \left(
\begin{matrix}
1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \vert &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; \vert &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \vert &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \vert &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \vert &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \vert &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \vert &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 \\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; \vert &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1
\end{matrix}
\right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
\bm{H} = \left(
\begin{matrix}
1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; \vert &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; \vert &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \vert &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \vert &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \vert &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \vert &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \vert &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \vert &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 1
\end{matrix}
\right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;See for instance belief propagation defined over GF(4) &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;qecsim, PanQEC, PyMatching, ldpc, etc. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;If you know a bit of abstract algebra, you will notice that our map defines an isomorphism from the Pauli group (modulo the phase) to the group &lt;code class=&quot;MathJax_Preview&quot;&gt;(\mathbb{Z}_2^2, +)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(\mathbb{Z}_2^2, +)&lt;/script&gt; &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Thanks Alex Cliffe for suggesting this proof! &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="quantum-computing" /><summary type="html">Welcome to the third and last post of the stabilizer trilogy! In Parts I and II, we introduced the stabilizer formalism using a group theoretic language: stabilizer codes are abelian subgroups of the Pauli group, logicals are elements of the centralizers, etc. While this formulation has a lot of merit, it might not be immediately obvious how to implement it in practice if you want to simulate a code. Fortunately, the whole formalism can be reexpressed using vectors, matrices and the whole linear algebra toolbox that comes with them: this is the parity-check matrix formulation! Parity-check matrices make it not only easy to implement stabilizer codes in your favorite programming language, they are also a very powerful tools to prove theorems about them, to classify them, to decode them, and more!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/stabilizer-formalism-3/thumbnail.png" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/stabilizer-formalism-3/thumbnail.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The stabilizer trilogy II — Logical operators</title><link href="https://arthurpesah.me/blog/2023-03-16-stabilizer-formalism-2/" rel="alternate" type="text/html" title="The stabilizer trilogy II — Logical operators" /><published>2023-03-16T00:00:00+01:00</published><updated>2023-03-16T00:00:00+01:00</updated><id>https://arthurpesah.me/blog/stabilizer-formalism-2</id><content type="html" xml:base="https://arthurpesah.me/blog/2023-03-16-stabilizer-formalism-2/">&lt;p&gt;Happy to see you back for the second part of the stabilizer trilogy! In the &lt;a href=&quot;/blog/2023-01-31-stabilizer-formalism-1&quot;&gt;previous post&lt;/a&gt;, we defined stabilizer codes and gave a few examples of codes and constructions. In particular, we studied the Steane code, which can be defined by laying down seven qubits on a triangle with three colored faces, each representing an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizer. However, we left pending a few important questions: what are the parameters of the code, and in particular the number of logical qubits and the distance? What logical operations can we apply to this code? How does the decoding process work?&lt;/p&gt;

&lt;p&gt;In this post, we will get down to the nitty-gritty of logical operations. Those are unitary operators acting on the physical qubits, which allow you to go from one part of the codespace to another. For instance, a logical Hadamard lets you go from the logical zero state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_L&lt;/script&gt; to the logical plus state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert + \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert + \rangle_L&lt;/script&gt;. An important class of logical operations are the Pauli logicals, whose properties form a crucial component of stabilizer codes, as they allow to derive the distance of the code, the number of logical qubits, and the main formulation of decoding. Formalizing all those ideas rigorously relies on a fair bit of abstraction, using notions such as centralizers, normalizers, equivalence classes, etc. While we won’t shy away from the abstraction, we will also make every notion as concrete as possible using the Steane code as our running example.&lt;/p&gt;

&lt;p&gt;We will start by showing how to count the number of logical qubits encoded in a stabilizer code. We will then formalize the notion of logical gates in a stabilizer code, and specialize the definition to the case of Pauli operators. Finally, we will see how to understand logical operators in terms of equivalent classes, which will become very handy when trying to understand decoding and topological constructions.&lt;/p&gt;

&lt;h2 id=&quot;logical-qubits&quot;&gt;Logical qubits&lt;/h2&gt;

&lt;p&gt;Before exploring logical operations, let’s first understand how to count the logical qubits of a stabilizer code.
Remember that the number of logical qubits is given by the logarithm of the dimension of the codespace. Indeed, if the codespace has dimension four, any logical state can be written as&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert \psi \rangle_L = a_1 \vert a_1\rangle + a_2 \vert a_2\rangle + a_3 \vert a_3\rangle + a_4 \vert a_4\rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert \psi \rangle_L = a_1 \vert a_1\rangle + a_2 \vert a_2\rangle + a_3 \vert a_3\rangle + a_4 \vert a_4\rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;Relabelling &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert a_1\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert a_1\rangle&lt;/script&gt; as &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 00\rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 00\rangle_L&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert a_2\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert a_2\rangle&lt;/script&gt; as &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 01\rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 01\rangle_L&lt;/script&gt;, etc. shows that the space corresponds to a two-qubit space.&lt;/p&gt;

&lt;p&gt;So what we really need to compute is the dimension of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt; for a stabilizer code.
Let &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; denote the number of physical qubits of our code, and &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; the number of generators of the stabilizer group (i.e. there are &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; independent elements whose products generate the whole group). The dimension of the codespace is then given by&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\text{dim}(\mathcal{C})=2^{n-m}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\text{dim}(\mathcal{C})=2^{n-m}
\end{aligned}&lt;/script&gt;

&lt;p&gt;and the number of logical qubits is therefore &lt;code class=&quot;MathJax_Preview&quot;&gt;k=n-m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=n-m&lt;/script&gt;. This should remind you of classical codes, where the same formula applies when &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; is the number of independent parity checks.&lt;/p&gt;

&lt;p&gt;Intuitively, the argument goes as follow: the dimension of the physical Hilbert space is &lt;code class=&quot;MathJax_Preview&quot;&gt;2^n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^n&lt;/script&gt;, and each independent constraint &lt;code class=&quot;MathJax_Preview&quot;&gt;S_i \vert \psi \rangle = \vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_i \vert \psi \rangle = \vert \psi \rangle&lt;/script&gt; divides this dimension by two. For instance, let’s start with the full space and consider an arbitrary stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;S_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_i&lt;/script&gt;. It has two eigenvalues, &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;, with the same multiplicity (since the trace of a Pauli operator is always zero), dividing the physical Hilbert space into two eigenspaces of equal dimension. We then need to show that the next stabilizer we choose divides this new space into two as well, etc. Let’s prove this rigorously through the following exercise.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;: Let &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}}=\frac{1}{2^m} (1+S_1)\ldots (I+S_m)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}}=\frac{1}{2^m} (1+S_1)\ldots (I+S_m)&lt;/script&gt; &lt;br /&gt;
&lt;strong&gt;(a)&lt;/strong&gt; Show that &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}}&lt;/script&gt; is a projector onto the codespace, that is, &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}} |\psi\rangle=|\psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}} |\psi\rangle=|\psi\rangle&lt;/script&gt; if &lt;code class=&quot;MathJax_Preview&quot;&gt;|\psi\rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;|\psi\rangle \in \mathcal{C}&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}} |\psi\rangle=0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}} |\psi\rangle=0&lt;/script&gt; if &lt;code class=&quot;MathJax_Preview&quot;&gt;|\psi\rangle \in \mathcal{C}^\perp&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;|\psi\rangle \in \mathcal{C}^\perp&lt;/script&gt;. &lt;br /&gt;
&lt;strong&gt;(b)&lt;/strong&gt; Show that we can rewrite this projector as &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}}=\frac{1}{2^m}\sum_{S \in \mathcal{S}} S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}}=\frac{1}{2^m}\sum_{S \in \mathcal{S}} S&lt;/script&gt;, where &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; is the full stabilizer group. &lt;br /&gt;
&lt;strong&gt;(c)&lt;/strong&gt; Show that &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{Tr}[\Pi_\mathcal{C}]=\text{dim}(\mathcal{C})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{Tr}[\Pi_\mathcal{C}]=\text{dim}(\mathcal{C})&lt;/script&gt; &lt;br /&gt;
&lt;strong&gt;(d)&lt;/strong&gt; Deduce that &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{dim}(\mathcal{C})=2^{n-m}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{dim}(\mathcal{C})=2^{n-m}&lt;/script&gt; &lt;br /&gt;
&lt;a href=&quot;#solution-of-the-exercises&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s apply this formula to the Steane code. As a reminder, the Steane code is a &lt;code class=&quot;MathJax_Preview&quot;&gt;7&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;7&lt;/script&gt;-qubit code defined on the following lattice, such that each face (also called &lt;em&gt;plaquette&lt;/em&gt;) supports an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizer generator:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-1/steane-code-lattice.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Therefore, the Steane code has six independent stabilizer generators, three &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquettes and three &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; plaquettes, such that &lt;code class=&quot;MathJax_Preview&quot;&gt;m=6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m=6&lt;/script&gt;. Hence we can see that it encodes &lt;code class=&quot;MathJax_Preview&quot;&gt;k=7-6=1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=7-6=1&lt;/script&gt; logical qubits.&lt;/p&gt;

&lt;h2 id=&quot;logical-gates&quot;&gt;Logical gates&lt;/h2&gt;

&lt;p&gt;Now that we know the number of encoded qubits, what about the distance?
To describe it, we need to introduce the notion of Pauli logical operator, which is a special case of logical gate. A &lt;strong&gt;logical gate&lt;/strong&gt; is a unitary operator &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; that maps the codespace to itself,
i.e. such that &lt;code class=&quot;MathJax_Preview&quot;&gt;L \vert \psi \rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \vert \psi \rangle \in \mathcal{C}&lt;/script&gt; for all &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle \in \mathcal{C}&lt;/script&gt;.
Logical gates therefore include stabilizers, but also operators that map one part of the codespace to another part.
For instance, a logical Hadamard maps the logical zero state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \overline{0} \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \overline{0} \rangle&lt;/script&gt; to the logical plus state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \overline{+} \rangle=\frac{1}{\sqrt{2}} \left(\vert \overline{0} \rangle + \vert \overline{1} \rangle\right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \overline{+} \rangle=\frac{1}{\sqrt{2}} \left(\vert \overline{0} \rangle + \vert \overline{1} \rangle\right)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Another way to understand logical gates is through their actions on the stabilizer group. Indeed, we can prove the following proposition:&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Proposition 1&lt;/strong&gt;: a unitary &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; is a logical gate if and only if it maps the stabilizer group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; to itself, i.e.
&lt;code class=&quot;MathJax_Preview&quot;&gt;L^{\dagger} SL \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^{\dagger} SL \in \mathcal{S}&lt;/script&gt; for all &lt;code class=&quot;MathJax_Preview&quot;&gt;S \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S \in \mathcal{S}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Note that this is precisely the definition of the &lt;strong&gt;normalizer&lt;/strong&gt; of the group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt;, denoted &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{N}(\mathcal{S})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(\mathcal{S})&lt;/script&gt;, and you will often find logical gates defined in the literature as elements of the normalizer of the stabilizer group. This proposition explains why those two definitions are equivalent, and proving it is a cute little exercise that I encourage you to try on your own before reading the solution at the end of this post.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;: Prove Proposition 1 &lt;a href=&quot;#solution-of-the-exercises&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Let’s apply this to the Steane code. For instance, let’s consider the operator &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L=H^{\otimes 7}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L=H^{\otimes 7}&lt;/script&gt; consisting of applying a Hadamard gate on all the physical qubits:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-2/steane-code-hadamard.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;I claim that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt; is a logical gate. To show this, let’s use Proposition 1 and show that it maps stabilizers to stabilizers. Let’s pick an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette, for instance the red one supported on qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;1,2,3,4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1,2,3,4&lt;/script&gt;, that we will call &lt;code class=&quot;MathJax_Preview&quot;&gt;S^X_r&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S^X_r&lt;/script&gt;. Remember that &lt;code class=&quot;MathJax_Preview&quot;&gt;H&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt; turns &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;, that is &lt;code class=&quot;MathJax_Preview&quot;&gt;HXH=Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;HXH=Z&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;HZH=X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;HZH=X&lt;/script&gt;. Therefore:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
H_L S^X_r H_L
&amp;amp;= (H_1 \ldots H_7) X_1 X_2 X_3 X_4 (H_1 \ldots H_7) \\
&amp;amp;= (H_1 X_1 H_1) \ldots (H_4 X_4 H_4) H_5^2 H_6^2 H_7^2 \\
&amp;amp;= Z_1 Z_2 Z_3 Z_4 \\
&amp;amp; = S^Z_r
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
H_L S^X_r H_L
&amp;= (H_1 \ldots H_7) X_1 X_2 X_3 X_4 (H_1 \ldots H_7) \\
&amp;= (H_1 X_1 H_1) \ldots (H_4 X_4 H_4) H_5^2 H_6^2 H_7^2 \\
&amp;= Z_1 Z_2 Z_3 Z_4 \\
&amp; = S^Z_r
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;S^Z_r&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S^Z_r&lt;/script&gt; is the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; red plaquette. Therefore, &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt; maps the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; red plaquette to the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; red plaquette. The same reasoning can be applied to all the other &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; plaquettes, showing that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt; maps stabilizers to stabilizers and is therefore a logical gate.&lt;/p&gt;

&lt;p&gt;Note that we haven’t shown that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt; actually corresponds to a logical Hadamard, i.e. that it maps &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \overline{0} \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \overline{0} \rangle&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \overline{+} \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \overline{+} \rangle&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \overline{1} \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \overline{1} \rangle&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \overline{-} \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \overline{-} \rangle&lt;/script&gt;. The easiest way to show that is by proving that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt; maps the logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operator to the logical &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operator, and vice-versa.
The next step is therefore to get a grasp of the Pauli logical operators. But before that, feel free to try the following exercise to check your understanding of logical gates:&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 3&lt;/strong&gt;: Show that &lt;code class=&quot;MathJax_Preview&quot;&gt;S_L=S^{\otimes 7}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_L=S^{\otimes 7}&lt;/script&gt; is a logical gate &lt;a href=&quot;#solution-of-the-exercises&quot;&gt;(solution)&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;pauli-logicals&quot;&gt;Pauli logicals&lt;/h2&gt;

&lt;p&gt;An important family of logical gates are the &lt;strong&gt;Pauli logical operators&lt;/strong&gt; (often abbreviated &lt;em&gt;logical operators&lt;/em&gt; if the context is clear, or even just &lt;em&gt;logicals&lt;/em&gt;).
As expected, those are the logical gates that belong to the Pauli group.
As two given Pauli operators can either commute or anticommute, Pauli logicals could either commute or anticommute with stabilizers.
However, if a Pauli logical anticommute with a stabilizer, that is &lt;code class=&quot;MathJax_Preview&quot;&gt;SL=-LS&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;SL=-LS&lt;/script&gt;, it means that &lt;code class=&quot;MathJax_Preview&quot;&gt;L^{\dagger} S L = -S \notin \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^{\dagger} S L = -S \notin \mathcal{S}&lt;/script&gt;, which contradicts the characterization of logical gates that we saw above. Therefore, Pauli logicals can be characterized by the following proposition:&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Proposition 2&lt;/strong&gt;: a Pauli operator &lt;code class=&quot;MathJax_Preview&quot;&gt;P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; is a logical operator if and only if it commutes with all the stabilizers&lt;/p&gt;

&lt;p&gt;Note that this is precisely the definition of the &lt;strong&gt;centralizer&lt;/strong&gt; of the group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; in the Pauli group, denoted &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}(\mathcal{S})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}(\mathcal{S})&lt;/script&gt;. The difference between the normalizer and the centralizer is that if &lt;code class=&quot;MathJax_Preview&quot;&gt;L \in \mathcal{N}(\mathcal{S})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \in \mathcal{N}(\mathcal{S})&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;LS=S'L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;LS=S'L&lt;/script&gt; for &lt;code class=&quot;MathJax_Preview&quot;&gt;S, S'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S, S'&lt;/script&gt; two stabilizers, while if &lt;code class=&quot;MathJax_Preview&quot;&gt;L \in \mathcal{C}(\mathcal{S})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \in \mathcal{C}(\mathcal{S})&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;LS=SL&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;LS=SL&lt;/script&gt;. For Pauli operators, &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{N}(\mathcal{S}) = \mathcal{C}(\mathcal{S})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(\mathcal{S}) = \mathcal{C}(\mathcal{S})&lt;/script&gt; and you will often find Pauli logicals defined with either normalizers or centralizers in the literature. Using either this characterization or the original definition, it is easy to show that the set &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{L}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}&lt;/script&gt; of all Pauli logicals from a group, that is, the product of two logicals is itself a logical.&lt;/p&gt;

&lt;p&gt;Finally, let’s define &lt;strong&gt;non-trivial logical operators&lt;/strong&gt; (also known as &lt;strong&gt;logical errors&lt;/strong&gt;) as elements of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}(\mathcal{S}) \backslash \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}(\mathcal{S}) \backslash \mathcal{S}&lt;/script&gt;, or in other words, Pauli operators that commute with all the stabilizers but are not stabilizers themselves. We can now characterize the &lt;strong&gt;distance&lt;/strong&gt; of a stabilizer code as the weight of the smallest logical error:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
d = \min_{L \in \mathcal{C}(\mathcal{S}) \backslash \mathcal{S}} |L|
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
d = \min_{L \in \mathcal{C}(\mathcal{S}) \backslash \mathcal{S}} |L|
\end{aligned}&lt;/script&gt;

&lt;p&gt;As usual, let’s apply what we’ve seen to the Steane code. I claim that the following operators, that we will call &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt;, are non-trivial logical operators of the code:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-2/steane-code-logicals.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;Indeed, it is easy to check that they commute with all the stabilizers, as they share either zero or two qubits with every plaquette. Moreover, by trying all the combinations of stabilizers, you can show that they don’t belong the stabilizer group, and are therefore non-trivial. By using a similar brute-force search, you can also show that they are the smallest non-trivial logical operators, thereby proving that the distance of the Steane code is &lt;code class=&quot;MathJax_Preview&quot;&gt;d=3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=3&lt;/script&gt;. This achieves the proof that the Steane code is a &lt;code class=&quot;MathJax_Preview&quot;&gt;[[7,1,3]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[7,1,3]]&lt;/script&gt; code, as claimed in the previous post.&lt;/p&gt;

&lt;p&gt;However, as discussed in the context of the Hadamard gate, we still haven’t shown that &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt; actually act as logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators on the codespace. For that, we would need to show that &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt; corresponds to a logical bit-flip and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt; to a logical phase-flip, i.e. that they map respectively &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_L&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 1 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 1 \rangle_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert + \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert + \rangle_L&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert - \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert - \rangle_L&lt;/script&gt;. Alternatively, we could show that &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 1 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 1 \rangle_L&lt;/script&gt; are eigenstates of &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt; while &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert + \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert + \rangle_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert - \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert - \rangle_L&lt;/script&gt; are eigenstates of &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;As it happens, this is just a matter of convention. There is no preferred &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_L&lt;/script&gt; state in the codespace, we have the freedom to pick any of the states and decide that it is going to be the zero state. For instance, for the repetition code, we decided that &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_L=\vert 000 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_L=\vert 000 \rangle&lt;/script&gt;, but we could have very much taken &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_L=\vert 111 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_L=\vert 111 \rangle&lt;/script&gt; or even &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_L=\frac{1}{\sqrt{2}} \left(\vert 000 \rangle+\vert 111 \rangle\right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_L=\frac{1}{\sqrt{2}} \left(\vert 000 \rangle+\vert 111 \rangle\right)&lt;/script&gt;, as long as we keep track of it during the computation and when analyzing the measurements.&lt;/p&gt;

&lt;p&gt;Therefore, as it is usually done with stabilizer codes, let’s &lt;strong&gt;define&lt;/strong&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 1 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 1 \rangle_L&lt;/script&gt; as the two eigenstates of &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert + \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert + \rangle_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert - \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert - \rangle_L&lt;/script&gt; as the two eigenstates of &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt;. This is a valid choice since &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_L&lt;/script&gt; anticommute, and this also fixes the logical &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; operator as &lt;code class=&quot;MathJax_Preview&quot;&gt;Y_L=X_LZ_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y_L=X_LZ_L&lt;/script&gt;. All the other logical gates are also fixed by how they transform those Pauli operators. For instance, you are now ready to prove that the logical gate &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt; actually acts as a logical Hadamard gate.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 4&lt;/strong&gt;: Show that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L=H^{\otimes 7}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L=H^{\otimes 7}&lt;/script&gt; acts as a logical Hadamard gate &lt;a href=&quot;#solution-of-exercises&quot;&gt;(solution)&lt;/a&gt;&lt;br /&gt;
&lt;em&gt;(&lt;strong&gt;Hint&lt;/strong&gt;:  show that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L X_L H_L=Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L X_L H_L=Z_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L Z_L H_L=X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L Z_L H_L=X_L&lt;/script&gt;)&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;logical-cosets&quot;&gt;Logical cosets&lt;/h2&gt;

&lt;p&gt;In the previous example, we saw one instance of logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators.
However, there will often be multiple logical operators that act as a given Pauli.
Indeed, take a logical operator &lt;code class=&quot;MathJax_Preview&quot;&gt;L \in \mathcal{L}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \in \mathcal{L}&lt;/script&gt; and a stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;S \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S \in \mathcal{S}&lt;/script&gt;. Then &lt;code class=&quot;MathJax_Preview&quot;&gt;SL=LS&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;SL=LS&lt;/script&gt; is also a logical operator acting in the same way on the codespace:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
L S \vert \psi \rangle = L \vert \psi \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
L S \vert \psi \rangle = L \vert \psi \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;In other words, applying a stabilizer to a logical doesn’t change the way it acts on the codespace. We say that two logicals &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;L'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L'&lt;/script&gt; are &lt;strong&gt;equivalent&lt;/strong&gt; if they only differ by a stabilizer, that is, if there exists &lt;code class=&quot;MathJax_Preview&quot;&gt;S \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S \in \mathcal{S}&lt;/script&gt; such that &lt;code class=&quot;MathJax_Preview&quot;&gt;SL=L'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;SL=L'&lt;/script&gt;. For instance, we have the following three equivalent logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operators in the Steane code:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-2/steane-code-logical-cosets.png&quot; height=&quot;200&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;To go from the first one to the second one, we apply a green &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette. To go from the second one to the last one, we apply a red &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette.&lt;/p&gt;

&lt;p&gt;Since all the equivalent logicals act in the same way on the codespace, it makes sense to group them together in some ways. The notion of equivalence classes is exactly what we need to formalize this idea.&lt;/p&gt;

&lt;p&gt;An &lt;strong&gt;equivalence class&lt;/strong&gt;, or &lt;strong&gt;coset&lt;/strong&gt;, is a set of the form&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\bar{L}=L\mathcal{S}=\{ LS : S \in \mathcal{S} \}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\bar{L}=L\mathcal{S}=\{ LS : S \in \mathcal{S} \}
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;L \in \mathcal{L}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \in \mathcal{L}&lt;/script&gt; is any logical operator.
In other words, a coset is a set of equivalent logicals.
Any element &lt;code class=&quot;MathJax_Preview&quot;&gt;P \in \bar{L}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P \in \bar{L}&lt;/script&gt; is called a &lt;strong&gt;representative&lt;/strong&gt; of the coset &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{L}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{L}&lt;/script&gt;.
For instance, any of the three &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; logicals of the figure above are representative of the coset &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{X}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{X}&lt;/script&gt; of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; logicals. Note that since the Steane code has only one qubit, all the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; logicals are equivalent and there is only one coset of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; logicals.&lt;/p&gt;

&lt;p&gt;Let’s remember a few important properties of equivalence classes. First of all, they &lt;strong&gt;partition&lt;/strong&gt; the set of logical operators, that is, they are all disjoint (i.e. have an empty intersection) and their union is the whole set. In the case of the Steane code, this can be written[^2]:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\mathcal{L}=\bar{I} \cup \bar{X} \cup \bar{Y} \cup \bar{Z}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\mathcal{L}=\bar{I} \cup \bar{X} \cup \bar{Y} \cup \bar{Z}
\end{aligned}&lt;/script&gt;

&lt;p&gt;If we had multiple logical qubits, we would have three different cosets &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{X_i}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{X_i}&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{Y_i}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{Y_i}&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{Z_i}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{Z_i}&lt;/script&gt; for each logical qubit.&lt;/p&gt;

&lt;p&gt;Secondly, the set of all the cosets form a group, which is called the &lt;strong&gt;quotient group&lt;/strong&gt; of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{L}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}&lt;/script&gt; by &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt;, and denoted &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{L} / \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L} / \mathcal{S}&lt;/script&gt;. In this group, the multiplication between two cosets &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{L}_1=L_1 \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{L}_1=L_1 \mathcal{S}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{L}_2=L_2 \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{L}_2=L_2 \mathcal{S}&lt;/script&gt; is defined as &lt;code class=&quot;MathJax_Preview&quot;&gt;L_1 L_2 \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L_1 L_2 \mathcal{S}&lt;/script&gt;, where &lt;code class=&quot;MathJax_Preview&quot;&gt;L_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L_1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;L_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L_2&lt;/script&gt; are two arbitrary representatives of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{L}_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{L}_1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{L}_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{L}_2&lt;/script&gt;. It is a nice exercise to check that the result does not depend on the choice of the two representatives. Moreover, you can check that the identity element of the group is &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{I}=\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{I}=\mathcal{S}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Finally, the quotient group can be generated by all the &lt;code class=&quot;MathJax_Preview&quot;&gt;\bar{X}_i, \bar{Z}_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bar{X}_i, \bar{Z}_i&lt;/script&gt;. This means that the number of logical qubits is exactly half the number of generators of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{L}/\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L}/\mathcal{S}&lt;/script&gt;. This simple fact gives us a different way to count the number of logical qubits of a given stabilizer code, which will become extremely important when discussing topological quantum error correction in future posts.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this post, we have introduced many crucial concepts to understand stabilizer codes. We have defined logical gates as operators that preserve the codespace, or equivalently, the stabilizer space. Those corresponds to elements of the normalizer of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt;. In the specialize case of Pauli operators, we have seen that they correspond to elements of the centralizer, that is, elements that commute with all the stabilizers. We have seen that logical operations are highly degenerate in stabilizer codes, as multiplying a logical operator by a stabilizer gives the same operation on the codespace. We have therefore shown how to group equivalent logicals together within equivalent classes. We have learned how to compute the number of logical qubits in two different ways: either by counting the number &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; of generators of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; and using &lt;code class=&quot;MathJax_Preview&quot;&gt;k=n-m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=n-m&lt;/script&gt;, or by counting the number of generators of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{L} / \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{L} / \mathcal{S}&lt;/script&gt; and dividing by two. Finally, we have seen that the distance can be obtained by finding the minimum-weight logical operator. All those ideas have been illustrated using the Steane code, which we have proven to be a &lt;code class=&quot;MathJax_Preview&quot;&gt;[[7,1,3]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[7,1,3]]&lt;/script&gt;-code.&lt;/p&gt;

&lt;p&gt;In the next and last part of this trilogy, we will see how to formulate the stabilizer formalism in a more concrete way, using parity-check matrices in the binary symplectic format. This format, widely used in numerical implementations of quantum codes, will allow us to switch from group theory to linear algebra. We will express stabilizers and logicals as binary vectors, with commutation relations corresponding to a linear operation on those vectors. Using the notion of logical cosets that we have learned in this post, we will finally be able to formalize the decoding problem for quantum codes.&lt;/p&gt;

&lt;h2 id=&quot;solution-of-the-exercises&quot;&gt;Solution of the exercises&lt;/h2&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;: Let &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}}=\frac{1}{2^m} (I+S_1)\ldots (I+S_m)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}}=\frac{1}{2^m} (I+S_1)\ldots (I+S_m)&lt;/script&gt; &lt;br /&gt;
&lt;strong&gt;(a)&lt;/strong&gt; Show that &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}}&lt;/script&gt; is a projector onto the codespace, that is, &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}} |\psi\rangle=|\psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}} |\psi\rangle=|\psi\rangle&lt;/script&gt; if &lt;code class=&quot;MathJax_Preview&quot;&gt;|\psi\rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;|\psi\rangle \in \mathcal{C}&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}} |\psi\rangle=0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}} |\psi\rangle=0&lt;/script&gt; if &lt;code class=&quot;MathJax_Preview&quot;&gt;|\psi\rangle \in \mathcal{C}^\perp&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;|\psi\rangle \in \mathcal{C}^\perp&lt;/script&gt;. &lt;br /&gt;
&lt;strong&gt;(b)&lt;/strong&gt; Show that we can rewrite this projector as &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}}=\frac{1}{2^m}\sum_{S \in \mathcal{S}} S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}}=\frac{1}{2^m}\sum_{S \in \mathcal{S}} S&lt;/script&gt;, where &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; is the full stabilizer group. &lt;br /&gt;
&lt;strong&gt;(c)&lt;/strong&gt; Show that &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{Tr}[\Pi_\mathcal{C}]=\text{dim}(\mathcal{C})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{Tr}[\Pi_\mathcal{C}]=\text{dim}(\mathcal{C})&lt;/script&gt; &lt;br /&gt;
&lt;strong&gt;(d)&lt;/strong&gt; Deduce that &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{dim}(\mathcal{C})=2^{n-m}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{dim}(\mathcal{C})=2^{n-m}&lt;/script&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;strong&gt;Correction&lt;/strong&gt;:
&lt;strong&gt;(a)&lt;/strong&gt; Let’s show that each operator &lt;code class=&quot;MathJax_Preview&quot;&gt;\frac{1}{2}(I+S_i)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{2}(I+S_i)&lt;/script&gt; is a projector onto the space stabilized by &lt;code class=&quot;MathJax_Preview&quot;&gt;S_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_i&lt;/script&gt;. If &lt;code class=&quot;MathJax_Preview&quot;&gt;|\psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;|\psi\rangle&lt;/script&gt; is stabilized by &lt;code class=&quot;MathJax_Preview&quot;&gt;S_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_i&lt;/script&gt;, we have &lt;code class=&quot;MathJax_Preview&quot;&gt;\frac{1}{2}(I+S_i)|\psi\rangle=\frac{1}{2}|\psi\rangle+\frac{1}{2}S_i|\psi\rangle=\frac{1}{2}|\psi\rangle+\frac{1}{2}|\psi\rangle=|\psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{2}(I+S_i)|\psi\rangle=\frac{1}{2}|\psi\rangle+\frac{1}{2}S_i|\psi\rangle=\frac{1}{2}|\psi\rangle+\frac{1}{2}|\psi\rangle=|\psi\rangle&lt;/script&gt;. If &lt;code class=&quot;MathJax_Preview&quot;&gt;|\psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;|\psi\rangle&lt;/script&gt; is in the orthogonal complement of this space, it means that &lt;code class=&quot;MathJax_Preview&quot;&gt;S_i|\psi\rangle=-|\psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_i|\psi\rangle=-|\psi\rangle&lt;/script&gt;, and therefore &lt;code class=&quot;MathJax_Preview&quot;&gt;\frac{1}{2}(I+S_i)|\psi\rangle=\frac{1}{2}|\psi\rangle+\frac{1}{2}S_i|\psi\rangle=\frac{1}{2}|\psi\rangle-\frac{1}{2}|\psi\rangle=0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{2}(I+S_i)|\psi\rangle=\frac{1}{2}|\psi\rangle+\frac{1}{2}S_i|\psi\rangle=\frac{1}{2}|\psi\rangle-\frac{1}{2}|\psi\rangle=0&lt;/script&gt;. The product of those operators is therefore a projector onto the space stabilized by all the stabilizers. &lt;br /&gt;
&lt;strong&gt;(b)&lt;/strong&gt; There are exactly &lt;code class=&quot;MathJax_Preview&quot;&gt;2^m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^m&lt;/script&gt; elements in the group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt;, each defined by the choice of the generators to include in the stabilizers. This is due to the independence of the generators, meaning that their products always defines a new stabilizer. When developing the expression of &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_\mathcal{C}&lt;/script&gt;, we therefore get all the elements of the stabilizer group exactly once in the sum. &lt;br /&gt;
&lt;strong&gt;(c)&lt;/strong&gt; The eigenvalues of &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}}&lt;/script&gt; are &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt;, with the multiplicity of &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; corresponding to the dimension of the codespace (since &lt;code class=&quot;MathJax_Preview&quot;&gt;\Pi_{\mathcal{C}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\Pi_{\mathcal{C}}&lt;/script&gt; projects onto the codespace). The trace is therefore exactly this dimension. &lt;br /&gt;
&lt;strong&gt;(d)&lt;/strong&gt; Taking the trace on both sides, we get &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{dim}(\mathcal{C})=\frac{1}{2^m}\sum_{S \in \mathcal{S}} \text{Tr}[S]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{dim}(\mathcal{C})=\frac{1}{2^m}\sum_{S \in \mathcal{S}} \text{Tr}[S]&lt;/script&gt;. Since all stabilizers are Paulis, their trace is zero except for the identity element, for which it is &lt;code class=&quot;MathJax_Preview&quot;&gt;2^n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^n&lt;/script&gt; (the total dimension of the space). Therefore, the sum is equal to &lt;code class=&quot;MathJax_Preview&quot;&gt;2^n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^n&lt;/script&gt; and we recover the desired formula.
&lt;br /&gt;
&lt;a href=&quot;#logical-gates&quot;&gt;(Back to section)&lt;/a&gt;&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;: Prove that a unitary &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; is a logical gate if and only if it maps the stabilizer group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt; to itself, i.e.
&lt;code class=&quot;MathJax_Preview&quot;&gt;L^{\dagger} SL \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^{\dagger} SL \in \mathcal{S}&lt;/script&gt; for all &lt;code class=&quot;MathJax_Preview&quot;&gt;S \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S \in \mathcal{S}&lt;/script&gt;.
&lt;br /&gt;&lt;br /&gt;
&lt;strong&gt;Correction&lt;/strong&gt;: For the first direction, let’s suppose that &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; is a logical gate, i.e. &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; maps the codespace to itself.
For &lt;code class=&quot;MathJax_Preview&quot;&gt;S \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S \in \mathcal{S}&lt;/script&gt;, let’s show that &lt;code class=&quot;MathJax_Preview&quot;&gt;LSL^{\dagger} \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;LSL^{\dagger} \in \mathcal{S}&lt;/script&gt;, that is, &lt;code class=&quot;MathJax_Preview&quot;&gt;LSL^{\dagger} \vert \psi \rangle = \vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;LSL^{\dagger} \vert \psi \rangle = \vert \psi \rangle&lt;/script&gt; for all &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle \in \mathcal{C}&lt;/script&gt;. For &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle \in \mathcal{C}&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;L\vert \psi \rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L\vert \psi \rangle \in \mathcal{C}&lt;/script&gt; by assumption, so &lt;code class=&quot;MathJax_Preview&quot;&gt;SL\vert \psi \rangle = L \vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;SL\vert \psi \rangle = L \vert \psi \rangle&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;L^{\dagger} S L \vert \psi \rangle = L^{\dagger} L \vert \psi \rangle = \vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^{\dagger} S L \vert \psi \rangle = L^{\dagger} L \vert \psi \rangle = \vert \psi \rangle&lt;/script&gt;.
For the other direction, let’s suppose that &lt;code class=&quot;MathJax_Preview&quot;&gt;L \in \mathcal{N}(\mathcal{S})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \in \mathcal{N}(\mathcal{S})&lt;/script&gt;, and let’s show that for a state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle \in \mathcal{C}&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;L \vert \psi \rangle \in \mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L \vert \psi \rangle \in \mathcal{C}&lt;/script&gt;. It comes down to showing &lt;code class=&quot;MathJax_Preview&quot;&gt;SL \vert \psi \rangle = L \vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;SL \vert \psi \rangle = L \vert \psi \rangle&lt;/script&gt; for &lt;code class=&quot;MathJax_Preview&quot;&gt;S \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S \in \mathcal{S}&lt;/script&gt;. Since &lt;code class=&quot;MathJax_Preview&quot;&gt;L^{\dagger} S L \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^{\dagger} S L \in \mathcal{S}&lt;/script&gt; by assumption, there exists &lt;code class=&quot;MathJax_Preview&quot;&gt;S' \in \mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S' \in \mathcal{S}&lt;/script&gt; such that &lt;code class=&quot;MathJax_Preview&quot;&gt;L^{\dagger} S L = S'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^{\dagger} S L = S'&lt;/script&gt;, or equivalently, &lt;code class=&quot;MathJax_Preview&quot;&gt;SL = LS'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;SL = LS'&lt;/script&gt;. Therefore, &lt;code class=&quot;MathJax_Preview&quot;&gt;SL\vert \psi \rangle = LS'\vert \psi \rangle = L \vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;SL\vert \psi \rangle = LS'\vert \psi \rangle = L \vert \psi \rangle&lt;/script&gt;.
&lt;br /&gt;
&lt;a href=&quot;#logical-gates&quot;&gt;(Back to section)&lt;/a&gt;&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 3&lt;/strong&gt;: Show that &lt;code class=&quot;MathJax_Preview&quot;&gt;S_L=S^{\otimes 7}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_L=S^{\otimes 7}&lt;/script&gt; is a logical gate
&lt;br /&gt;&lt;br /&gt;
&lt;strong&gt;Correction&lt;/strong&gt;: Remember that the &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; gate turns &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; into itself.
Let’s pick any &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette. Applying &lt;code class=&quot;MathJax_Preview&quot;&gt;S_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_L&lt;/script&gt; turns &lt;code class=&quot;MathJax_Preview&quot;&gt;X^{\otimes 4}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X^{\otimes 4}&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;Y^{\otimes 4}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y^{\otimes 4}&lt;/script&gt;.
Since &lt;code class=&quot;MathJax_Preview&quot;&gt;Y^{\otimes 4}=X^{\otimes 4} Z^{\otimes 4}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y^{\otimes 4}=X^{\otimes 4} Z^{\otimes 4}&lt;/script&gt; (up to a phase), it is a product of stabilizers and therefore a stabilizer itself.
Moreover, &lt;code class=&quot;MathJax_Preview&quot;&gt;S_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_L&lt;/script&gt; leaves &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; plaquettes unchanged.
Thus, &lt;code class=&quot;MathJax_Preview&quot;&gt;S_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S_L&lt;/script&gt; maps stabilizers to stabilizers and forms a logical gate.
&lt;br /&gt;
&lt;a href=&quot;#logical-gates&quot;&gt;(Back to section)&lt;/a&gt;&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 4&lt;/strong&gt;: Show that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L=H^{\otimes 7}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L=H^{\otimes 7}&lt;/script&gt; acts as a logical Hadamard gate&lt;br /&gt;
&lt;em&gt;(&lt;strong&gt;Hint&lt;/strong&gt;:  show that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L X_L H_L=Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L X_L H_L=Z_L&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L Z_L H_L=X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L Z_L H_L=X_L&lt;/script&gt;)&lt;/em&gt;
&lt;br /&gt;&lt;br /&gt;
&lt;strong&gt;Correction&lt;/strong&gt;: Consider the logical &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operator &lt;code class=&quot;MathJax_Preview&quot;&gt;X_L=X^{\otimes 3}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_L=X^{\otimes 3}&lt;/script&gt; acting on qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;5,6,7&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;5,6,7&lt;/script&gt;.
We get &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L X_L H_L = Z^{\otimes 3}=Z_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L X_L H_L = Z^{\otimes 3}=Z_L&lt;/script&gt;.
Using a similar reasoning, we can show that &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L Z_L H_L =X_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L Z_L H_L =X_L&lt;/script&gt;.
Thus, &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt; acts as a logical Hadamard on the codespace.
&lt;br /&gt;
&lt;a href=&quot;#logical-gates&quot;&gt;(Back to section)&lt;/a&gt;&lt;/p&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="quantum-computing" /><summary type="html">Happy to see you back for the second part of the stabilizer trilogy! In the previous post, we defined stabilizer codes and gave a few examples of codes and constructions. In particular, we studied the Steane code, which can be defined by laying down seven qubits on a triangle with three colored faces, each representing an X and a Z stabilizer. However, we left pending a few important questions: what are the parameters of the code, and in particular the number of logical qubits and the distance? What logical operations can we apply to this code? How does the decoding process work?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/stabilizer-formalism-2/thumbnail.png" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/stabilizer-formalism-2/thumbnail.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">The stabilizer trilogy I — Stabilizer codes</title><link href="https://arthurpesah.me/blog/2023-01-31-stabilizer-formalism-1/" rel="alternate" type="text/html" title="The stabilizer trilogy I — Stabilizer codes" /><published>2023-01-31T00:00:00+01:00</published><updated>2023-01-31T00:00:00+01:00</updated><id>https://arthurpesah.me/blog/stabilizer-formalism-1</id><content type="html" xml:base="https://arthurpesah.me/blog/2023-01-31-stabilizer-formalism-1/">&lt;p&gt;Now that you know &lt;a href=&quot;/blog/2022-05-21-classical-error-correction/&quot;&gt;all you need to know about classical error correction&lt;/a&gt;, the time has finally come to learn how to correct those damn errors that keep sabotaging your quantum computer! The key tool, introduced by Daniel Gottesman in &lt;a href=&quot;https://thesis.library.caltech.edu/2900/2/THESIS.pdf&quot;&gt;his landmark 1997 PhD thesis&lt;/a&gt; is the stabilizer formalism.
The same way most classical codes fall into the linear code category, almost all the quantum codes you will encounter can be classified as stabilizer codes. And for a good reason: stabilizer codes are simply the quantum generalization of linear codes!
Your beloved parity checks will turn into stabilizers, a set of commuting measurements controlling the parity of your qubits in different bases.
Parity-check matrices and Tanner graphs will get slightly bigger and more constrained. But apart from that, if you’re more or less comfortable with the notions discussed in the last post, going quantum shouldn’t give you too much trouble.&lt;/p&gt;

&lt;p&gt;So, what’s the plan? To make the content of this post a bit more digestible, I’ve decided to divide it into three parts: the stabilizer trilogy.
In the first part, we will start by motivating the need for the stabilizer formalism, using the quantum repetition code and Shor’s code as examples. We will then be ready to formally define stabilizer codes and one of its most important families, the CSS codes.
To illustrate our construction, we will end the post by introducing a simple code that really exemplifies the stabilizer and CSS construction: the Steane code. Finally, in case you need it, I’ve put some reminders on the manipulation of Pauli operators in the appendix.&lt;/p&gt;

&lt;p&gt;In the second part of this series, we will look more deeply into the properties of stabilizer codes. In particular, we will introduce the notion of logical operator, and see how it can be used to derive the parameters of stabilizer codes. In the last part, we will learn how to generalize parity-check matrices and Tanner graphs to the quantum setting. This formulation can be used to express the decoding problem formally and to implement quantum code simulation in practice.&lt;/p&gt;

&lt;p&gt;This trilogy should give you all you need to start exploring the quantum error correction literature. And with all those tools in our hand, we will finally be ready to study one of the most popular quantum code: the surface code! So hang in there, have a good read, and I assure you the journey will be worth it!&lt;/p&gt;

&lt;h2 id=&quot;motivation-a-new-lens-on-the-quantum-repetition-code&quot;&gt;Motivation: a new lens on the quantum repetition code&lt;/h2&gt;

&lt;p&gt;To understand the challenges in building quantum codes, let’s look back at our good ol’ quantum repetition code (introduced in the &lt;a href=&quot;/blog/2022-01-25-intro-qec-1/&quot;&gt;first post&lt;/a&gt; of this series), with our new error correction knowledge.  As a reminder, the quantum repetition code is defined as the encoding of a single-qubit logical state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle_L = a \vert 0 \rangle_L + b \vert 1 \rangle_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle_L = a \vert 0 \rangle_L + b \vert 1 \rangle_L&lt;/script&gt; as a 3-qubit physical state:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert \psi \rangle = a \vert 000 \rangle + b \vert 111 \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert \psi \rangle = a \vert 000 \rangle + b \vert 111 \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;We define the &lt;strong&gt;codespace&lt;/strong&gt; of our code as the space of all the states that can be written as above (for any &lt;code class=&quot;MathJax_Preview&quot;&gt;a,b&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a,b&lt;/script&gt;).
Let’s see how errors affect the codespace.
As we saw in the first post, quantum noise comes into two flavours: &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors, also known as bit flips, and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors, also known as phase flips.
Let’s focus on &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors first.
If an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error occurs on the first qubit, the state is transformed into&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert \widetilde{\psi} \rangle = X_1 \vert \psi \rangle = a \vert 100 \rangle + b \vert 011 \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert \widetilde{\psi} \rangle = X_1 \vert \psi \rangle = a \vert 100 \rangle + b \vert 011 \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;In the classical repetition code, errors such as this one could be detected by reading the message and seeing that it is neither &lt;code class=&quot;MathJax_Preview&quot;&gt;000&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;000&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;111&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;111&lt;/script&gt;, or in other words, it is not a codeword.
Decoding would then consist of taking a majority vote on the three bits.&lt;/p&gt;

&lt;p&gt;However, in the quantum case, “reading the message” would collapse the state and ruin any further computation we might want to do on this state.
To make error detection work, let’s remember that there is another technique to detect errors on linear codes (including the repetition code), that we saw in the last post: we can look at the parity checks of the code! For the classical repetition codes, those parity checks measured the parity of all the pairs of bits. If some of the checks had an odd parity, it meant that an error had occurred, and depending on which pairs had a violated parity-check equation, we could then decode any single bit-flip error.&lt;/p&gt;

&lt;p&gt;And that’s where the magic comes in: those parity checks can be measured quantumly without collapsing the state!
First, you might wonder what “parity” means for our state, given that we have a superposition of two computational basis elements in the codespace.
However, it’s easy to verify that it is actually well-defined. Consider the state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle&lt;/script&gt; subjected to any number of bit-flip errors. Choose one of the two elements of the superposition. Look at the parity of a pair of qubits. This parity will be the same if you had chosen the other element of the superposition. This is due to the fact that bit flips are always applied simultaneously on both parts of the superposition.&lt;/p&gt;

&lt;p&gt;Now, how do we measure this parity? We can simply measure the observable &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_i Z_j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_i Z_j&lt;/script&gt;.
Indeed, &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle&lt;/script&gt; is an eigenstate of &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_i Z_j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_i Z_j&lt;/script&gt;, and remains so when bit-flip errors are applied to the state.
For instance, &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1 Z_2 \vert \psi \rangle = \vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1 Z_2 \vert \psi \rangle = \vert \psi \rangle&lt;/script&gt;, meaning that measuring &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1 Z_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1 Z_2&lt;/script&gt; on the error-free state will give &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt;.
On the other hand, &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1 Z_2 \vert \widetilde{\psi} \rangle = Z_1 Z_2 X_1 \vert \psi \rangle = - X_1 Z_1 Z_2 \vert \psi \rangle = -\vert \widetilde{\psi} \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1 Z_2 \vert \widetilde{\psi} \rangle = Z_1 Z_2 X_1 \vert \psi \rangle = - X_1 Z_1 Z_2 \vert \psi \rangle = -\vert \widetilde{\psi} \rangle&lt;/script&gt;, so measuring this operator when a bit-flip has occurred on the first qubit gives &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt; (if this manipulation of Pauli operators is not straightforward to you, feel free to read the &lt;a href=&quot;2023-01-21-stabilizer-formalism-1/#appendix-handling-pauli-operators-with-ease&quot;&gt;Appendix&lt;/a&gt; on Pauli operators and come back).
Checking those calculations on your own, and for other examples of bit-flip errors, should convince you that measuring &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_i Z_j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_i Z_j&lt;/script&gt; gives you exactly the parity between the qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;. In general, the result of measuring those operators is exactly like the syndrome we introduced in the previous post: we get &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; when a parity-check equation is satisfied, and &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt; when it is not. As an example of how to measure those parity checks, the circuit to measure &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1 Z_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1 Z_2&lt;/script&gt; is given below:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/stabilizer-formalism-1/repetition-code-circuit.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So, what have we done so far? We have found a set of operators &lt;code class=&quot;MathJax_Preview&quot;&gt;\{Z_i Z_j\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{Z_i Z_j\}&lt;/script&gt; such that:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Our error-free state is a simultaneous &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; eigenstate of all those operators&lt;/li&gt;
  &lt;li&gt;Single and two-qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors anti-commute with some of them, allowing the detection and correction of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We will soon call those operators “stabilizers”, and study their general properties.
But first—you might have been wondering all this time—what about &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors?
As it happens, they are actually undetectable by our code.
For instance, if a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error were to occur on the first qubit of the state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle&lt;/script&gt;, we would get the state&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert \widetilde{\psi} \rangle = Z_1 \vert \psi \rangle = a \vert 000 \rangle - b \vert 111 \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert \widetilde{\psi} \rangle = Z_1 \vert \psi \rangle = a \vert 000 \rangle - b \vert 111 \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;This is still in the codespace of our code! Therefore, we have no way to detect this error:
&lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors are &lt;strong&gt;logical errors&lt;/strong&gt;.
We define the &lt;strong&gt;distance&lt;/strong&gt; of a code as the smallest Pauli error that maps the codespace to itself,
or in other words, the smallest logical error. Since a single &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error in the quantum repetition code
is undetectable, it means that the distance of the code is &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;.
Denoting &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; the number of physical qubits of a code, &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; the number of logical qubits it encodes,
and &lt;code class=&quot;MathJax_Preview&quot;&gt;d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; its distance, we say that the repetition code is an &lt;code class=&quot;MathJax_Preview&quot;&gt;[[n,k,d]]=[[n,1,1]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[n,k,d]]=[[n,1,1]]&lt;/script&gt;-code.
Note the use of double brackets, a common convention used to distinguish quantum from classical codes.&lt;/p&gt;

&lt;p&gt;So what do we do from there? Taking inspiration from the quantum repetition code, let’s try to build
our first code that can detect both &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors: Shor’s code.&lt;/p&gt;

&lt;h2 id=&quot;our-first-truly-quantum-code-shors-code&quot;&gt;Our first truly quantum code: Shor’s code&lt;/h2&gt;

&lt;p&gt;To understand the idea behind Shor’s code, let’s first see how we could design a repetition code that only protects information against &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors, instead of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors. Can you see what modification of the repetition code would be required?&lt;/p&gt;

&lt;p&gt;The idea is to simply use a different basis for the codewords. Indeed, replacing &lt;code class=&quot;MathJax_Preview&quot;&gt;\{\vert 000\rangle, \vert 111\rangle\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{\vert 000\rangle, \vert 111\rangle\}&lt;/script&gt; by &lt;code class=&quot;MathJax_Preview&quot;&gt;\{\vert +++\rangle, \vert ---\rangle\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{\vert +++\rangle, \vert ---\rangle\}&lt;/script&gt;, and the parity-check measurements &lt;code class=&quot;MathJax_Preview&quot;&gt;\{Z_i Z_j\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{Z_i Z_j\}&lt;/script&gt; by &lt;code class=&quot;MathJax_Preview&quot;&gt;\{X_i X_j\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{X_i X_j\}&lt;/script&gt;, we obtain a code that can correct any single-qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error.&lt;/p&gt;

&lt;p&gt;The trick found by Peter Shor is to combine those two codes using a process called &lt;strong&gt;concatenation&lt;/strong&gt;. It consists of encoding the logical qubits of one code using a second code. In our case, we can encode the logical qubits of the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;-basis repetition code into the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt;-basis repetition code. This defines the 9-qubit Shor’s code, made of the following codewords&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert 0 \rangle_{L_2} = \vert + \rangle_{L_1} \otimes \vert + \rangle_{L_1} \otimes \vert + \rangle_{L_1} = \frac{1}{2^{3/2}} \left(\vert 000 \rangle + \vert 111 \rangle \right) \left(\vert 000 \rangle + \vert 111 \rangle \right) \left(\vert 000 \rangle + \vert 111 \rangle \right) \\
\vert 1 \rangle_{L_2} = \vert - \rangle_{L_1} \otimes \vert - \rangle_{L_1} \otimes \vert - \rangle_{L_1} = \frac{1}{2^{3/2}} \left(\vert 000 \rangle - \vert 111 \rangle \right) \left(\vert 000 \rangle - \vert 111 \rangle \right) \left(\vert 000 \rangle - \vert 111 \rangle \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert 0 \rangle_{L_2} = \vert + \rangle_{L_1} \otimes \vert + \rangle_{L_1} \otimes \vert + \rangle_{L_1} = \frac{1}{2^{3/2}} \left(\vert 000 \rangle + \vert 111 \rangle \right) \left(\vert 000 \rangle + \vert 111 \rangle \right) \left(\vert 000 \rangle + \vert 111 \rangle \right) \\
\vert 1 \rangle_{L_2} = \vert - \rangle_{L_1} \otimes \vert - \rangle_{L_1} \otimes \vert - \rangle_{L_1} = \frac{1}{2^{3/2}} \left(\vert 000 \rangle - \vert 111 \rangle \right) \left(\vert 000 \rangle - \vert 111 \rangle \right) \left(\vert 000 \rangle - \vert 111 \rangle \right)
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \cdot \rangle_{L_1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \cdot \rangle_{L_1}&lt;/script&gt; refers to logical qubits after the first encoding, for which &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_{L_1}=\vert 000 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_{L_1}=\vert 000 \rangle&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \cdot \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \cdot \rangle_{L_2}&lt;/script&gt; refers to logical qubits after the second encoding, for which &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_{L_2}=\vert +++ \rangle_{L_1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_{L_2}=\vert +++ \rangle_{L_1}&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Now, if an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error occurs on any of the 9 qubits, we will be able to correct it by measuring &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_i Z_{j}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_i Z_{j}&lt;/script&gt; on all the qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; of the same block. Indeed, you can check that in the absence of error, we have&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
Z_i Z_j \vert \psi \rangle_{L_2} = \vert \psi \rangle_{L_2}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
Z_i Z_j \vert \psi \rangle_{L_2} = \vert \psi \rangle_{L_2}
\end{aligned}&lt;/script&gt;

&lt;p&gt;with &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle_{L_2} = a \vert 0 \rangle_{L_2} + b \vert 1 \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle_{L_2} = a \vert 0 \rangle_{L_2} + b \vert 1 \rangle_{L_2}&lt;/script&gt;.
This means that measuring those operators will give the result &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;On the other hand, let’s say we have an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error on the fourth qubit of the logical zero state. It would result in the state:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
X_4 \vert 0 \rangle_{L_2} = \frac{1}{2^{3/2}} \left(\vert 000 \rangle + \vert 111 \rangle \right) \left(\vert 100 \rangle + \vert 011 \rangle \right) \left(\vert 000 \rangle + \vert 111 \rangle \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
X_4 \vert 0 \rangle_{L_2} = \frac{1}{2^{3/2}} \left(\vert 000 \rangle + \vert 111 \rangle \right) \left(\vert 100 \rangle + \vert 011 \rangle \right) \left(\vert 000 \rangle + \vert 111 \rangle \right)
\end{aligned}&lt;/script&gt;

&lt;p&gt;The odd parity between qubit 4 and qubits 5 and 6, detected by measuring &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4 Z_5&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4 Z_5&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_5 Z_6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_5 Z_6&lt;/script&gt;, tells us that the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error occurred on qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;4&lt;/script&gt;. We can therefore correct this error, and more generally any other single-qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error, by analyzing the result of the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_i Z_j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_i Z_j&lt;/script&gt; measurements.&lt;/p&gt;

&lt;p&gt;Let’s now focus our attention to &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors. Let’s remember that for the Z-basis repetition code, the operator &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X}=XXX&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X}=XXX&lt;/script&gt; is a logical Pauli &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operator, turning &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_{L_1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_{L_1}&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 1 \rangle_{L_1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 1 \rangle_{L_1}&lt;/script&gt;. Let’s write &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_1}=X_1 X_2 X_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_1}=X_1 X_2 X_3&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_2}=X_4 X_5 X_6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_2}=X_4 X_5 X_6&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_3}=X_7 X_8 X_9&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_3}=X_7 X_8 X_9&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;To detect &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors, we can measure the parity &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X}_i \overline{X}_{j}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X}_i \overline{X}_{j}&lt;/script&gt; for all &lt;code class=&quot;MathJax_Preview&quot;&gt;i,j \in \{1,2,3\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i,j \in \{1,2,3\}&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;i \neq j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i \neq j&lt;/script&gt;. Indeed, you can verify explicitly that we have&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\overline{X_i} \overline{X_j} \vert \psi \rangle_{L_2} = \vert \psi \rangle_{L_2}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\overline{X_i} \overline{X_j} \vert \psi \rangle_{L_2} = \vert \psi \rangle_{L_2}
\end{aligned}&lt;/script&gt;

&lt;p&gt;for all &lt;code class=&quot;MathJax_Preview&quot;&gt;i,j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i,j&lt;/script&gt;. Moreover, if a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error occurs, for example on the fourth qubit of the logical zero state, we would get:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
Z_4 \vert 0 \rangle_{L_2} = \vert +-+ \rangle_{L_1} = \frac{1}{2^{3/2}} \left(\vert 000 \rangle + \vert 111 \rangle \right) \left(\vert 000 \rangle - \vert 111 \rangle \right) \left(\vert 000 \rangle + \vert 111 \rangle \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
Z_4 \vert 0 \rangle_{L_2} = \vert +-+ \rangle_{L_1} = \frac{1}{2^{3/2}} \left(\vert 000 \rangle + \vert 111 \rangle \right) \left(\vert 000 \rangle - \vert 111 \rangle \right) \left(\vert 000 \rangle + \vert 111 \rangle \right)
\end{aligned}&lt;/script&gt;

&lt;p&gt;The odd parity between blocks &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt; and blocks &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt; can be detected using the operator &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_1} \overline{X_2} = X_1 X_2 X_3 X_4 X_5 X_6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_1} \overline{X_2} = X_1 X_2 X_3 X_4 X_5 X_6&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_2} \overline{X_3} = X_4 X_5 X_6 X_7 X_8 X_9&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_2} \overline{X_3} = X_4 X_5 X_6 X_7 X_8 X_9&lt;/script&gt;. You can check that explicitly by applying those operators to &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4 \vert 0 \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4 \vert 0 \rangle_{L_2}&lt;/script&gt; and showing for instance that&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\overline{X_1} \overline{X_2} Z_4 \vert 0 \rangle_{L_2} = - Z_4 \vert 0 \rangle_{L_2}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\overline{X_1} \overline{X_2} Z_4 \vert 0 \rangle_{L_2} = - Z_4 \vert 0 \rangle_{L_2}
\end{aligned}&lt;/script&gt;

&lt;p&gt;meaning that the result of measuring &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_1} \overline{X_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_1} \overline{X_2}&lt;/script&gt; will be &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;. Similarly, the result of measuring &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X_2} \overline{X_3}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X_2} \overline{X_3}&lt;/script&gt; will be &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;. However, note that we would have obtained the exact same measurement result if the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error had occurred on qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;5&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;5&lt;/script&gt; or qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;6&lt;/script&gt;. That’s our first example of &lt;strong&gt;error degeneracy&lt;/strong&gt;: different errors causing the same syndrome. How do we decide where to apply our correction then? The answer is that it doesn’t matter: we can choose either of the three middle qubits. To see why, let’s look at what happens if we apply &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_5&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_5&lt;/script&gt; to a state affected by the error &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4&lt;/script&gt;:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
Z_5 Z_4 \vert \psi \rangle_{L_2} = \vert \psi \rangle_{L_2}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
Z_5 Z_4 \vert \psi \rangle_{L_2} = \vert \psi \rangle_{L_2}
\end{aligned}&lt;/script&gt;

&lt;p&gt;It gets us back to the original state! The reason is that any state in the codespace is a +1 eigenstate of &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_5 Z_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_5 Z_4&lt;/script&gt; (as we saw when looking at &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error detection). The same phenomenon would have happened if we had applied &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_6&lt;/script&gt;, and therefore we can correct the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4&lt;/script&gt; error by applying a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operator on any of the three middle qubits. More generally, any single-qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error can be corrected by analyzing the result of the &lt;code class=&quot;MathJax_Preview&quot;&gt;\overline{X}_i \overline{X}_{j}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\overline{X}_i \overline{X}_{j}&lt;/script&gt; measurements. This trick for dealing with error degeneracies is preponderant in quantum error correction, and we will see the most general version of it when looking at decoding stabilizer codes (in the next post).&lt;/p&gt;

&lt;p&gt;So our code is able to detect and correct any single-qubit error. But what about errors of higher weight? Or in other words, what is the distance of Shor’s code (i.e. the smallest undetectable errors)? Since this is a perfect exercise to see if you’ve understood this code, I leave this question as an exercise!&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: show that Shor’s code has a distance of &lt;code class=&quot;MathJax_Preview&quot;&gt;d=3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=3&lt;/script&gt;. &lt;br /&gt;
&lt;em&gt;(&lt;strong&gt;Hint&lt;/strong&gt;: find a weight-3 error, made of either &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; elements, that applies a bit-flip or phase-flip to the logical state of the code)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In summary, we have found a &lt;code class=&quot;MathJax_Preview&quot;&gt;[[9,1,3]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[9,1,3]]&lt;/script&gt; quantum code that can detect both &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors by measuring a set of operators &lt;code class=&quot;MathJax_Preview&quot;&gt;\{ Z_i Z_j \}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{ Z_i Z_j \}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\{\overline{X_i} \overline{X_j} \}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{\overline{X_i} \overline{X_j} \}&lt;/script&gt;. This means that error-free states (i.e. codewords) are a common &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; eigenstate of those operators, while states subjected to weight-1 and weight-2 errors are &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt; eigenstates of some of those operators, allowing us to detect those errors. With this example in mind, we are now finally ready to delve into the stabilizer formalism!&lt;/p&gt;

&lt;h2 id=&quot;stabilizer-formalism-first-definitions&quot;&gt;Stabilizer formalism: first definitions&lt;/h2&gt;

&lt;p&gt;The stabilizer formalism allows us to generalize the ideas above in order to come up with new quantum codes and study their properties. The main idea is to change our perspective from states (or codewords) to operators, similarly to the way we defined classical linear codes using parity-check matrices. But generalizing parity-check operators in the quantum setting requires a bit of care. Let’s see how it works.&lt;/p&gt;

&lt;p&gt;First, let me outline the general idea of this section.
As we saw with Shor’s code, errors in a quantum code can be detected by measuring a certain set of operators, generalizing the parity checks of classical codes.
Those operators are called &lt;strong&gt;stabilizers&lt;/strong&gt; and have a certain number of properties: they have eigenvalues &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;, they all commute (the order of measurement doesn’t matter), etc.
Moreover, any codeword is a common &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; eigenstate of all the stabilizers, i.e. measuring any stabilizer on an error-free state gives the value &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; and does not disturb the state.&lt;/p&gt;

&lt;p&gt;The goal is to go backward: given any set of stabilizers, does it define a code?
As found out by Daniel Gottesman, the answer is yes, and this simple fact has been foundational for quantum error correction, allowing us to find codes by searching for stabilizers with good properties.
Let us now introduce the formalism behind this brilliant idea.&lt;/p&gt;

&lt;p&gt;The n-qubit &lt;strong&gt;Pauli group&lt;/strong&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{P}_n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{P}_n&lt;/script&gt; is the set of all Pauli operators on &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; qubits, with the usual matrix multiplication as the group operation, that is:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\mathcal{P}_n=\{ \omega P_1 \otimes \ldots \otimes P_n : P_i \in \{I,X,Y,Z \}, \omega \in \{1,-1,i,-i\}\}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\mathcal{P}_n=\{ \omega P_1 \otimes \ldots \otimes P_n : P_i \in \{I,X,Y,Z \}, \omega \in \{1,-1,i,-i\}\}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Note that the phase factor is included in order for this set to be close under the group operation.&lt;/p&gt;

&lt;p&gt;We can now define a &lt;strong&gt;stabilizer group&lt;/strong&gt; as an abelian subgroup of the Pauli group that does not contain &lt;code class=&quot;MathJax_Preview&quot;&gt;-I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-I&lt;/script&gt;.
Let’s slowly break that down.
First, the stabilizer group is a subgroup of the Pauli group, meaning that every element is a Pauli operator, and has in consequence eigenvalues &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;. It is a group, meaning that the product of any two stabilizers is also a stabilizer.
This group is abelian, meaning that any two stabilizers commute, and can therefore be measured in any order.
Finally, we don’t want &lt;code class=&quot;MathJax_Preview&quot;&gt;-I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-I&lt;/script&gt; to be included, or equivalently we don’t want any two operators &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;-S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-S&lt;/script&gt; to be in the same stabilizer group, as it will make sense shortly.&lt;/p&gt;

&lt;p&gt;We can now define a &lt;strong&gt;stabilizer code&lt;/strong&gt; as the common &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; eigenspace of all the operators in a stabilizer group.
That is, given a stabilizer group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}&lt;/script&gt;, we define the codespace of a stabilizer code as:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\mathcal{C}=\{ \vert \psi \rangle : S\vert \psi \rangle = \vert \psi \rangle, \forall S \in \mathcal{S} \}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\mathcal{C}=\{ \vert \psi \rangle : S\vert \psi \rangle = \vert \psi \rangle, \forall S \in \mathcal{S} \}
\end{aligned}&lt;/script&gt;

&lt;p&gt;This set is well-defined, since by definition all the stabilizers commute, and have therefore some common eigenstates.
Moreover, each stabilizer has at least one &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; eigenvalue (remember that &lt;code class=&quot;MathJax_Preview&quot;&gt;-I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-I&lt;/script&gt; is not included in the stabilizer group), so there is a common &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; eigenstate of all the stabilizers. Finally, you can notice that &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt; forms a vector space, and therefore defines a valid code.&lt;/p&gt;

&lt;p&gt;This one-to-one correspondence between codespaces defined as above and stabilizer groups is the foundation of quantum error correction: instead of the thinking of codes in the state picture (as a vector space of states), we can now think of them in the operator picture (as a stabilizer group). For instance, Shor’s code can either be defined in the state picture, as the codespace &lt;code class=&quot;MathJax_Preview&quot;&gt;\{a \vert 0 \rangle_{L_2} + b \vert 1 \rangle_{L_2} \}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\{a \vert 0 \rangle_{L_2} + b \vert 1 \rangle_{L_2} \}&lt;/script&gt; (with &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_{L_2}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 1 \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 1 \rangle_{L_2}&lt;/script&gt; defined in the previous section), or in the operator picture, as the codespace stabilized by &lt;code class=&quot;MathJax_Preview&quot;&gt;\langle Z_i Z_j, \overline{X_i} \overline{X_j} \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\langle Z_i Z_j, \overline{X_i} \overline{X_j} \rangle&lt;/script&gt; with &lt;code class=&quot;MathJax_Preview&quot;&gt;i,j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i,j&lt;/script&gt; neighboring physical/logical qubits.&lt;/p&gt;

&lt;p&gt;Last but not least, how can we detect and correct errors with a stabilizer code? As we saw with the repetition code and Shor’s code, the idea is to simply measure all the stabilizers, resulting in what is called the &lt;strong&gt;syndrome&lt;/strong&gt;. If no error has occurred, the syndrome should consist of &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; for all the stabilizers. If a Pauli error &lt;code class=&quot;MathJax_Preview&quot;&gt;E&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;E&lt;/script&gt; has occurred, there are two possibilities for each stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt;: either it commutes or it anticommutes with it. If it commutes, we will measure &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt;:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
SE \vert \psi \rangle = ES \vert \psi \rangle = E \vert \psi \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
SE \vert \psi \rangle = ES \vert \psi \rangle = E \vert \psi \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;If it anticommutes, we will measure &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
SE \vert \psi \rangle = - ES \vert \psi \rangle = - E \vert \psi \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
SE \vert \psi \rangle = - ES \vert \psi \rangle = - E \vert \psi \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;To detect &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors, we therefore need stabilizers with some &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; operators, while to detect &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors, we need stabilizers with some &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Y&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y&lt;/script&gt; operators.&lt;/p&gt;

&lt;p&gt;By analyzing the syndrome, it is often possible to correct errors as well. However, one specificity of quantum codes is that we often don’t need to find the exact qubits on which the errors have occurred. What we need is to find a correction operator &lt;code class=&quot;MathJax_Preview&quot;&gt;C&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C&lt;/script&gt; that restores our state, that is:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
C E \vert \psi \rangle = \vert \psi \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
C E \vert \psi \rangle = \vert \psi \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;In other words, we want &lt;code class=&quot;MathJax_Preview&quot;&gt;C E&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C E&lt;/script&gt; to be a stabilizer. For instance, in Shor’s code, we saw that if the error &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4&lt;/script&gt; occurs, we can correct it by using either &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_5&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_5&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_6&lt;/script&gt; as our correction operator. This was due to &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4 Z_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4 Z_4&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4 Z_5&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4 Z_5&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_4 Z_6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_4 Z_6&lt;/script&gt; being stabilizers. Finding the best correction operator is the essence of the &lt;strong&gt;decoding problem&lt;/strong&gt;, which we will see in more details in the next post.&lt;/p&gt;

&lt;p&gt;So what have we done so far? We have shown that given a stabilizer group, that is a set of commuting Pauli operators that does not contain &lt;code class=&quot;MathJax_Preview&quot;&gt;-I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-I&lt;/script&gt;, we can construct a quantum code by considering the common +1 eigenspace of all the stabilizers.
When errors occur in this code, moving the state outside of the codespace, they can be detected (and sometimes corrected) by measuring all the stabilizers and checking if some measurements are equal to &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;However, we haven’t yet given any method to construct interesting stabilizer groups. The next section introduces one of the most important family of stabilizer codes, the CSS codes, which will help us to build a new example of quantum code: the quantum version of the Hamming code.&lt;/p&gt;

&lt;h2 id=&quot;quantum-codes-from-classical-codes-the-css-construction&quot;&gt;Quantum codes from classical codes: the CSS construction&lt;/h2&gt;

&lt;p&gt;So, how can we construct stabilizer codes? One method is to start from two classical codes: one that will take care of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors and one that will take care of &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors. As we saw in the previous section, to correct &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; errors, we can use stabilizers made of &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators, and to correct &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors, we can use stabilizers made of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operators.&lt;/p&gt;

&lt;p&gt;The idea is therefore the following: let’s pick two classical codes that we will call &lt;code class=&quot;MathJax_Preview&quot;&gt;C_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;C_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_Z&lt;/script&gt;. For each parity check of &lt;code class=&quot;MathJax_Preview&quot;&gt;C_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_X&lt;/script&gt;, supported on bits &lt;code class=&quot;MathJax_Preview&quot;&gt;b_1,\ldots,b_k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;b_1,\ldots,b_k&lt;/script&gt;, add the stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;X_{b_1} \ldots X_{b_k}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_{b_1} \ldots X_{b_k}&lt;/script&gt; to the stabilizer group. Similarly, for each parity check of &lt;code class=&quot;MathJax_Preview&quot;&gt;C_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_Z&lt;/script&gt;, supported on bits &lt;code class=&quot;MathJax_Preview&quot;&gt;b'_1,\ldots,b'_k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;b'_1,\ldots,b'_k&lt;/script&gt;, add the stabilizer &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_{b'_1} \ldots Z_{b'_k}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_{b'_1} \ldots Z_{b'_k}&lt;/script&gt; to the stabilizer group.
For the resulting quantum code to be valid, remember that all the stabilizers should commute. While stabilizers of the same Pauli type necessarily commute, it is not obvious that all the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers commute with all the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizers. For this to be the case, each &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; stabilizer should intersect on an even number of qubits with all the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers (see &lt;a href=&quot;2023-01-21-stabilizer-formalism-1/#appendix-handling-pauli-operators-with-ease&quot;&gt;Appendix&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;If this is the case, the resulting quantum code is valid and form what is called a Calderbank-Shor-Steane (CSS) code. More precisely, a &lt;strong&gt;CSS code&lt;/strong&gt; is a stabilizer code that can be generated by a set of pure &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and pure &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers. For instance, both codes that we have encountered before, Shor’s code and the quantum repetition code, are examples of CSS codes. And so are most of the codes that you will encounter in the literature, making CSS codes one of the most important family of codes.&lt;/p&gt;

&lt;p&gt;However, if you try the construction above with some random codes &lt;code class=&quot;MathJax_Preview&quot;&gt;C_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;C_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_Z&lt;/script&gt; taken from the classical literature, you will find that it is very difficult to pass the commutation criterion. Therefore, more involved methods are needed to construct quantum codes, such as topological constructions or hypergraph products. However, there is on example where our procedure works extremely well: our good old Hamming code!&lt;/p&gt;

&lt;h2 id=&quot;steane-code-the-quantum-version-of-the-hamming-code&quot;&gt;Steane code, the quantum version of the Hamming code&lt;/h2&gt;

&lt;p&gt;It’s finally time to illustrate the stabilizer formalism with a concrete example!
If the two previous sections were feeling a bit abstract, this section should hopefully clarify things.&lt;/p&gt;

&lt;p&gt;So let’s apply the CSS construction to the Hamming code that we introduced in the &lt;a href=&quot;/blog/2022-05-21-classical-error-correction/&quot;&gt;previous blog post&lt;/a&gt;. As a reminder, the Hamming code is a &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4,3]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4,3]&lt;/script&gt;-code defined by the following three parity check equations&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    x_1 + x_2 + x_3 + x_4 = 0 \\
    x_2 + x_3 + x_5 + x_6 = 0 \\
    x_3 + x_4 + x_6 + x_7 = 0
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    x_1 + x_2 + x_3 + x_4 = 0 \\
    x_2 + x_3 + x_5 + x_6 = 0 \\
    x_3 + x_4 + x_6 + x_7 = 0
\end{aligned}&lt;/script&gt;

&lt;p&gt;Let’s now apply the CSS construction with &lt;code class=&quot;MathJax_Preview&quot;&gt;C_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;C_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_Z&lt;/script&gt; two Hamming codes. To &lt;code class=&quot;MathJax_Preview&quot;&gt;C_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_X&lt;/script&gt;, we associate the group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}_X&lt;/script&gt; on 7 qubits defined as:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \mathcal{S}_X = \langle X_1 X_2 X_3 X_4, X_2 X_3 X_5 X_6, X_3 X_4 X_6 X_7 \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \mathcal{S}_X = \langle X_1 X_2 X_3 X_4, X_2 X_3 X_5 X_6, X_3 X_4 X_6 X_7 \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;and to &lt;code class=&quot;MathJax_Preview&quot;&gt;C_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;C_Z&lt;/script&gt;, the group &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}_Z&lt;/script&gt; defined as:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \mathcal{S}_Z = \langle Z_1 Z_2 Z_3 Z_4, Z_2 Z_3 Z_5 Z_6, Z_3 Z_4 Z_6 Z_7 \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \mathcal{S}_Z = \langle Z_1 Z_2 Z_3 Z_4, Z_2 Z_3 Z_5 Z_6, Z_3 Z_4 Z_6 Z_7 \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;It is often convenient to visualize stabilizer codes using some graphical representations. Here is how to visualize the stabilizers defined above:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-1/steane-code-lattice.png&quot; height=&quot;300&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;In this figure, each vertex (numbered from 1 to 7) represents a qubit, and each coloured face (often called &lt;strong&gt;plaquette&lt;/strong&gt; in the literature) supports an &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizer. The different plaquette stabilizers are shown explicitly here:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/stabilizer-formalism-1/steane-code-stabilizers.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From this representation, it is easy to see that each plaquette stabilizer intersects with every other plaquette stabilizers on exactly two qubits, which is an even number. As we discussed earlier, it means that elements of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}_X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}_X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{S}_Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{S}_Z&lt;/script&gt; commute, and we can form a valid code by combining the generators of the two groups. The resulting code is called the &lt;strong&gt;Steane code&lt;/strong&gt;, and is an example of &lt;strong&gt;color code&lt;/strong&gt; (a very interesting family of codes which would deserve their own blog post).&lt;/p&gt;

&lt;p&gt;The Steane code is often considered a promising candidate for near-term quantum error correction and is indeed one of the first codes to have been implemented on a real device (by different teams of ion trappers) &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. This is due to its many nice properties: its small size (it only requires &lt;code class=&quot;MathJax_Preview&quot;&gt;7&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;7&lt;/script&gt; physical qubits), its 2D locality (it can be built on a 2D lattice without requiring long-range connections to measure the stabilizers), and the presence of many transversal logical gates (a topic for another time). Furthermore, it only requires the measurement of weight-4 stabilizers, as opposed to Shor’s code which requires measuring weight-6 stabilizers. Since errors can happen during the measurement of stabilizers, a good rule of thumb to get well-performing quantum codes is to always try to minimize the weight of its stabilizer generators.&lt;/p&gt;

&lt;p&gt;We will study the characteristics of the Steane code in the next post, showing that it is a &lt;code class=&quot;MathJax_Preview&quot;&gt;[[7,1,3]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[7,1,3]]&lt;/script&gt; quantum code. Meanwhile, we can already look at what happens in the presence of single-qubit errors. Since &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors are detected in the same way (using either &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; stabilizers on the plaquettes), we can consider the effect of &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors only, without loss of generality. Below is the observed syndrome for a single &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error on qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt;:&lt;/p&gt;

&lt;p style=&quot;text-align:center;&quot; class=&quot;figure&quot;&gt;
    &lt;img src=&quot;/assets/img/blog/stabilizer-formalism-1/steane-code-errors.png&quot; /&gt;
&lt;/p&gt;

&lt;p&gt;In this figure, the purple vertices correspond to &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors, and the highlighted plaquettes to stabilizer measurements of &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;.
To obtain this this result, note that a single-qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error will always anticommute with the &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; plaquette it touches (you can easily show this using the property of the appendix).&lt;/p&gt;

&lt;p&gt;You can continue this exercise with the remaining single-qubit errors, and you will see that they all lead to a different syndrome.
Therefore, the Steane code can correct any single-qubit error.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this post, we have introduced the most important tool to build and analyze quantum codes: the stabilizer formalism. Starting from a stabilizer group (set of commuting Pauli operators), we found that we can construct a codespace by considering the common &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; eigenspace of its elements. We defined the family of CSS codes, whose stabilizer generators can be split into pure &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and pure &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; elements. We studied a few examples of stabilizer codes: the &lt;code class=&quot;MathJax_Preview&quot;&gt;[[3,1,1]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[3,1,1]]&lt;/script&gt; repetition code, the &lt;code class=&quot;MathJax_Preview&quot;&gt;[[9,1,3]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[9,1,3]]&lt;/script&gt; Shor code, and the &lt;code class=&quot;MathJax_Preview&quot;&gt;[[7,1,3]]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[[7,1,3]]&lt;/script&gt; Steane code.&lt;/p&gt;

&lt;p&gt;In the next post, we will go further in our study of stabilizer codes: we will learn how to find the logical operators, the distance and the number of encoded qubits of a code. The Steane code will continue to serve as our main example throughout the next post.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Acknowledgment&lt;/strong&gt;: Big thanks to Dominik Kufel and Ren Li for their feedbacks on this blog post!&lt;/p&gt;

&lt;h2 id=&quot;appendix-useful-tricks-to-manipulate-pauli-operators&quot;&gt;Appendix: useful tricks to manipulate Pauli operators&lt;/h2&gt;

&lt;p&gt;For the discussion that follows, let’s define a Pauli operator as an operator of the form &lt;code class=&quot;MathJax_Preview&quot;&gt;P_1 \otimes \ldots \otimes P_n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_1 \otimes \ldots \otimes P_n&lt;/script&gt; with &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i \in \{I, X, Y, Z\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i \in \{I, X, Y, Z\}&lt;/script&gt; for all &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;. As a reminder, here is the definitions of the Pauli matrices &lt;code class=&quot;MathJax_Preview&quot;&gt;X,Y,Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X,Y,Z&lt;/script&gt;:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    X = \left(
        \begin{matrix}
            0 &amp;amp; 1 \\ 1 &amp;amp; 0
        \end{matrix}
    \right), \;
    Y = \left(
        \begin{matrix}
            0 &amp;amp; -i \\ i &amp;amp; 0
        \end{matrix}
    \right), \;
    Z = \left(
        \begin{matrix}
            1 &amp;amp; 0 \\ 0 &amp;amp; -1
        \end{matrix}
    \right) \;
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    X = \left(
        \begin{matrix}
            0 &amp; 1 \\ 1 &amp; 0
        \end{matrix}
    \right), \;
    Y = \left(
        \begin{matrix}
            0 &amp; -i \\ i &amp; 0
        \end{matrix}
    \right), \;
    Z = \left(
        \begin{matrix}
            1 &amp; 0 \\ 0 &amp; -1
        \end{matrix}
    \right) \;
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;We say that two Pauli operators &lt;code class=&quot;MathJax_Preview&quot;&gt;P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;P'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'&lt;/script&gt; commute if &lt;code class=&quot;MathJax_Preview&quot;&gt;P P' = P'P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P P' = P'P&lt;/script&gt;, and anticommute if &lt;code class=&quot;MathJax_Preview&quot;&gt;P P' = -P' P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P P' = -P' P&lt;/script&gt;. The goal of this section is to prove the following extremely useful fact about Pauli operators:&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Property&lt;/strong&gt;: Two Pauli operators &lt;code class=&quot;MathJax_Preview&quot;&gt;P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;P'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'&lt;/script&gt; commute if they intersect on an even number of terms with a different Pauli element. Otherwise, they anticommute.&lt;/p&gt;

&lt;p&gt;For instance, &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1 Y_2 Z_3 X_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1 Y_2 Z_3 X_4&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1 Z_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1 Z_4&lt;/script&gt; anticommute: they intersect on qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; (with the same Pauli) and &lt;code class=&quot;MathJax_Preview&quot;&gt;4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;4&lt;/script&gt; (with a different Pauli), so only on one qubit with a different Pauli. On the other hand, &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1 X_2 X_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1 X_2 X_3&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_2 Z_3 Z_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_2 Z_3 Z_4&lt;/script&gt; commute as they intersect on two terms (qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt;) with a different Pauli.&lt;/p&gt;

&lt;p&gt;This property is used all the time in quantum error correction: to check that the stabilizers of a code commute, to see how errors affect the stabilizer measurements, etc. So it’s worth getting comfortable with it early in your QEC journey.&lt;/p&gt;

&lt;p&gt;So let’s show this fact. Let &lt;code class=&quot;MathJax_Preview&quot;&gt;P=P_1 \ldots P_n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P=P_1 \ldots P_n&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;P'=P'_1 \ldots P'_n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'=P'_1 \ldots P'_n&lt;/script&gt; two Pauli operators, with each &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;P'_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'_i&lt;/script&gt; acting on qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;. Our objective is to go from &lt;code class=&quot;MathJax_Preview&quot;&gt;PP'=P_1 \ldots P_n P'_1 \ldots P'_n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;PP'=P_1 \ldots P_n P'_1 \ldots P'_n&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;P'P=P'_1 \ldots P'_n P_1 \ldots P_n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'P=P'_1 \ldots P'_n P_1 \ldots P_n&lt;/script&gt;.
For that, we will move each term &lt;code class=&quot;MathJax_Preview&quot;&gt;P'_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'_i&lt;/script&gt; to the top. Since any &lt;code class=&quot;MathJax_Preview&quot;&gt;P'_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'_i&lt;/script&gt; commute with all the terms &lt;code class=&quot;MathJax_Preview&quot;&gt;P_j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_j&lt;/script&gt; with &lt;code class=&quot;MathJax_Preview&quot;&gt;i \neq j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i \neq j&lt;/script&gt; (they act on different qubits), we can move it next to &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i&lt;/script&gt;:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
PP'=P_1 \ldots P_i P'_i P_{i+1} \ldots P_n P'_1 \ldots P'_{i-1} P'_{i+1} \ldots P_n
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
PP'=P_1 \ldots P_i P'_i P_{i+1} \ldots P_n P'_1 \ldots P'_{i-1} P'_{i+1} \ldots P_n
\end{aligned}&lt;/script&gt;

&lt;p&gt;Now, if &lt;code class=&quot;MathJax_Preview&quot;&gt;P&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;P'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'&lt;/script&gt; don’t intersect on qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt;, that is either &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i=I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i=I&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;P'_i = I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'_i = I&lt;/script&gt;, we will have &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i P'_i = P'_i P_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i P'_i = P'_i P_i&lt;/script&gt;. Same result if &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i = P'_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i = P'_i&lt;/script&gt;. In those two cases, we can move &lt;code class=&quot;MathJax_Preview&quot;&gt;P'_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'_i&lt;/script&gt; to the top without introducing any minus sign:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
PP'=P'_i P_1 \ldots P_n P'_1 \ldots P'_{i-1} P'_{i+1} \ldots P_n
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
PP'=P'_i P_1 \ldots P_n P'_1 \ldots P'_{i-1} P'_{i+1} \ldots P_n
\end{aligned}&lt;/script&gt;

&lt;p&gt;On the other hand, if &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i \neq P'_i \neq I&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i \neq P'_i \neq I&lt;/script&gt;, we will have &lt;code class=&quot;MathJax_Preview&quot;&gt;P_i P'_i = - P'_i P_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P_i P'_i = - P'_i P_i&lt;/script&gt; (remember that &lt;code class=&quot;MathJax_Preview&quot;&gt;XZ+ZX=XY+YX=YZ+ZY=0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;XZ+ZX=XY+YX=YZ+ZY=0&lt;/script&gt;). This means that moving &lt;code class=&quot;MathJax_Preview&quot;&gt;P'_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P'_i&lt;/script&gt; to the top introduces a minus sign:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
PP'=-P'_i P_1 \ldots P_n P'_1 \ldots P'_{i-1} P'_{i+1} \ldots P_n
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
PP'=-P'_i P_1 \ldots P_n P'_1 \ldots P'_{i-1} P'_{i+1} \ldots P_n
\end{aligned}&lt;/script&gt;

&lt;p&gt;Therefore, each intersection with a different Pauli element introduces a minus sign, and the overall sign will be &lt;code class=&quot;MathJax_Preview&quot;&gt;+1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;+1&lt;/script&gt; if and only if there is an even number of such intersections, which proves our propositions.&lt;/p&gt;

&lt;h2 id=&quot;solution-of-the-exercise&quot;&gt;Solution of the exercise&lt;/h2&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise&lt;/strong&gt;: show that Shor’s code has a distance of &lt;code class=&quot;MathJax_Preview&quot;&gt;d=3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=3&lt;/script&gt;. &lt;br /&gt;
&lt;em&gt;(&lt;strong&gt;Hint&lt;/strong&gt;: find a weight-3 error, made of either &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; elements, that applies a bit-flip or phase-flip to the logical state of the code)&lt;/em&gt;&lt;br /&gt;&lt;br /&gt;
&lt;strong&gt;Correction&lt;/strong&gt;: the operator &lt;code class=&quot;MathJax_Preview&quot;&gt;Z_1 Z_4 Z_7&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z_1 Z_4 Z_7&lt;/script&gt; turns &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_{L_2}&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 1 \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 1 \rangle_{L_2}&lt;/script&gt;, and is therefore a logical bit-flip operator. The operator &lt;code class=&quot;MathJax_Preview&quot;&gt;X_1 X_2 X_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X_1 X_2 X_3&lt;/script&gt; turns &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 1 \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 1 \rangle_{L_2}&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;-\vert 1 \rangle_{L_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-\vert 1 \rangle_{L_2}&lt;/script&gt;, and is therefore a logical phase-flip operator. Note that those errors preserve the codespace (they turn a logical state into another logical state), and therefore cannot be detected by measuring our parity-check operators.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Note that I’m using a different notation from the previous post, giving variables a more generalizable name. If that confuses you, here is the exact mapping: &lt;code class=&quot;MathJax_Preview&quot;&gt;z_1 \rightarrow x_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_1 \rightarrow x_1&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;z_2 \rightarrow x_5&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_2 \rightarrow x_5&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;z_3 \rightarrow x_7&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_3 \rightarrow x_7&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;a \rightarrow x_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a \rightarrow x_2&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;b \rightarrow x_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;b \rightarrow x_3&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;c \rightarrow x_6&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;c \rightarrow x_6&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;d \rightarrow x_4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d \rightarrow x_4&lt;/script&gt;. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;The &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle_{L}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle_{L}&lt;/script&gt; state of the Steane code was first implemented by an Austrian team, in &lt;a href=&quot;https://arxiv.org/abs/1403.5426&quot;&gt;Nigg et al., 2014&lt;/a&gt;. Actual error correction using stabilizer measurements was then done by Honeywell in &lt;a href=&quot;https://arxiv.org/abs/2107.07505&quot;&gt;Ryan-Anderson et al., 2021&lt;/a&gt;. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="quantum-computing" /><summary type="html">Now that you know all you need to know about classical error correction, the time has finally come to learn how to correct those damn errors that keep sabotaging your quantum computer! The key tool, introduced by Daniel Gottesman in his landmark 1997 PhD thesis is the stabilizer formalism. The same way most classical codes fall into the linear code category, almost all the quantum codes you will encounter can be classified as stabilizer codes. And for a good reason: stabilizer codes are simply the quantum generalization of linear codes! Your beloved parity checks will turn into stabilizers, a set of commuting measurements controlling the parity of your qubits in different bases. Parity-check matrices and Tanner graphs will get slightly bigger and more constrained. But apart from that, if you’re more or less comfortable with the notions discussed in the last post, going quantum shouldn’t give you too much trouble.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/stabilizer-formalism-1/thumbnail.png" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/stabilizer-formalism-1/thumbnail.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">All you need to know about classical error correction</title><link href="https://arthurpesah.me/blog/2022-05-21-classical-error-correction/" rel="alternate" type="text/html" title="All you need to know about classical error correction" /><published>2022-05-21T00:00:00+02:00</published><updated>2022-05-21T00:00:00+02:00</updated><id>https://arthurpesah.me/blog/classical-error-correction</id><content type="html" xml:base="https://arthurpesah.me/blog/2022-05-21-classical-error-correction/">&lt;p&gt;When learning about quantum error correction (QEC) for the first time, I tried to jump directly into the core of the subject, going from the stabilizer formalism to topological codes and decoders, but completely missing the classical origin of those notions. The reason is that many introductions to the subject do a great job presenting all those concepts in a self-contained way, without assuming any knowledge in error correction.
So why bother learning classical error correction at all? Because if you dig deeper, you will find classical error correction concepts sprinkled all over QEC. Important classical notions such as parity checks, linear codes, Tanner graphs, belief propagation, low-density parity-check (LDPC) codes and many more, have natural generalizations in the quantum world and have been widely used in the development of QEC. Learning about classical error correction a few months into my QEC journey was completely illuminating: many ideas that I only understood formally suddenly made sense intuitively, and I was able to understand the content of many more papers. For this reason, I’d like this second article on quantum error correction to actually be about classical error correction. You will learn all you need to start off your QEC journey on the right foot!&lt;/p&gt;

&lt;p&gt;So what exactly are we gonna study today? The central notion in this post is that of &lt;strong&gt;linear code&lt;/strong&gt;. Linear codes form one of the most important families of error-correcting codes. It includes for instance Hamming codes (some of the earliest codes, invented in 1950), Reed-Solomon codes (used in CDs and QR codes), Turbo codes (used in 3G/4G communication) and LDPC codes (used in 5G communication). While we won’t try to cover the whole zoo of linear codes here, we will introduce some crucial tools to understand them. In particular, the goal of this post is to give you a good grasp of the parity-check matrix, and its graphical representation, the Tanner graph. As we will see when going quantum, the stabilizer formalism (the dominant paradigm to construct quantum codes) can be understood as a direct generalization of linear coding theory, and the quantum parity-check matrix happens to be an essential tool to simulate quantum codes in practice. This post will also be the occasion to introduce some more general coding terminology (encoding, decoding, distance, &lt;code class=&quot;MathJax_Preview&quot;&gt;[n,k,d]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n,k,d]&lt;/script&gt;-code, codewords, etc.), which will be handy when delving into QEC.&lt;/p&gt;

&lt;p&gt;As a final motivating factor before starting, it happens that this field contains some of the most beautiful ideas in computer science. To get a sense of this beauty, I recommend watching the &lt;a href=&quot;https://youtu.be/X8jsijhllIA&quot;&gt;3Blue1Brown videos on the Hamming code&lt;/a&gt; as a complement to this post. It will give you a very visual picture of some of the techniques introduced here. However, it’s not a prerequisite, so feel free to continue reading this post and watch the video at a later time. On that note, let’s start!&lt;/p&gt;

&lt;h2 id=&quot;general-setting&quot;&gt;General setting&lt;/h2&gt;

&lt;p&gt;Let us consider the following setting: we would like to send a &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;-bit message &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; across a noisy channel, for instance between your phone and a satellite. If we choose to send &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; directly without any pre-processing, a different result &lt;code class=&quot;MathJax_Preview&quot;&gt;\widetilde{\bm{x}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\widetilde{\bm{x}}&lt;/script&gt; will arrive with a certain number of errors. Here, we will assume that all errors are bit-flip errors, meaning that they can turn a &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; or a &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; into &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; (potentially with a different probability).&lt;/p&gt;

&lt;p&gt;To protect the message against bit-flip errors, we can choose to add redundancy to it. For instance, let’s send all the bits three times: each &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; becomes &lt;code class=&quot;MathJax_Preview&quot;&gt;000&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;000&lt;/script&gt; and each &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; becomes &lt;code class=&quot;MathJax_Preview&quot;&gt;111&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;111&lt;/script&gt;. For example, if we want to send the message &lt;code class=&quot;MathJax_Preview&quot;&gt;10100&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;10100&lt;/script&gt;, we should send instead&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    111,000,111,000,000
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    111,000,111,000,000
\end{aligned}&lt;/script&gt;

&lt;p&gt;Now, imagine some errors have occurred, and the satellite receives the following message instead:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    101,000,111,000,100
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    101,000,111,000,100
\end{aligned}&lt;/script&gt;

&lt;p&gt;Assuming that at most one error has occurred on each triplet, the original message can be decoded by taking a majority vote: &lt;code class=&quot;MathJax_Preview&quot;&gt;101&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;101&lt;/script&gt; is decoded as &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;100&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;100&lt;/script&gt; is decoded as &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt;. The message &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}=\bm{x} \bm{x} \bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}=\bm{x} \bm{x} \bm{x}&lt;/script&gt; that we send across the channel is called an &lt;strong&gt;encoding&lt;/strong&gt; of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt;, while trying to infer the original message &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; from the noisy encoding &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{\tilde{y}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{\tilde{y}}&lt;/script&gt; is called &lt;strong&gt;decoding&lt;/strong&gt;. A particular encoding is often called a &lt;strong&gt;code&lt;/strong&gt; as well, and the example we have seen is called the &lt;strong&gt;3-repetition code&lt;/strong&gt;. More generally, an error-correction process can be summarized with the following diagram:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/classical-error-correction/error-correction-diagram.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Let’s now introduce some important jargon. In general, an encoder &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}&lt;/script&gt; divides a message into chunks of &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; bits, and encodes them into &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; bits. We write &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}(\bm{x})=\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}(\bm{x})=\bm{y}&lt;/script&gt;, where &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; is a &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;-bit message and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}&lt;/script&gt; is an &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;-bit encoding.
For example, in the 3-repetition code, we are encoding one bit at a time into three bits, so &lt;code class=&quot;MathJax_Preview&quot;&gt;k=1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=1&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;n=3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n=3&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}(x)=xxx&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}(x)=xxx&lt;/script&gt; for each bit &lt;code class=&quot;MathJax_Preview&quot;&gt;x&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;codeword&lt;/strong&gt; is an element of the image of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}&lt;/script&gt;. We denote the set of all codewords as &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}=\text{Im}(\mathcal{E})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}=\text{Im}(\mathcal{E})&lt;/script&gt;. For instance, in the &lt;strong&gt;3-repetition code&lt;/strong&gt;, we have two codewords: &lt;code class=&quot;MathJax_Preview&quot;&gt;000&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;000&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;111&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;111&lt;/script&gt;, respectively given by &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}(0)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}(0)&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}(1)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}(1)&lt;/script&gt;. In this example, we see that if one or two errors occur on a given codeword, the resulting bit-string won’t be a codeword anymore, making the error &lt;strong&gt;detectable&lt;/strong&gt;. For instance, if you see &lt;code class=&quot;MathJax_Preview&quot;&gt;110&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;110&lt;/script&gt; in your message, you know that an error has occurred, since &lt;code class=&quot;MathJax_Preview&quot;&gt;110&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;110&lt;/script&gt; is not a codeword. On the other hands, the error will only be &lt;strong&gt;correctable&lt;/strong&gt; by our majority vote procedure if at most one error occurs. Finally, if three bit-flips occur—going from &lt;code class=&quot;MathJax_Preview&quot;&gt;000&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;000&lt;/script&gt; to &lt;code class=&quot;MathJax_Preview&quot;&gt;111&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;111&lt;/script&gt; or the reverse—, the errors will be &lt;strong&gt;undetectable&lt;/strong&gt;, resulting in what we call a &lt;strong&gt;logical error&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This argument can be generalized using the notion of &lt;strong&gt;distance&lt;/strong&gt;. The distance &lt;code class=&quot;MathJax_Preview&quot;&gt;d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; of a code is the minimum number of bit-flips required to pass from one codeword to another, or in other words, the minimum number of errors that would be undetectable with our code. To define the distance more formally, we need to introduce two important notions. The &lt;strong&gt;Hamming weight&lt;/strong&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert\bm{x}\vert&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert\bm{x}\vert&lt;/script&gt; of a binary vector &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; is the number of &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; of this vector. The &lt;strong&gt;Hamming distance&lt;/strong&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;D_H(\bm{x},\bm{y})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;D_H(\bm{x},\bm{y})&lt;/script&gt; between two binary vectors &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}&lt;/script&gt; is the number of components that differ between &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}&lt;/script&gt;, i.e.&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    D_H(\bm{x},\bm{y})=\vert \bm{x} - \bm{y} \vert
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    D_H(\bm{x},\bm{y})=\vert \bm{x} - \bm{y} \vert
\end{aligned}&lt;/script&gt;

&lt;p&gt;We can then define the distance as the minimum Hamming distance between two vectors:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    d=\min_{\bm{x},\bm{y} \in \mathcal{C}} D_H(\bm{x},\bm{y})
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    d=\min_{\bm{x},\bm{y} \in \mathcal{C}} D_H(\bm{x},\bm{y})
\end{aligned}&lt;/script&gt;

&lt;p&gt;For instance, the distance of the 3-repetition code is 3 (we need to flip all 3 bits to have an undetectable error).
A code that encodes &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; bits with &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; bits and has a distance &lt;code class=&quot;MathJax_Preview&quot;&gt;d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; is called an &lt;code class=&quot;MathJax_Preview&quot;&gt;[n,k,d]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n,k,d]&lt;/script&gt;&lt;strong&gt;-code&lt;/strong&gt;. The 3-repetition code is an example of &lt;code class=&quot;MathJax_Preview&quot;&gt;[3,1,3]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[3,1,3]&lt;/script&gt;-code.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;strong&gt;rate&lt;/strong&gt; of an &lt;code class=&quot;MathJax_Preview&quot;&gt;[n, k, d]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n, k, d]&lt;/script&gt;-code is defined as &lt;code class=&quot;MathJax_Preview&quot;&gt;R=k/n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;R=k/n&lt;/script&gt; (so &lt;code class=&quot;MathJax_Preview&quot;&gt;R=1/3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;R=1/3&lt;/script&gt; in our case).&lt;/p&gt;

&lt;p&gt;The difficulty in designing good error-correcting codes lies in the trade-off between rate and distance. Indeed, we would ideally like both quantities to be high: a high rate means that there is a low overhead in the encoding process (we only need a few redundancy bits), and a high distance means that we can correct many errors. So can we maximize both quantities? Unfortunately, many bounds have been established on this trade-off, telling us that high-rate codes must have low distance, and high-distance codes must have low rate. The easiest bound to understand is the &lt;strong&gt;Singleton bound&lt;/strong&gt;, which states that for any linear &lt;code class=&quot;MathJax_Preview&quot;&gt;[n, k, d]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n, k, d]&lt;/script&gt;-code (we will see the definition of a linear code shortly), we have&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    k \leq n - d + 1
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    k \leq n - d + 1
\end{aligned}&lt;/script&gt;

&lt;p&gt;or in terms of rate&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    R \leq 1 - \frac{d - 1}{n}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    R \leq 1 - \frac{d - 1}{n}
\end{aligned}&lt;/script&gt;

&lt;p&gt;This shows that we cannot arbitrarily increase the rate without decreasing the distance. We will see an interesting illustration of this trade-off in this post by introducing two codes with opposite characteristics: the Hamming code and the simplex code. While the first one is an &lt;code class=&quot;MathJax_Preview&quot;&gt;[n, n - \log(n+1), 3]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n, n - \log(n+1), 3]&lt;/script&gt;-code (high rate, low distance), the second one is an &lt;code class=&quot;MathJax_Preview&quot;&gt;[n, \log(n), n/2]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n, \log(n), n/2]&lt;/script&gt;-code (low rate, high distance).&lt;/p&gt;

&lt;p&gt;We have introduced a lot of notations and jargon in this section, which can be overwhelming when seen for the first time. That’s what happens when you decide to learn a new field! But don’t get discouraged, those notations will keep appearing all the time during your (quantum) error correction learning trip, so they will soon be very familiar to you. In the meantime, I encourage you to do the following three (short) exercises to consolidate what you’ve just learned (the solutions are at the end of the post).&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;: We define the &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell&lt;/script&gt;&lt;strong&gt;-repetition code&lt;/strong&gt; as the repetition of each bit of the message &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell&lt;/script&gt; times. Work out the encoding function &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}&lt;/script&gt; and the different codewords, as well the parameters &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; of the code. How many errors per codeword are detectable? Correctable? What is the rate of the code, and its limit when &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell \rightarrow \infty&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell \rightarrow \infty&lt;/script&gt;?&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;: Show that an &lt;code class=&quot;MathJax_Preview&quot;&gt;[n,k,d]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n,k,d]&lt;/script&gt;-code can &lt;strong&gt;detect&lt;/strong&gt; up to &lt;code class=&quot;MathJax_Preview&quot;&gt;d-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d-1&lt;/script&gt; errors and &lt;strong&gt;correct&lt;/strong&gt; up to &lt;code class=&quot;MathJax_Preview&quot;&gt;\frac{d-1}{2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{d-1}{2}&lt;/script&gt; errors.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 3&lt;/strong&gt;: Show that for an &lt;code class=&quot;MathJax_Preview&quot;&gt;[n,k,d]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n,k,d]&lt;/script&gt;-code defined by the set of codewords &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt;, we have &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert\mathcal{C}\vert=2^k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert\mathcal{C}\vert=2^k&lt;/script&gt;.&lt;/p&gt;

&lt;h2 id=&quot;parity-checks-and-hamming-codes&quot;&gt;Parity-checks and Hamming codes&lt;/h2&gt;

&lt;p&gt;In 1950, Richard Hamming discovered a more intelligent way to introduce redundancy in a message than having to repeat it several times. As a warm-up to understand his method, let’s consider the following code, called &lt;strong&gt;simple parity-check code&lt;/strong&gt;, that encodes &lt;code class=&quot;MathJax_Preview&quot;&gt;k=3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=3&lt;/script&gt; bits into &lt;code class=&quot;MathJax_Preview&quot;&gt;n=4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n=4&lt;/script&gt; bits&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \mathcal{E}(abc) = a b c z
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \mathcal{E}(abc) = a b c z
\end{aligned}&lt;/script&gt;

&lt;p&gt;where &lt;code class=&quot;MathJax_Preview&quot;&gt;z = a + b + c \; (\text{mod} \; 2)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z = a + b + c \; (\text{mod} \; 2)&lt;/script&gt;. We call &lt;code class=&quot;MathJax_Preview&quot;&gt;z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; a &lt;strong&gt;parity-check bit&lt;/strong&gt;, as it indicates whether there is an even or an odd number of &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;s in the sum (&lt;code class=&quot;MathJax_Preview&quot;&gt;z=0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z=0&lt;/script&gt; for even and &lt;code class=&quot;MathJax_Preview&quot;&gt;z=1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z=1&lt;/script&gt; for odd). As an exercise, try to write the different codewords corresponding to this encoding map!&lt;/p&gt;

&lt;p&gt;Now, we can show that any single error can be detected by this code. Indeed, if one of the bits &lt;code class=&quot;MathJax_Preview&quot;&gt;a, b, c&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a, b, c&lt;/script&gt; gets flipped, the parity of the three bits will be reversed, and we won’t have &lt;code class=&quot;MathJax_Preview&quot;&gt;z=a + b + c \; (\text{mod} \; 2)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z=a + b + c \; (\text{mod} \; 2)&lt;/script&gt; anymore, indicating that an error have occurred. Similarly, if &lt;code class=&quot;MathJax_Preview&quot;&gt;z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z&lt;/script&gt; gets flipped, it won’t correspond to the parity of &lt;code class=&quot;MathJax_Preview&quot;&gt;a,b,c&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a,b,c&lt;/script&gt; anymore and we will detect an error.&lt;/p&gt;

&lt;p&gt;However, there is no way to know &lt;em&gt;where&lt;/em&gt; the error has occurred using this code, or in other words, errors are not correctable. The genius of Hamming was to find a way to use parity checks to actually know the position of the error!&lt;/p&gt;

&lt;p&gt;To illustrate his method, let us consider a 4-bit message &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}=abcd&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}=abcd&lt;/script&gt;, as well as the three variables &lt;code class=&quot;MathJax_Preview&quot;&gt;z_1, z_2, z_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_1, z_2, z_3&lt;/script&gt; given by&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    z_1 &amp;amp;= a + b + d \\
    z_2 &amp;amp;= a + c + d \\
    z_3 &amp;amp;= b + c + d \\
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    z_1 &amp;= a + b + d \\
    z_2 &amp;= a + c + d \\
    z_3 &amp;= b + c + d \\
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;where the sum is taken modulo 2 (we will consider all the sums of bits to be modulo 2 from now on, without explicitely writing &lt;code class=&quot;MathJax_Preview&quot;&gt;\mod 2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mod 2&lt;/script&gt;). Those variables indicate the parity of different chunks of our message, as illustrated here:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/classical-error-correction/hamming-code.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In this diagram, each circle represents a parity-check bit &lt;code class=&quot;MathJax_Preview&quot;&gt;z_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt;, and each intersection represents a message bit &lt;code class=&quot;MathJax_Preview&quot;&gt;a,b,c,d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a,b,c,d&lt;/script&gt;. By construction, each parity-check bit only involves the three message bits contained in its corresponding circle.&lt;/p&gt;

&lt;p&gt;If we now send the 7-bit message &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}=\mathcal{E}(abcd)=abcdz_1z_2z_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}=\mathcal{E}(abcd)=abcdz_1z_2z_3&lt;/script&gt;, we can show that any single-bit error will be correctable. Indeed, let’s see what happens if an error occurs on bit &lt;code class=&quot;MathJax_Preview&quot;&gt;a&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;. In this case, we can read in the diagram above that both &lt;code class=&quot;MathJax_Preview&quot;&gt;z_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;z_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_2&lt;/script&gt; parity checks will be violated, while &lt;code class=&quot;MathJax_Preview&quot;&gt;z_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_3&lt;/script&gt; will remain equal to &lt;code class=&quot;MathJax_Preview&quot;&gt;b+c+d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;b+c+d&lt;/script&gt;. This can only happen if &lt;code class=&quot;MathJax_Preview&quot;&gt;a&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; is flipped, which allows us to correct the error. A similar reasoning can be performed for the other bits. This code, called the &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4]&lt;/script&gt;-&lt;strong&gt;Hamming code&lt;/strong&gt;, is a  &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4,3]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4,3]&lt;/script&gt;-code with a rate &lt;code class=&quot;MathJax_Preview&quot;&gt;R=4/7 \approx 0.57&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;R=4/7 \approx 0.57&lt;/script&gt;, which is already better than the rate &lt;code class=&quot;MathJax_Preview&quot;&gt;R \approx 0.33&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;R \approx 0.33&lt;/script&gt; of the &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt;-repetition code, for the same distance.&lt;/p&gt;

&lt;p&gt;The construction presented here can be generalized, leading to a whole family of Hamming codes defined for any &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; of the form &lt;code class=&quot;MathJax_Preview&quot;&gt;n=2^r-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n=2^r-1&lt;/script&gt;. We won’t go into the details of this construction here, but if you’re interested, I encourage you to watch &lt;a href=&quot;(https://youtu.be/X8jsijhllIA)&quot;&gt;this 3Blue1Brown video&lt;/a&gt; on the topic. The main takeaway from the general Hamming code construction is that we only need a logarithmic number of parity checks to correct all single-bit errors! More precisely, Hamming codes are &lt;code class=&quot;MathJax_Preview&quot;&gt;[2^r-1, 2^r-r-1, 3]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[2^r-1, 2^r-r-1, 3]&lt;/script&gt;-codes, with a rate &lt;code class=&quot;MathJax_Preview&quot;&gt;R=\frac{2^r-r-1}{2^r-1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;R=\frac{2^r-r-1}{2^r-1}&lt;/script&gt; that converges to &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; when &lt;code class=&quot;MathJax_Preview&quot;&gt;r \rightarrow \infty&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;r \rightarrow \infty&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;However, Hamming codes have a low distance that doesn’t increase with the codeword length, and they would therefore be impractical in very noisy systems. So we need a more general framework that would allow us to find new codes with better characteristics. That framework is the one of linear codes.&lt;/p&gt;

&lt;h2 id=&quot;linear-codes&quot;&gt;Linear codes&lt;/h2&gt;

&lt;p&gt;This idea of transmitting both the message and some parity-check bits can be generalized with the notion of linear code. A linear code consists in using a matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}&lt;/script&gt;—called &lt;strong&gt;generator matrix&lt;/strong&gt;—as our code, i.e.&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{y} = \bm{G} \bm{x}.
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \bm{y} = \bm{G} \bm{x}.
\end{aligned}&lt;/script&gt;

&lt;p&gt;If our message &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; has length &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; and is complemented by &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; parity checks, such that &lt;code class=&quot;MathJax_Preview&quot;&gt;n=k+m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n=k+m&lt;/script&gt; is the size of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}&lt;/script&gt;, we can write &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}&lt;/script&gt; as&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)
\end{aligned}&lt;/script&gt;

&lt;p&gt;with &lt;code class=&quot;MathJax_Preview&quot;&gt;I_k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;I_k&lt;/script&gt; the &lt;code class=&quot;MathJax_Preview&quot;&gt;k \times k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k \times k&lt;/script&gt; identity matrix (used to reproduce the message in the code) and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{A}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{A}&lt;/script&gt; an &lt;code class=&quot;MathJax_Preview&quot;&gt;m \times k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m \times k&lt;/script&gt; matrix that performs the parity checks. In this notation, all the matrix operations are performed modulo 2. For instance, the generator matrix of the Hamming code can be written&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{G} = \left( \begin{matrix}
    1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
    0 &amp;amp; 1 &amp;amp; 0&amp;amp; 0 \\
    0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
    0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
    \hline
    1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 \\
    1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 \\
    0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1
    \end{matrix} \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{G} = \left( \begin{matrix}
    1 &amp; 0 &amp; 0 &amp; 0 \\
    0 &amp; 1 &amp; 0&amp; 0 \\
    0 &amp; 0 &amp; 1 &amp; 0 \\
    0 &amp; 0 &amp; 0 &amp; 1 \\
    \hline
    1 &amp; 1 &amp; 0 &amp; 1 \\
    1 &amp; 0 &amp; 1 &amp; 1 \\
    0 &amp; 1 &amp; 1 &amp; 1
    \end{matrix} \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;since&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{G} \bm{x} =
    \left(
        \begin{matrix}
            1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 \\
            0 &amp;amp; 1 &amp;amp; 0&amp;amp; 0 \\
            0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
            0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
            \hline
            1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 \\
            1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 \\
            0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1
        \end{matrix}
    \right)
    \left(
        \begin{matrix}
            a \\
            b \\
            c \\
            d
        \end{matrix}
    \right)
    =
    \left(
        \begin{matrix}
            a \\
            b \\
            c \\
            d \\
            a + b + d \\
            a + c + d \\
            b + c + d
        \end{matrix}
    \right)
    =
    \left(
        \begin{matrix}
            a \\
            b \\
            c \\
            d \\
            z_1 \\
            z_2 \\
            z_3
        \end{matrix}
    \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{G} \bm{x} =
    \left(
        \begin{matrix}
            1 &amp; 0 &amp; 0 &amp; 0 \\
            0 &amp; 1 &amp; 0&amp; 0 \\
            0 &amp; 0 &amp; 1 &amp; 0 \\
            0 &amp; 0 &amp; 0 &amp; 1 \\
            \hline
            1 &amp; 1 &amp; 0 &amp; 1 \\
            1 &amp; 0 &amp; 1 &amp; 1 \\
            0 &amp; 1 &amp; 1 &amp; 1
        \end{matrix}
    \right)
    \left(
        \begin{matrix}
            a \\
            b \\
            c \\
            d
        \end{matrix}
    \right)
    =
    \left(
        \begin{matrix}
            a \\
            b \\
            c \\
            d \\
            a + b + d \\
            a + c + d \\
            b + c + d
        \end{matrix}
    \right)
    =
    \left(
        \begin{matrix}
            a \\
            b \\
            c \\
            d \\
            z_1 \\
            z_2 \\
            z_3
        \end{matrix}
    \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Two important remarks about generator matrices:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Elementary operations on the rows and columns of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}&lt;/script&gt; don’t change the code. Indeed, the code is defined as the image of &lt;code class=&quot;MathJax_Preview&quot;&gt;G&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;G&lt;/script&gt;, which is invariant under similarity transformations. Using Gaussian reduction, it is therefore always possible to transform &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}&lt;/script&gt; to have the form &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)&lt;/script&gt;. In other words, any linear code can be seen as a message supplemented with parity checks!&lt;/li&gt;
  &lt;li&gt;The codewords of a code described by &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}&lt;/script&gt; can be found by taking all the linear combinations of the columns of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}&lt;/script&gt; (the vector &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; in the definition indicates which columns you select or not). Therefore, to find all the codewords, just calculate all the &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}&lt;/script&gt; of the form &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}=a_1 \bm{c_1} + ... a_k \bm{c_k}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}=a_1 \bm{c_1} + ... a_k \bm{c_k}&lt;/script&gt; where &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{c_i}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{c_i}&lt;/script&gt; is the &lt;code class=&quot;MathJax_Preview&quot;&gt;i^{\th}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i^{\th}&lt;/script&gt; column of &lt;code class=&quot;MathJax_Preview&quot;&gt;G&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;G&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;a_1,...a_k \in \{0,1\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a_1,...a_k \in \{0,1\}&lt;/script&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;An equivalent picture to describe linear codes is through the &lt;strong&gt;parity-check matrix&lt;/strong&gt;, defined as an &lt;code class=&quot;MathJax_Preview&quot;&gt;m \times n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m \times n&lt;/script&gt; matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt; such that&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{H} \bm{y} = 0
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \bm{H} \bm{y} = 0
\end{aligned}&lt;/script&gt;

&lt;p&gt;if and only if &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}&lt;/script&gt; is a codeword. In other words, the space of codewords can be defined as the kernel of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt;. The intuition is that linear codes can always be defined as a set of codewords obeying a certain system of linear equations, defined by the parity checks. For instance, the codewords of the Hamming code obey the following system:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    a + b + d + z_1 = 0 \\
    a + c + d + z_2 = 0 \\
    b + c + d + z_3 = 0
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    a + b + d + z_1 = 0 \\
    a + c + d + z_2 = 0 \\
    b + c + d + z_3 = 0
\end{aligned}&lt;/script&gt;

&lt;p&gt;(since &lt;code class=&quot;MathJax_Preview&quot;&gt;a+b+d=z_1 \Leftrightarrow a+b+d+z_1=0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a+b+d=z_1 \Leftrightarrow a+b+d+z_1=0&lt;/script&gt; when working modulo &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt;)&lt;/p&gt;

&lt;p&gt;Therefore, the parity-check matrix of the Hamming code can be written&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{H} =
    \left(
        \begin{array}{cccc|ccc}
            1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 \\
            1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
            0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
        \end{array}
    \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{H} =
    \left(
        \begin{array}{cccc|ccc}
            1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 \\
            1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 \\
            0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 \\
        \end{array}
    \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;For a generator matrix of the form &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)&lt;/script&gt;, the corresponding parity-check matrix can be written&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{H}=\left(\begin{matrix} \bm{A} &amp;amp; I_m  \end{matrix} \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{H}=\left(\begin{matrix} \bm{A} &amp; I_m  \end{matrix} \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Indeed, if &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}&lt;/script&gt; is a codeword, it can be written &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}=\bm{G}\bm{x}=\left(\begin{matrix} \bm{x} \\ \hline \bm{A} \bm{x} \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}=\bm{G}\bm{x}=\left(\begin{matrix} \bm{x} \\ \hline \bm{A} \bm{x} \end{matrix} \right)&lt;/script&gt;. Applying &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt;, we get&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{H} \bm{y} = \bm{A}\bm{x} + \bm{A}\bm{x} = 2\bm{A}\bm{x} = \bm{0}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \bm{H} \bm{y} = \bm{A}\bm{x} + \bm{A}\bm{x} = 2\bm{A}\bm{x} = \bm{0}
\end{aligned}&lt;/script&gt;

&lt;p&gt;since all operations are performed modulo 2, and &lt;code class=&quot;MathJax_Preview&quot;&gt;2=0 \mod 2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2=0 \mod 2&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;Similarly to how all generator matrices can be chosen to have the form &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)&lt;/script&gt;, we can always apply a Gaussian reduction on &lt;code class=&quot;MathJax_Preview&quot;&gt;H&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt; such that is has the form &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}=\left(\begin{matrix} \bm{A} &amp;amp; I_m  \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\bm{H}=\left(\begin{matrix} \bm{A} &amp; I_m  \end{matrix} \right) %]]&gt;&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;At this point of the post, you might be wondering why we should use the parity-check matrix, when the generator matrix seems much more natural. There are many reasons to prefer the parity-check matrix over the generator matrix. The simplest one is that it gives a convenient method to detect and correct errors. Indeed, if &lt;code class=&quot;MathJax_Preview&quot;&gt;\widetilde{\bm{y}}=\bm{y} + \bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\widetilde{\bm{y}}=\bm{y} + \bm{e}&lt;/script&gt; is the received message disturbed by an error vector &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt;, applying the parity-check matrix to &lt;code class=&quot;MathJax_Preview&quot;&gt;\widetilde{\bm{y}}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\widetilde{\bm{y}}&lt;/script&gt; gives&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{H} \widetilde{\bm{y}} &amp;amp;= \bm{H} \left( \bm{y} + \bm{e} \right) \\
    &amp;amp;= \bm{H} \bm{e}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{H} \widetilde{\bm{y}} &amp;= \bm{H} \left( \bm{y} + \bm{e} \right) \\
    &amp;= \bm{H} \bm{e}
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;The new vector &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{s} = \bm{H} \bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{s} = \bm{H} \bm{e}&lt;/script&gt; has dimension &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; and is called the &lt;strong&gt;syndrome&lt;/strong&gt;. Each component &lt;code class=&quot;MathJax_Preview&quot;&gt;s_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;s_i&lt;/script&gt; of the syndrome is equal to &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; if the parity-check equation &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is violated. Decoding a message then consists in finding the most probable error &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt; that has yielded to the syndrome &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{s}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{s}&lt;/script&gt;. Let’s illustrate this syndrome decoding technique with the &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4]&lt;/script&gt;-Hamming code. The components of the syndrome are given by the following system of equations:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    a + b + d + z_1 = s_1 \\
    a + c + d + z_2 = s_2 \\
    b + c + d + z_3 = s_3
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    a + b + d + z_1 = s_1 \\
    a + c + d + z_2 = s_2 \\
    b + c + d + z_3 = s_3
\end{aligned}&lt;/script&gt;

&lt;p&gt;When &lt;code class=&quot;MathJax_Preview&quot;&gt;s_i=1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;s_i=1&lt;/script&gt;, it therefore means that the parity-check bit &lt;code class=&quot;MathJax_Preview&quot;&gt;z_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_i&lt;/script&gt; is violated (it doesn’t correspond to the parity of its block anymore).
The following table shows the bit we choose to correct for each of the 8 possible syndromes (we can obtain it by looking at the Venn diagram of the Hamming code):&lt;/p&gt;

&lt;table class=&quot;stretch-table&quot;&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Syndrome&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;000&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;001&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;010&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;011&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;100&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;101&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;110&lt;/strong&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;&lt;strong&gt;111&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Correction&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;\emptyset&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\emptyset&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;z_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_3&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;z_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_2&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;c&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;c&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;z_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_1&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;b&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;b&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;a&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;MathJax_Preview&quot;&gt;d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A visual way to construct the parity-check matrix is through the &lt;strong&gt;Tanner graph&lt;/strong&gt; of the code. The Tanner graph is a bipartite graph containing two types of nodes, the data nodes (one for each bit of the codeword) and the check nodes (one for each bit of the syndrome). A check node &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and a data node &lt;code class=&quot;MathJax_Preview&quot;&gt;j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; are connected if the syndrome bit &lt;code class=&quot;MathJax_Preview&quot;&gt;s_i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;s_i&lt;/script&gt; depends on &lt;code class=&quot;MathJax_Preview&quot;&gt;x_j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;x_j&lt;/script&gt;. The figure below represents the Tanner graph of the Hamming code. The parity-check matrix is then simply the adjacency matrix of the Tanner graph, i.e. it has a &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; at row &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; and column &lt;code class=&quot;MathJax_Preview&quot;&gt;j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt; if the check node &lt;code class=&quot;MathJax_Preview&quot;&gt;i&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;i&lt;/script&gt; is connected to the data node &lt;code class=&quot;MathJax_Preview&quot;&gt;j&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;j&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; otherwise.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/classical-error-correction/tanner-graph.png&quot; alt=&quot;&quot; /&gt;
Tanner graph of the Hamming code. The top nodes represent the codeword bits and the bottom nodes the syndrome bits, with an edge whenever a codeword bit is involved in the definition of a syndrome bit.&lt;/p&gt;

&lt;p&gt;In quantum error correction, the syndrome can be measured without disturbing the state (through the so-called stabilizer measurements), which makes the theory of linear codes easily transferable to the quantum domain. While quantum codewords can be complicated superpositions in the Hilbert space, errors are simple vectors of size &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; (the number of qubits), making the calculation of the syndrome &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{s}=\bm{H} \bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{s}=\bm{H} \bm{e}&lt;/script&gt; straightforward using the the parity-check matrix, and it is indeed used extensively in simulations.&lt;/p&gt;

&lt;p&gt;In the next section, we will study the problem of decoding linear codes in general, i.e. correcting the errors using the syndrome information. But before that, you can try to solve the following exercises to make sure you understand the basics of linear codes.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 4&lt;/strong&gt;: Find the generator and the parity-check matrix of the code defined by &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}(abc) = a b c z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}(abc) = a b c z&lt;/script&gt; where &lt;code class=&quot;MathJax_Preview&quot;&gt;z=a+b+c&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z=a+b+c&lt;/script&gt;, and draw its Tanner graph.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 5&lt;/strong&gt;: Find the generator and the parity-check matrix of the 3-repetition code, and draw its Tanner graph.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 6&lt;/strong&gt;: Show that the set of codewords is a vector space, i.e. if two vectors &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_1}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_2}&lt;/script&gt; are codewords, &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_1} + \bm{y_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_1} + \bm{y_2}&lt;/script&gt; is also a codeword. This property is sometimes taken as the definition of linear codes.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 7&lt;/strong&gt;: &lt;strong&gt;(a)&lt;/strong&gt; Show that if &lt;code class=&quot;MathJax_Preview&quot;&gt;V&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; is a vector space over binary numbers, then &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert V\vert  = 2^{\dim(V)}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert V\vert  = 2^{\dim(V)}&lt;/script&gt;, where &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert V\vert&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert V\vert&lt;/script&gt; is the the number of elements in the vector space. &lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(b)&lt;/strong&gt; Deduce that the parity-check matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt; of an &lt;code class=&quot;MathJax_Preview&quot;&gt;[n,k,d]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[n,k,d]&lt;/script&gt;-code obeys the relation &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{rank}(H)=n-k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{rank}(H)=n-k&lt;/script&gt;.&lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(c)&lt;/strong&gt; Deduce that if a code has &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; independent parity checks, we have &lt;code class=&quot;MathJax_Preview&quot;&gt;m=n-k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m=n-k&lt;/script&gt;. This relation is often used to find the parameter &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; of a code given the parity checks.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 8&lt;/strong&gt;:
&lt;strong&gt;(a)&lt;/strong&gt; Show that the distance of a linear code is the minimum Hamming weight of all the non-zero codewords, i.e. &lt;code class=&quot;MathJax_Preview&quot;&gt;d=\min_{\bm{y}\in \mathcal{C}, \bm{y} \neq \bm{0}} \vert \bm{y} \vert&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=\min_{\bm{y}\in \mathcal{C}, \bm{y} \neq \bm{0}} \vert \bm{y} \vert&lt;/script&gt;, where &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt; is the space of codewords and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert\cdot\vert&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert\cdot\vert&lt;/script&gt; denotes the Hamming weight (&lt;em&gt;Hint: first prove that the Hamming distance between two codewords is translation-invariant, i.e. &lt;code class=&quot;MathJax_Preview&quot;&gt;D_H(\bm{x},\bm{y})=D_H(\bm{x}+\bm{z},\bm{y}+\bm{z})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;D_H(\bm{x},\bm{y})=D_H(\bm{x}+\bm{z},\bm{y}+\bm{z})&lt;/script&gt;&lt;/em&gt;)&lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(b)&lt;/strong&gt; Use this property to compute the distance of the Hamming code.&lt;/p&gt;

&lt;h2 id=&quot;decoding-linear-codes&quot;&gt;Decoding linear codes&lt;/h2&gt;

&lt;p&gt;Designing a code with good characteristics, such as a high rate and a high distance, is not enough to make it practical: you need to show how to decode it efficiently. As discussed before, decoding consists in finding the original message given its noisy encoded version. We then define an &lt;strong&gt;efficient decoder&lt;/strong&gt; as an algorithm able to accomplish this task in polynomial time, i.e. with a time complexity that grows polynomially with the size &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; of the code.&lt;/p&gt;

&lt;p&gt;To see why decoding can be a difficult problem, let’s consider the general task of decoding a linear code, when errors follow a certain distribution &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{e})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{e})&lt;/script&gt;. As we’ve seen in the previous section, decoding a linear code can be reduced to finding the most likely error given a received syndrome.
Let &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt; denote the parity-check matrix of our code and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{s}=\bm{H}\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{s}=\bm{H}\bm{e}&lt;/script&gt; the received syndrome . The goal of an ideal decoder would be to find the vector &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt; that maximizes the probability &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{e} \vert \bm{s})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{e} \vert \bm{s})&lt;/script&gt;. Using Bayes rule, we can write this probability as:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    P(\bm{e} \vert \bm{s}) = \frac{P(\bm{s} \vert \bm{e}) P(\bm{e})}{P(\bm{s})}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    P(\bm{e} \vert \bm{s}) = \frac{P(\bm{s} \vert \bm{e}) P(\bm{e})}{P(\bm{s})}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Since &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{s})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{s})&lt;/script&gt; doesn’t depend explicitely on &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt;, we can ignore it when solving the maximization problem over &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt;. Next, we notice that any valid predicted error will have to obey &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}\bm{e}=\bm{s}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}\bm{e}=\bm{s}&lt;/script&gt;, so &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{s} \vert \bm{e})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{s} \vert \bm{e})&lt;/script&gt; is either &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt;, depending on whether this equation is satisfied or not. In other words:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    P(\bm{s} \vert \bm{e}) = \bm{1}_{\{\bm{H}\bm{e}=\bm{s}\}}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    P(\bm{s} \vert \bm{e}) = \bm{1}_{\{\bm{H}\bm{e}=\bm{s}\}}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Therefore, we can rewrite our optimization problem as:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \max_{\bm{e}\in \{0,1\}^n} P(\bm{e}) \; \text{ s.t. } \; \bm{H}\bm{e}=\bm{s}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \max_{\bm{e}\in \{0,1\}^n} P(\bm{e}) \; \text{ s.t. } \; \bm{H}\bm{e}=\bm{s}
\end{aligned}&lt;/script&gt;

&lt;p&gt;An important special case is when errors are independent and identically distributed, such that&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    P(\bm{e}) = \prod_{i=1}^n P(e_i)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    P(\bm{e}) = \prod_{i=1}^n P(e_i)
\end{aligned}&lt;/script&gt;

&lt;p&gt;Writing &lt;code class=&quot;MathJax_Preview&quot;&gt;P(e_i=1)=p&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(e_i=1)=p&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;P(e_i=0) = (1-p)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(e_i=0) = (1-p)&lt;/script&gt;, and denoting &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \bm{e} \vert&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \bm{e} \vert&lt;/script&gt; the Hamming weight of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt; (i.e. the number of 1 in &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt;), we can rewrite the equation above as&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    P(\bm{e}) = p^{\vert \bm{e} \vert} (1-p)^{n-\vert \bm{e} \vert}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    P(\bm{e}) = p^{\vert \bm{e} \vert} (1-p)^{n-\vert \bm{e} \vert}
\end{aligned}&lt;/script&gt;

&lt;p&gt;This expression only depends on the weight of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{e}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{e}&lt;/script&gt;, and if the probability of error &lt;code class=&quot;MathJax_Preview&quot;&gt;p &amp;lt; 0.5&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
p &lt; 0.5 %]]&gt;&lt;/script&gt;, it increases when lowering the weight. In other words, our optimization problem reduces to finding the error of minimum weight that satisfies &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}\bm{e}=\bm{s}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}\bm{e}=\bm{s}&lt;/script&gt;:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \min_{\bm{e}\in \{0,1\}^n} \vert \bm{e} \vert \; \text{ s.t. } \; \bm{H}\bm{e}=\bm{s}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \min_{\bm{e}\in \{0,1\}^n} \vert \bm{e} \vert \; \text{ s.t. } \; \bm{H}\bm{e}=\bm{s}
\end{aligned}&lt;/script&gt;

&lt;p&gt;Any decoder that explicitely solves this optimization problem is called a &lt;strong&gt;Maximum A Posteriori (MAP) decoder&lt;/strong&gt;, as we are maximizing the posterior distribution &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{e} \vert \bm{s})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{e} \vert \bm{s})&lt;/script&gt;, and is considered to be an ideal decoder.&lt;/p&gt;

&lt;p&gt;So how do we solve the MAP decoding problem? A naive idea would be to simply search through all error vectors and find one that has minimum weight and obeys the constraint. Since there are &lt;code class=&quot;MathJax_Preview&quot;&gt;2^n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^n&lt;/script&gt; possible error vectors, the time complexity of this algorithm would scale exponentially with &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; and definitely not be efficient. So can we do better? Unfortunately, the answer is no in general: this constrained optimization problem can be shown to be NP-complete&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, meaning that, most likely, no polynomial-time algorithm will ever solve it.&lt;/p&gt;

&lt;p&gt;What we do from there really depends on the code that is being decoded. Some parity-check matrices have a particular structure that allows the construction of polynomial-time algorithms that solve the MAP decoding problem. It’s for instance the case with Hamming codes and repetition codes. More generally, certain heuristics can be used as approximations to MAP decoding, and lead to high performance in practice. The main example of high-performance heuristic is the &lt;strong&gt;belief propagation algorithm&lt;/strong&gt;, a linear-time iterative algorithm that exploits the fact that the probability &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\bm{e} \vert \bm{s})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\bm{e} \vert \bm{s})&lt;/script&gt; can often be factorized over a graph (in our case the Tanner graph)&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. This algorithm is used extensively by the classical error-correction community, and has recently started to become popular in the quantum community as well, so I will try to dedicate a blog post to it.&lt;/p&gt;

&lt;p&gt;Before ending this post, there is one last important notion I want you to know, as it is frequently used in quantum error correction: code duality.&lt;/p&gt;

&lt;h2 id=&quot;code-duality&quot;&gt;Code duality&lt;/h2&gt;

&lt;p&gt;Let’s consider a code &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt; with generator matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}&lt;/script&gt; and parity-check matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt;. We define the &lt;strong&gt;dual code&lt;/strong&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}^\perp&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}^\perp&lt;/script&gt; as the code with generator matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}^\perp=\bm{H}^T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}^\perp=\bm{H}^T&lt;/script&gt; and parity-check matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}^\perp=\bm{G}^T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}^\perp=\bm{G}^T&lt;/script&gt;. It means that the codewords in &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}^\perp&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}^\perp&lt;/script&gt; now span the rows of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt;, and are orthogonal to all the codewords of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}&lt;/script&gt;. Duality is an extremely useful notion in coding theory, as it allows to construct new codes from known ones. It is also widely used in quantum error correction, where many constructions make use of the dual code. Let’s try to understand this notion more precisely by looking at some examples.&lt;/p&gt;

&lt;p&gt;First, what is the dual of the 3-repetition code? If you’ve attempted Exercise 5, you know that the repetition code is associated to the following matrices:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{G} =
    \left(
        \begin{matrix}
            1 \\
            1 \\
            1 \\
        \end{matrix}
    \right)
    , \; \;
    \bm{H} =
    \left(
        \begin{matrix}
            1 &amp;amp; 1 &amp;amp; 0 \\
            1 &amp;amp; 0 &amp;amp; 1
        \end{matrix}
    \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{G} =
    \left(
        \begin{matrix}
            1 \\
            1 \\
            1 \\
        \end{matrix}
    \right)
    , \; \;
    \bm{H} =
    \left(
        \begin{matrix}
            1 &amp; 1 &amp; 0 \\
            1 &amp; 0 &amp; 1
        \end{matrix}
    \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;Therefore, the dual of the 3-repetition code corresponds to&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{G}^\perp =
    \left(
        \begin{matrix}
            1 &amp;amp; 1 \\
            1 &amp;amp; 0 \\
            0 &amp;amp; 1
        \end{matrix}
    \right)
    , \; \;
    \bm{H}^\perp =
    \left(
        \begin{matrix}
            1 &amp;amp; 1 &amp;amp; 1\\
        \end{matrix}
    \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{G}^\perp =
    \left(
        \begin{matrix}
            1 &amp; 1 \\
            1 &amp; 0 \\
            0 &amp; 1
        \end{matrix}
    \right)
    , \; \;
    \bm{H}^\perp =
    \left(
        \begin{matrix}
            1 &amp; 1 &amp; 1\\
        \end{matrix}
    \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;From this new parity-check matrix, we can deduce that the codewords of &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{C}^\perp&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{C}^\perp&lt;/script&gt; are all the vectors
&lt;code class=&quot;MathJax_Preview&quot;&gt;\left(
    \begin{matrix}
        a \\
        b \\
        c
    \end{matrix}
\right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\left(
    \begin{matrix}
        a \\
        b \\
        c
    \end{matrix}
\right)&lt;/script&gt;
such that
&lt;code class=&quot;MathJax_Preview&quot;&gt;\left(
    \begin{matrix}
        1 &amp;amp; 1 &amp;amp; 1
    \end{matrix}
\right)
\left(
    \begin{matrix}
        a \\
        b \\
        c
    \end{matrix}
\right)
= a+b+c=0 = 0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\left(
    \begin{matrix}
        1 &amp; 1 &amp; 1
    \end{matrix}
\right)
\left(
    \begin{matrix}
        a \\
        b \\
        c
    \end{matrix}
\right)
= a+b+c=0 = 0 %]]&gt;&lt;/script&gt;. In other words, the first two bits can be seen as a message and the last bit as a parity check. That’s the &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt;-bit version of the simple parity-check code that we’ve studied in the second section and in Exercise 4! It has four codewords, that we can read from the span of the columns of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}^\perp&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}^\perp&lt;/script&gt;:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \mathcal{C}^\perp = \left\{
        \left(
        \begin{matrix}
            0 \\
            0 \\
            0
        \end{matrix}
        \right),
        \left(
        \begin{matrix}
            1 \\
            1 \\
            0
        \end{matrix}
        \right),
        \left(
        \begin{matrix}
            1 \\
            0 \\
            1
        \end{matrix}
        \right),
        \left(
        \begin{matrix}
            0 \\
            1 \\
            1
        \end{matrix}
        \right)
    \right\}
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \mathcal{C}^\perp = \left\{
        \left(
        \begin{matrix}
            0 \\
            0 \\
            0
        \end{matrix}
        \right),
        \left(
        \begin{matrix}
            1 \\
            1 \\
            0
        \end{matrix}
        \right),
        \left(
        \begin{matrix}
            1 \\
            0 \\
            1
        \end{matrix}
        \right),
        \left(
        \begin{matrix}
            0 \\
            1 \\
            1
        \end{matrix}
        \right)
    \right\}
\end{aligned}&lt;/script&gt;

&lt;p&gt;A second, even simpler example, is the 2-repetition code, whose matrices are
&lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}=
\left(
    \begin{matrix}
        1 \\
        1 \\
    \end{matrix}
\right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}=
\left(
    \begin{matrix}
        1 \\
        1 \\
    \end{matrix}
\right)&lt;/script&gt;
and
&lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}=
\left(
    \begin{matrix}
        1 &amp;amp; 1
    \end{matrix}
\right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\bm{H}=
\left(
    \begin{matrix}
        1 &amp; 1
    \end{matrix}
\right) %]]&gt;&lt;/script&gt;.
Indeed, this code is the simplest example of a &lt;strong&gt;self-dual code&lt;/strong&gt;: its dual is equal to the original code. A more interesting example of self-dual code is given in Exercise 9.&lt;/p&gt;

&lt;p&gt;Finally, what about our good old &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4]&lt;/script&gt;-Hamming code? The generator of its dual is given by&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \bm{G}^\perp =
    \left(
        \begin{matrix}
            1 &amp;amp; 1 &amp;amp; 0 \\
            1 &amp;amp; 0 &amp;amp; 1 \\
            0 &amp;amp; 1 &amp;amp; 1 \\
            1 &amp;amp; 1 &amp;amp; 1 \\
            1 &amp;amp; 0 &amp;amp; 0 \\
            0 &amp;amp; 1 &amp;amp; 0 \\
            0 &amp;amp; 0 &amp;amp; 1 \\
        \end{matrix}
    \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{G}^\perp =
    \left(
        \begin{matrix}
            1 &amp; 1 &amp; 0 \\
            1 &amp; 0 &amp; 1 \\
            0 &amp; 1 &amp; 1 \\
            1 &amp; 1 &amp; 1 \\
            1 &amp; 0 &amp; 0 \\
            0 &amp; 1 &amp; 0 \\
            0 &amp; 0 &amp; 1 \\
        \end{matrix}
    \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;from which we can deduce the list of codewords (by calculating the span of the columns of &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}^\perp&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}^\perp&lt;/script&gt;):&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    \mathcal{C}^\perp =
    \left\{
        \left(
            \begin{matrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{matrix}
        \right),
        \left(
            \begin{matrix} 1 \\ 1 \\ 0 \\ 1 \\ 1 \\ 0 \\ 0 \end{matrix}
        \right),
        \left(
            \begin{matrix} 1 \\ 0 \\ 1 \\ 1 \\ 0 \\ 1 \\ 0 \end{matrix}
        \right),
        \left(
            \begin{matrix} 0 \\ 1 \\ 1 \\ 1 \\ 0 \\ 0 \\ 1 \end{matrix}
        \right),
        \left(
            \begin{matrix} 0 \\ 1 \\ 1 \\ 0 \\ 1 \\ 1 \\ 0 \end{matrix}
        \right),
        \left(
            \begin{matrix} 1 \\ 1 \\ 0 \\ 0 \\ 0 \\ 1 \\ 1 \end{matrix}
        \right),
        \left(
            \begin{matrix} 1 \\ 0 \\ 1 \\ 0 \\ 1 \\ 0 \\ 1 \end{matrix}
        \right),
        \left(
            \begin{matrix} 0 \\ 0 \\ 0 \\ 1 \\ 1 \\ 1 \\ 1 \end{matrix}
        \right),
    \right\}

\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
    \mathcal{C}^\perp =
    \left\{
        \left(
            \begin{matrix} 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0 \end{matrix}
        \right),
        \left(
            \begin{matrix} 1 \\ 1 \\ 0 \\ 1 \\ 1 \\ 0 \\ 0 \end{matrix}
        \right),
        \left(
            \begin{matrix} 1 \\ 0 \\ 1 \\ 1 \\ 0 \\ 1 \\ 0 \end{matrix}
        \right),
        \left(
            \begin{matrix} 0 \\ 1 \\ 1 \\ 1 \\ 0 \\ 0 \\ 1 \end{matrix}
        \right),
        \left(
            \begin{matrix} 0 \\ 1 \\ 1 \\ 0 \\ 1 \\ 1 \\ 0 \end{matrix}
        \right),
        \left(
            \begin{matrix} 1 \\ 1 \\ 0 \\ 0 \\ 0 \\ 1 \\ 1 \end{matrix}
        \right),
        \left(
            \begin{matrix} 1 \\ 0 \\ 1 \\ 0 \\ 1 \\ 0 \\ 1 \end{matrix}
        \right),
        \left(
            \begin{matrix} 0 \\ 0 \\ 0 \\ 1 \\ 1 \\ 1 \\ 1 \end{matrix}
        \right),
    \right\}

\end{aligned}&lt;/script&gt;

&lt;p&gt;An interesting fact about those 8 codewords is that they all belong to the 16 codewords of the Hamming codes! You can check that by showing either that the three last components of each codewords correspond to the parity checks &lt;code class=&quot;MathJax_Preview&quot;&gt;z_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_1&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;z_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_2&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;z_3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_3&lt;/script&gt; of the Hamming code, or that all the vectors are orthogonal to each others (meaning that that &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}\bm{y}=\bm{0}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}\bm{y}=\bm{0}&lt;/script&gt; for all of them). For this reason, we say the the &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4]&lt;/script&gt;-Hamming code is &lt;strong&gt;self-orthogonal&lt;/strong&gt;, meaning that its dual is included in the original code. Are self-orthogonal codes interesting, given that they just seem to be diminished version of known codes? It happens that they’re interesting if the included codewords all have a large Hamming weight, meaning that the distance will be higher than the original code (as shown in Exercise 8)! In our case, all the codewords have weight 4. The distance of the dual code is therefore 4, instead of 3 for the &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4]&lt;/script&gt;-Hamming code.&lt;/p&gt;

&lt;p&gt;The resulting code is therefore a &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,3,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,3,4]&lt;/script&gt;-code, called a &lt;strong&gt;simplex code&lt;/strong&gt;. The general family of simplex codes, defined as dual of Hamming codes, are &lt;code class=&quot;MathJax_Preview&quot;&gt;[2^r-1, r, 2^{r-1}]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[2^r-1, r, 2^{r-1}]&lt;/script&gt;-codes, meaning that they have a very large distance but a very low rate. That’s one of the advantages of the duality construction, it allows us to find new codes with different properties!&lt;/p&gt;

&lt;p&gt;Let’s now take a step back and see what we can say about the general characteristics of dual codes:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The codeword length is the same for a code and its dual: &lt;code class=&quot;MathJax_Preview&quot;&gt;n^\perp=n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n^\perp=n&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;The message length is given by &lt;code class=&quot;MathJax_Preview&quot;&gt;k^\perp=n-k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k^\perp=n-k&lt;/script&gt;. Indeed, taking &lt;code class=&quot;MathJax_Preview&quot;&gt;H&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt; to be full-rank and of dimension &lt;code class=&quot;MathJax_Preview&quot;&gt;m \times n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m \times n&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;G^\perp=H^T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;G^\perp=H^T&lt;/script&gt; is also full rank and has dimension &lt;code class=&quot;MathJax_Preview&quot;&gt;n \times m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n \times m&lt;/script&gt;. By Exercise 7, &lt;code class=&quot;MathJax_Preview&quot;&gt;m=n-k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m=n-k&lt;/script&gt; (since H is full-rank), and &lt;code class=&quot;MathJax_Preview&quot;&gt;G^\perp&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;G^\perp&lt;/script&gt; therefore has &lt;code class=&quot;MathJax_Preview&quot;&gt;n-k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n-k&lt;/script&gt; (independent) columns, meaning that it has &lt;code class=&quot;MathJax_Preview&quot;&gt;n-k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n-k&lt;/script&gt; message bits.&lt;/li&gt;
  &lt;li&gt;As a consequence of 2, self-dual codes have rate &lt;code class=&quot;MathJax_Preview&quot;&gt;R=\frac{1}{2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;R=\frac{1}{2}&lt;/script&gt;, since &lt;code class=&quot;MathJax_Preview&quot;&gt;k=n-k \Rightarrow k=\frac{n}{2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=n-k \Rightarrow k=\frac{n}{2}&lt;/script&gt;&lt;/li&gt;
  &lt;li&gt;We have the following inequality on distances: &lt;code class=&quot;MathJax_Preview&quot;&gt;d+d^\perp -2 \leq n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d+d^\perp -2 \leq n&lt;/script&gt; (you can show it by adding together the Singleton bounds for a code and its dual). It can be interpreted as a tradeoff between the two distances: increasing the distance of a code often results in a decrease of its dual distance.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hence, the dual construction can often allow us to find codes with opposite characteristics, just like the Hamming and the simplex codes. Moreover, showing that a code is self-dual, or simply deriving the dual of a code, is often a powerful tool in coding theory to prove certain theorems.&lt;/p&gt;

&lt;p&gt;Before concluding this post, here is one last exercise to consolidate your knowledge of duality.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 9&lt;/strong&gt;: We can extend the Hamming code by adding a last parity-check bit, that checks the total parity of the message, i.e. &lt;code class=&quot;MathJax_Preview&quot;&gt;z_4=a+b+c+d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;z_4=a+b+c+d&lt;/script&gt;. We call this code the &lt;strong&gt;extended Hamming code&lt;/strong&gt;. &lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(a)&lt;/strong&gt; Write the parity-check matrix of the extended Hamming code. &lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(b)&lt;/strong&gt; Show that the extended Hamming code is a &lt;code class=&quot;MathJax_Preview&quot;&gt;[8,4,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[8,4,4]&lt;/script&gt;-code. It means that it can now detect (but not correct) all the &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt;-bit errors.&lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(c)&lt;/strong&gt; Show that this code is self-dual. It is the smallest non-trivial self-dual code, after the &lt;code class=&quot;MathJax_Preview&quot;&gt;2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2&lt;/script&gt;-repetition code introduced earlier.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;So what have we learned in this post? We have defined error-correcting codes and shown that they are characterized by three important parameters: the number of bits &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; of the message we want to send, the number of bits &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; of the encoding, and the distance &lt;code class=&quot;MathJax_Preview&quot;&gt;d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; of the code. We have introduced linear codes, an important family of codes characterized by a generator and a parity-check matrix. We have seen that decoding can be performed by applying the parity-check matrix to the received message (getting what we called the syndrome), but that finding efficient algorithms to solve this problem can be challenging in general. Finally, we have shown that new codes can be obtained from known ones using duality.&lt;/p&gt;

&lt;p&gt;Now is time to confess that I have lied in the title: there is so much more to know about classical error correction, we’ve only barely scratched the surface!
Soon after Richard Hamming invented linear codes in the early 1950s, David Muller, Irving Reed and Gustave Solomon discovered a more algebraic way to come up with new linear codes, based on generator polynomials instead of generator matrices. This framework led to the invention of the most important codes of the 20th century, such as Reed-Muller codes, convolutional codes, Turbo codes, etc. More recently, LDPC codes, which use graph theory methods to obtain Tanner graphs with good properties, have gained popularity due to improvements of belief propagation decoders, and have for instance been used in the 5G protocol. Apart from coming up with new codes, classical error correction is also concerned with establishing bonds on code performance, often using information theory and probabilities. And decoding is a central notion in the field that we have only barely touch.&lt;/p&gt;

&lt;p&gt;However, what we have learned in this post will allow us to start quantum error correction from solid foundations. In the next post, we will introduce the main framework of quantum error correction: the stabilizer formalism. We will see how stabilizers are a direct generalization of parity checks when we have both &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; Pauli errors instead of just bit-flips. We will introduce the Shor code, a generalization of the repetition code, and the Steane code, a generalization of the &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4]&lt;/script&gt;-Hamming code. We will see how we can write a quantum version of the parity-check matrix, and how decoding works in this context. Moving forward in our quantum error correction journey, new classical error correction techniques will be needed, and we will introduce them in due time. But for the moment, you should have all you need to start quantum error correction on good feet!&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;p&gt;Popular science videos to build some intuition:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=X8jsijhllIA&quot;&gt;How to send a self-correcting message&lt;/a&gt;, by 3Blue1Brown&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=-15nx57tbfc&amp;amp;list=PLp_s0welk1_cQkK6GxYsfE_SFQTRjXuB&quot;&gt;Error correcting codes&lt;/a&gt;, by Computerphile&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Lecture series to actually delve into the subject:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://youtube.com/watch?v=vfjN7MmSB6g&amp;amp;list=PLkvhuSoxwjI_UudECvFYArvG0cLbFlzSr&quot;&gt;Algebraic coding theory&lt;/a&gt;, by Mary Wootters&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=eixCGqdlGxQ&amp;amp;list=PLJHszsWbB6hqkOyFCQOAlQtfzC1G9sf2&quot;&gt;Error Correcting codes&lt;/a&gt;, by Eigenchris&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Textbook from which I learned most of the content of this post:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.inference.org.uk/itprnn/book.pdf&quot;&gt;Information Theory, Inference, and Learning Algorithms&lt;/a&gt;, by David McKay&lt;/li&gt;
&lt;/ul&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Acknowledgment&lt;/strong&gt;: Big thanks to George Umbrarescu and Avinash Mocherla for their feedback on this blog post!&lt;/p&gt;

&lt;h2 id=&quot;solution-to-the-exercises&quot;&gt;Solution to the exercises&lt;/h2&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 1&lt;/strong&gt;: The encoding function of the &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell&lt;/script&gt;-repetition code is given by &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{E}(x) = x...x&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{E}(x) = x...x&lt;/script&gt; where &lt;code class=&quot;MathJax_Preview&quot;&gt;x&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; is repeated &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell&lt;/script&gt; times.
There are two codewords, made of all &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; or all &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;: &lt;code class=&quot;MathJax_Preview&quot;&gt;0...0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0...0&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;1...1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1...1&lt;/script&gt;. It is an &lt;code class=&quot;MathJax_Preview&quot;&gt;[\ell,1,\ell]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[\ell,1,\ell]&lt;/script&gt;-code, since we are encoding &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; bit into &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt; bits, and the distance (number of bit-flips to go from one codeword to another) is &lt;code class=&quot;MathJax_Preview&quot;&gt;n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n&lt;/script&gt;. It means that &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell-1&lt;/script&gt; errors would be detectable, and &lt;code class=&quot;MathJax_Preview&quot;&gt;(\ell-1)/2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(\ell-1)/2&lt;/script&gt; would be correctable (using majority vote). The rate of the code is &lt;code class=&quot;MathJax_Preview&quot;&gt;R=\frac{k}{n}=\frac{1}{\ell}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;R=\frac{k}{n}=\frac{1}{\ell}&lt;/script&gt;, which asymptotically goes to &lt;code class=&quot;MathJax_Preview&quot;&gt;0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;0&lt;/script&gt; when &lt;code class=&quot;MathJax_Preview&quot;&gt;\ell\rightarrow \infty&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\ell\rightarrow \infty&lt;/script&gt;, making those codes impractical as they require a high number of redundant bits to encode a single bit.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 2&lt;/strong&gt;: The distance &lt;code class=&quot;MathJax_Preview&quot;&gt;d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d&lt;/script&gt; is the minimum number of errors that can make the message switch from one codeword to another. Therefore, any error of weight &lt;code class=&quot;MathJax_Preview&quot;&gt;d-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d-1&lt;/script&gt; or lower will make the message leave the space of codewords, and will therefore be detectable. To correct an error, we need to find the closest codeword to the received message (in terms of Hamming distance). If the error weight is lower than &lt;code class=&quot;MathJax_Preview&quot;&gt;\frac{d-1}{2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{d-1}{2}&lt;/script&gt;, we will be &lt;code class=&quot;MathJax_Preview&quot;&gt;\frac{d-1}{2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{d-1}{2}&lt;/script&gt; errors apart from the correct codeword, but &lt;code class=&quot;MathJax_Preview&quot;&gt;\frac{d+1}{2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\frac{d+1}{2}&lt;/script&gt; errors apart from the next closest codeword. We will therefore output the correct codeword. On the other hand, if the errors has weight &lt;code class=&quot;MathJax_Preview&quot;&gt;d/2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d/2&lt;/script&gt; or larger, we might be closer to another codeword and output the wrong correction.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 3&lt;/strong&gt;: By definition, we’re encoding a message of length &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt; using &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \mathcal{C} \vert&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \mathcal{C} \vert&lt;/script&gt; codewords. Since there are &lt;code class=&quot;MathJax_Preview&quot;&gt;2^k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^k&lt;/script&gt; binary messages of lengths of &lt;code class=&quot;MathJax_Preview&quot;&gt;k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k&lt;/script&gt;, we need &lt;code class=&quot;MathJax_Preview&quot;&gt;2^k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^k&lt;/script&gt; codewords to encode them all.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 4&lt;/strong&gt;: Using the form &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G}=\left(\begin{matrix} I_k \\ \hline \bm{A}  \end{matrix} \right)&lt;/script&gt; of the generator matrix, we find the following generator matrix for the simple parity-check code:
&lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G}=
\left(
    \begin{matrix}
    1 &amp;amp; 0 &amp;amp; 0 \\
    0 &amp;amp; 1 &amp;amp; 0 \\
    0 &amp;amp; 0 &amp;amp; 1 \\\hline
    1 &amp;amp; 1 &amp;amp; 1
    \end{matrix}
\right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\bm{G}=
\left(
    \begin{matrix}
    1 &amp; 0 &amp; 0 \\
    0 &amp; 1 &amp; 0 \\
    0 &amp; 0 &amp; 1 \\\hline
    1 &amp; 1 &amp; 1
    \end{matrix}
\right) %]]&gt;&lt;/script&gt;. &lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
Similarly, using &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}=\left(\begin{matrix} \bm{A} &amp;amp; I_m \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\bm{H}=\left(\begin{matrix} \bm{A} &amp; I_m \end{matrix} \right) %]]&gt;&lt;/script&gt;, we find &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}=\left(\begin{matrix} 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\bm{H}=\left(\begin{matrix} 1 &amp; 1 &amp; 1 &amp; 1 \end{matrix} \right) %]]&gt;&lt;/script&gt;. The Tanner graph can be constructed using four message nodes, and one check node connected to all the message nodes.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 5&lt;/strong&gt;: The repetition code has two codewords, &lt;code class=&quot;MathJax_Preview&quot;&gt;\left( \begin{matrix} 0 \\ 0 \\ 0 \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\left( \begin{matrix} 0 \\ 0 \\ 0 \end{matrix} \right)&lt;/script&gt;
and &lt;code class=&quot;MathJax_Preview&quot;&gt;\left( \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\left( \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right)&lt;/script&gt;. It is therefore generated by &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{G} = \left( \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{G} = \left( \begin{matrix} 1 \\ 1 \\ 1 \end{matrix} \right)&lt;/script&gt;. The first component can be interpreted as the identity matrix in dimension &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;, and we can define &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{A}=\left( \begin{matrix} 1 \\ 1 \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{A}=\left( \begin{matrix} 1 \\ 1 \end{matrix} \right)&lt;/script&gt;. From there, we get the parity-check matrix &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}= \left( \begin{matrix} 1 &amp;amp; 1 &amp;amp; 0 \\ 1 &amp;amp; 0 &amp;amp; 1 \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\bm{H}= \left( \begin{matrix} 1 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1 \end{matrix} \right) %]]&gt;&lt;/script&gt;. It can be interpreted as checking that the parity of each pair of bits is even. The corresponding Tanner graph is drawn below.&lt;/p&gt;

&lt;p class=&quot;figure message&quot;&gt;&lt;img src=&quot;/assets/img/blog/classical-error-correction/repetition-code-tanner-graph.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 6&lt;/strong&gt;: We can show this using either the parity-check or the generator picture. In the generator picture, it comes down to showing that &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{Im}(\bm{G})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{Im}(\bm{G})&lt;/script&gt; is a vector space. You might already know this fact from linear algebra, but if not, take two codewords &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_1}, \bm{y_2} \in \text{Im}(\bm{G})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_1}, \bm{y_2} \in \text{Im}(\bm{G})&lt;/script&gt;. By definition, they can be written as &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_1}=\bm{G} \bm{x_1}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_1}=\bm{G} \bm{x_1}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_2}=\bm{G} \bm{x_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_2}=\bm{G} \bm{x_2}&lt;/script&gt;. Therefore, &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_1} + \bm{y_2} = \bm{G} \bm{x_1} + \bm{G} \bm{x_2} = \bm{G}(\bm{x_1} + \bm{x_2}) \in \text{Im}(\bm{G})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_1} + \bm{y_2} = \bm{G} \bm{x_1} + \bm{G} \bm{x_2} = \bm{G}(\bm{x_1} + \bm{x_2}) \in \text{Im}(\bm{G})&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_1} + \bm{y_2}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_1} + \bm{y_2}&lt;/script&gt; is a codeword.
In the parity-check picture, it comes down to showing that &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{Ker}(\bm{H})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{Ker}(\bm{H})&lt;/script&gt; is a vector space, which you might also already know from linear algebra. It can be shown by taking two codewords &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_1}, \bm{y_2} \in \text{Ker}(\bm{H})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_1}, \bm{y_2} \in \text{Ker}(\bm{H})&lt;/script&gt;. Then &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H} (\bm{y_1} + \bm{y_2}) = \bm{H} \bm{y_1} + \bm{H} \bm{y_2} = \bm{0} + \bm{0} = \bm{0}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H} (\bm{y_1} + \bm{y_2}) = \bm{H} \bm{y_1} + \bm{H} \bm{y_2} = \bm{0} + \bm{0} = \bm{0}&lt;/script&gt;, so &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y_1}+\bm{y_2} \in \text{Ker}(\bm{H})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y_1}+\bm{y_2} \in \text{Ker}(\bm{H})&lt;/script&gt;.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 7&lt;/strong&gt;:
&lt;strong&gt;(a)&lt;/strong&gt; If &lt;code class=&quot;MathJax_Preview&quot;&gt;k=\dim V&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=\dim V&lt;/script&gt;, we can find a basis &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}_1,...,\bm{y}_k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}_1,...,\bm{y}_k&lt;/script&gt; of &lt;code class=&quot;MathJax_Preview&quot;&gt;V&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt; s.t. any element &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y} \in V&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y} \in V&lt;/script&gt; can be written &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}=a_1 \bm{y}_1 + ... + a_k \bm{y}_k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}=a_1 \bm{y}_1 + ... + a_k \bm{y}_k&lt;/script&gt; with &lt;code class=&quot;MathJax_Preview&quot;&gt;a_1,...,a_k \in \{0,1\}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a_1,...,a_k \in \{0,1\}&lt;/script&gt;. Since there are &lt;code class=&quot;MathJax_Preview&quot;&gt;2^k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^k&lt;/script&gt; possible values of &lt;code class=&quot;MathJax_Preview&quot;&gt;a_1,...,a_k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a_1,...,a_k&lt;/script&gt;, we can deduce that there are &lt;code class=&quot;MathJax_Preview&quot;&gt;2^k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^k&lt;/script&gt; elements in &lt;code class=&quot;MathJax_Preview&quot;&gt;V&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;V&lt;/script&gt;. It can also be seen as a consequence of Exercise 3, where we showed that for any code, the number of codewords is &lt;code class=&quot;MathJax_Preview&quot;&gt;2^k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;2^k&lt;/script&gt;. &lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(b)&lt;/strong&gt; From the &lt;a href=&quot;https://en.wikipedia.org/wiki/Rank%E2%80%93nullity_theorem&quot;&gt;rank-nullity theorem&lt;/a&gt;, we know that &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{rank}(H) + \text{dim}(\text{Ker}(H)) = n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{rank}(H) + \text{dim}(\text{Ker}(H)) = n&lt;/script&gt;. Using (a), we get &lt;code class=&quot;MathJax_Preview&quot;&gt;\dim(\text{Ker}(H))=\log \vert \text{Ker}(H) \vert&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\dim(\text{Ker}(H))=\log \vert \text{Ker}(H) \vert&lt;/script&gt;. But we know from Exercise 3 that &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert\text{Ker}(H)\vert=2^k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert\text{Ker}(H)\vert=2^k&lt;/script&gt;, from which we can deduce that &lt;code class=&quot;MathJax_Preview&quot;&gt;\dim(\text{Ker}(H))=k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\dim(\text{Ker}(H))=k&lt;/script&gt;. Therefore, &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{rank}(H) = n - k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{rank}(H) = n - k&lt;/script&gt;.&lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(c)&lt;/strong&gt;: If there &lt;code class=&quot;MathJax_Preview&quot;&gt;m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m&lt;/script&gt; independent parity checks, we can write &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt; as a full-rank matrix where each row is one of the parity checks. Since &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{H}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{H}&lt;/script&gt; has dimension &lt;code class=&quot;MathJax_Preview&quot;&gt;m \times n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m \times n&lt;/script&gt;, and &lt;code class=&quot;MathJax_Preview&quot;&gt;m &amp;lt; n&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
m &lt; n %]]&gt;&lt;/script&gt; (a fair assumption if we want &lt;code class=&quot;MathJax_Preview&quot;&gt;k &amp;gt; 0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k &gt; 0&lt;/script&gt;), we have &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{rank}(\bm{H})=m&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{rank}(\bm{H})=m&lt;/script&gt;, and by the previous question, &lt;code class=&quot;MathJax_Preview&quot;&gt;m=n-k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m=n-k&lt;/script&gt;.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 8&lt;/strong&gt;: &lt;strong&gt;(a)&lt;/strong&gt; Let’s first show that the Hamming distance is translation-invariant: &lt;code class=&quot;MathJax_Preview&quot;&gt;D_H(\bm{x}+\bm{z}, \bm{y}+\bm{z})=\vert \bm{x} + \bm{z} - (\bm{y}+\bm{z})\vert=\vert \bm{x} - \bm{y} \vert=D_H(\bm{x},\bm{y})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;D_H(\bm{x}+\bm{z}, \bm{y}+\bm{z})=\vert \bm{x} + \bm{z} - (\bm{y}+\bm{z})\vert=\vert \bm{x} - \bm{y} \vert=D_H(\bm{x},\bm{y})&lt;/script&gt;. Therefore, it means that &lt;code class=&quot;MathJax_Preview&quot;&gt;D_H(\bm{x},\bm{y})=D_H(\bm{x}-\bm{x}, \bm{y}-\bm{x})=D_H(0,\bm{y}-\bm{x})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;D_H(\bm{x},\bm{y})=D_H(\bm{x}-\bm{x}, \bm{y}-\bm{x})=D_H(0,\bm{y}-\bm{x})&lt;/script&gt;. If &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{x}&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}&lt;/script&gt; are two codewords, &lt;code class=&quot;MathJax_Preview&quot;&gt;\bm{y}-\bm{x}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\bm{y}-\bm{x}&lt;/script&gt; is also a codeword by linearity of our code (see Exercise 6 for a proof). Therefore, &lt;code class=&quot;MathJax_Preview&quot;&gt;d=\min_{\bm{x},\bm{y}\in \mathcal{C}, \bm{x} \neq \bm{y}} D_H(\bm{x},\bm{y})=\min_{\bm{x},\bm{y}\in \mathcal{C}, \bm{x} \neq \bm{y}} D_H(\bm{0},\bm{x}-\bm{y})=\min_{\bm{x}\in \mathcal{C}, \bm{x} \neq \bm{0}} D_H(\bm{0},\bm{x})&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=\min_{\bm{x},\bm{y}\in \mathcal{C}, \bm{x} \neq \bm{y}} D_H(\bm{x},\bm{y})=\min_{\bm{x},\bm{y}\in \mathcal{C}, \bm{x} \neq \bm{y}} D_H(\bm{0},\bm{x}-\bm{y})=\min_{\bm{x}\in \mathcal{C}, \bm{x} \neq \bm{0}} D_H(\bm{0},\bm{x})&lt;/script&gt;. &lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(b)&lt;/strong&gt; Let’s show that the &lt;code class=&quot;MathJax_Preview&quot;&gt;[7,4]&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;[7,4]&lt;/script&gt;-Hamming code has distance &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt;. Any codeword of the Hamming code is of the form &lt;code class=&quot;MathJax_Preview&quot;&gt;(a, b, c, d, z_1, z_2, z_3)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;(a, b, c, d, z_1, z_2, z_3)&lt;/script&gt;. If &lt;code class=&quot;MathJax_Preview&quot;&gt;a=b=c=d=0&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a=b=c=d=0&lt;/script&gt;, then we will have the zero codeword (which is not included in our optimization). If one of &lt;code class=&quot;MathJax_Preview&quot;&gt;a,b,c,d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a,b,c,d&lt;/script&gt; is &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;, two of the parity checks will be &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;, giving a weight of &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt; for those codewords. If two of &lt;code class=&quot;MathJax_Preview&quot;&gt;a,b,c,d&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a,b,c,d&lt;/script&gt; are &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;, then one parity-check will be &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;, giving also a weight of &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt;. And if three or more variables are &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;, the weight will be at least three. Therefore, the minimum weight of a non-zero codeword is &lt;code class=&quot;MathJax_Preview&quot;&gt;3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;3&lt;/script&gt;, and we have &lt;code class=&quot;MathJax_Preview&quot;&gt;d=3&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=3&lt;/script&gt; by the previous question.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Exercise 9&lt;/strong&gt;: &lt;strong&gt;(a)&lt;/strong&gt; We obtain the parity-check matrix of the extended Hamming code by adding a new column (for our new parity-check bit) and appending the row &lt;code class=&quot;MathJax_Preview&quot;&gt;\left( \begin{matrix} 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \end{matrix} \right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\left( \begin{matrix} 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \end{matrix} \right) %]]&gt;&lt;/script&gt;, giving
&lt;code class=&quot;MathJax_Preview&quot;&gt;\begin{aligned}
    \bm{H} =
    \left(
        \begin{matrix}
            1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0\\
            1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0\\
            0 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 &amp;amp; 0 \\
            1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 1 &amp;amp; 0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 1 \\
        \end{matrix}
    \right)
\end{aligned}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    \bm{H} =
    \left(
        \begin{matrix}
            1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0\\
            1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
            0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\
            1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\
        \end{matrix}
    \right)
\end{aligned} %]]&gt;&lt;/script&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(b)&lt;/strong&gt; We now have &lt;code class=&quot;MathJax_Preview&quot;&gt;n=8&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;n=8&lt;/script&gt; since we have added a new check bit to the original Hamming code. The new parity-check matrix is full-rank, and therefore it has a number of columns &lt;code class=&quot;MathJax_Preview&quot;&gt;m=n-k&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m=n-k&lt;/script&gt; (by Exercise 7). Since &lt;code class=&quot;MathJax_Preview&quot;&gt;m=4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;m=4&lt;/script&gt;, we can deduce that &lt;code class=&quot;MathJax_Preview&quot;&gt;k=4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;k=4&lt;/script&gt;. To calculate the distance, we can find the lowest weight of its codewords (by Exercise 8a). A very similar reasoning to the proof of Exercise 8b can be used to prove that &lt;code class=&quot;MathJax_Preview&quot;&gt;d=4&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;d=4&lt;/script&gt;. &lt;code class=&quot;MathJax_Preview&quot;&gt;\newline&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\newline&lt;/script&gt;
&lt;strong&gt;(c)&lt;/strong&gt; The non-identity part &lt;code class=&quot;MathJax_Preview&quot;&gt;A&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;A&lt;/script&gt; of the parity-check matrix computed above is a symmetric matrix. Therefore, &lt;code class=&quot;MathJax_Preview&quot;&gt;A^T=A&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;A^T=A&lt;/script&gt; and the transpose of the parity-check matrix will be equal to the generator matrix, meaning that the code is self-dual.&lt;/p&gt;

&lt;!-- ---------------------------------------------------------------- --&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Berlekamp et al, &lt;a href=&quot;https://authors.library.caltech.edu/5607/1/BERieeetit78.pdf&quot;&gt;On the Inherent Intractability of Certain Coding Problems&lt;/a&gt;, 1978 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;See McKay, &lt;a href=&quot;https://www.inference.org.uk/itprnn/book.pdf&quot;&gt;Information Theory, Inference, and Learning Algorithms&lt;/a&gt;¸ for a great introduction to belief propagation algorithms for decoding &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="quantum-computing" /><summary type="html">When learning about quantum error correction (QEC) for the first time, I tried to jump directly into the core of the subject, going from the stabilizer formalism to topological codes and decoders, but completely missing the classical origin of those notions. The reason is that many introductions to the subject do a great job presenting all those concepts in a self-contained way, without assuming any knowledge in error correction. So why bother learning classical error correction at all? Because if you dig deeper, you will find classical error correction concepts sprinkled all over QEC. Important classical notions such as parity checks, linear codes, Tanner graphs, belief propagation, low-density parity-check (LDPC) codes and many more, have natural generalizations in the quantum world and have been widely used in the development of QEC. Learning about classical error correction a few months into my QEC journey was completely illuminating: many ideas that I only understood formally suddenly made sense intuitively, and I was able to understand the content of many more papers. For this reason, I’d like this second article on quantum error correction to actually be about classical error correction. You will learn all you need to start off your QEC journey on the right foot!</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/classical-error-correction/thumbnail.png" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/classical-error-correction/thumbnail.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">A bird’s-eye view of quantum error correction and fault tolerance</title><link href="https://arthurpesah.me/blog/2022-01-25-intro-qec-1/" rel="alternate" type="text/html" title="A bird’s-eye view of quantum error correction and fault tolerance" /><published>2022-01-25T00:00:00+01:00</published><updated>2022-01-25T00:00:00+01:00</updated><id>https://arthurpesah.me/blog/intro-qec-1</id><content type="html" xml:base="https://arthurpesah.me/blog/2022-01-25-intro-qec-1/">&lt;p&gt;This Summer marked the beginning of my thesis work, and with it, of my trip in the fascinating world of quantum error correction. I quickly found in this area the interdisciplinarity that I love: the field takes its roots in theoretical computer science (classical error correction), uses intuitions and techniques from theoretical physics (condensed matter, statistical physics, quantum field theory) and has deep connections to black hole research, statistical inference, algebraic topology and geometry, and many other areas of science and mathematics.&lt;/p&gt;

&lt;p&gt;As I am just starting my PhD adventure, I have taken the resolution to start blogging again. And since my first task as a new PhD student is to learn as much as I can about my field, why not sharing this learning journey with you?&lt;/p&gt;

&lt;p&gt;In this first article, we will dive together into the basics of quantum error correction (QEC). The goal is for a reader beginning in the field to get familiar with the big picture of fault-tolerance and error correction. No previous QEC background is required, but some familiarity with the basics of quantum computing (qubits, gates, measurements, etc.) is assumed.&lt;/p&gt;

&lt;h2 id=&quot;a-bit-of-history&quot;&gt;A bit of history&lt;/h2&gt;

&lt;p&gt;When the concept of a quantum computer was first proposed and formalized in the 1980s and 1990s, many physicists were skeptical that those devices would one day see the light of day. As an example, Serge Haroche and Jean-Michel Raimond—two eminent atomic physicists—famously said in a &lt;a href=&quot;https://physicstoday.scitation.org/doi/10.1063/1.881512&quot;&gt;1996 article in Physics Today&lt;/a&gt; that&lt;/p&gt;
&lt;blockquote&gt;
  &lt;p&gt;The large-scale quantum machine, though it may be the computer scientist’s dream, is the experimenter’s nightmare.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The reason for their skepticism was the inherent fragility of quantum states: any noise present in a quantum system, due for instance to unwanted interactions with the environment, can irreversibly modify your quantum state.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/intro-qec/qc-dream-nightmare.png&quot; alt=&quot;&quot; /&gt;
Article from &lt;a href=&quot;https://physicstoday.scitation.org/doi/10.1063/1.881512&quot;&gt;Physics Today&lt;/a&gt; by Serge Haroche and Jean-Michel Raimond, that expressed a general skepticism towards the idea of a large-scale quantum computer.&lt;/p&gt;

&lt;p&gt;Fortunately, the problem of computing with noise had been known for decades in the classical computing community. In the 1940s and 1950s, most computers were built from either mechanical relays or vacuum tubes, both of which were very prone to failure. It meant that random bits could flip in the middle of your calculations, giving you rubbish at the end. It’s exactly in this context that the Bell Labs mathematician Richard Hamming invented the first practical error-correcting code, out of frustration that his calculations on &lt;em&gt;Model 5&lt;/em&gt;—a relay computer only available to him on week-ends—were failing weeks after weeks&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. Modern computers can still have errors from time to time (for instance &lt;a href=&quot;https://www.youtube.com/watch?v=AaZ_RSt0KP8&amp;amp;ab_channel=Veritasium&quot;&gt;due to cosmic rays&lt;/a&gt;!) and some critical systems therefore still require some sort of error correction. But more commonly, error-correcting codes are used everywhere in wireless communication, including satellite communication and the 4G/5G protocol.&lt;/p&gt;

&lt;p&gt;However, generalizing those ideas from classical to quantum bits was not an easy task. The invention of the first quantum error-correcting codes, and with them of the &lt;strong&gt;threshold theorem&lt;/strong&gt;, changed the game. This theorem states that there exist some families of quantum codes that can correct arbitrary errors by increasing the number of redundant qubits, as long as the noise level of the system is below a certain threshold. So, let’s say you found a code with a threshold of &lt;code class=&quot;MathJax_Preview&quot;&gt;1\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1\%&lt;/script&gt;. Then, if your noise is above &lt;code class=&quot;MathJax_Preview&quot;&gt;1\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1\%&lt;/script&gt;, adding more qubits to your code will yield more errors, while if it is below, adding more qubits will reduce the number of errors. 
The presence of a threshold below &lt;code class=&quot;MathJax_Preview&quot;&gt;50\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;50\%&lt;/script&gt; is a purely quantum phenomenon: classical codes are always improved by increasing the number of redundant bits. This important difference is due to the fact that there is only one type of classical errors, the bit-flips, while quantum errors can be caused by both bit-flips and phase-flips, as we will see in the next section.&lt;/p&gt;

&lt;p&gt;While the first quantum codes served as a useful proof of concept, their threshold was estimated to be around &lt;code class=&quot;MathJax_Preview&quot;&gt;10^{-6}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;10^{-6}&lt;/script&gt;, which was far below the experimental capabilities of the time &lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;. The introduction of the stabilizer formalism in 1998 revolutionized quantum error-correction and led to the invention of the surface code&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, which has a threshold over &lt;code class=&quot;MathJax_Preview&quot;&gt;1\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1\%&lt;/script&gt; in realistic settings&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. While subsequent years saw the development of many different quantum codes, the surface code has remained one of the most promising one, and I will probably dedicate several articles to it. But for now, let’s try to understand how quantum error correction works.&lt;/p&gt;

&lt;h2 id=&quot;what-is-quantum-error-correction&quot;&gt;What is quantum error correction?&lt;/h2&gt;

&lt;h3 id=&quot;modeling-quantum-noise&quot;&gt;Modeling quantum noise&lt;/h3&gt;

&lt;p&gt;Imagine that you are running a circuit on a real quantum computer. At each step of the circuit, you are expecting a certain state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle&lt;/script&gt; to come out of the device. However, if you are reading this in the 2020s, chances are that your device is noisy: instead of getting &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi\rangle&lt;/script&gt;, you will get a different state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \widetilde{\psi} \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \widetilde{\psi} \rangle&lt;/script&gt;. This failure can be caused by multiple phenomena: unwanted interactions between qubits when applying a gate, unwanted interactions with the environment (causing decoherence), badly-controlled gates, errors in the measurement or state preparation process, etc. While the source of noise is diverse, it happens that a very general and simple noise model can be used to accurately model noise in a large range of situations: the &lt;strong&gt;Pauli error model&lt;/strong&gt;. It consists in assuming that a Pauli operator &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; is randomly applied after each gate or each clock cycle of the quantum computer. The generality of this model comes from the fact that any continuous error can be decomposed in the Pauli basis, and &lt;code class=&quot;MathJax_Preview&quot;&gt;Y=iXZ&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Y=iXZ&lt;/script&gt;. For instance, if your error is an unwanted rotation by an angle &lt;code class=&quot;MathJax_Preview&quot;&gt;\theta&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; in the Bloch sphere (let’s say in the &lt;code class=&quot;MathJax_Preview&quot;&gt;x&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; direction), we can write:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
R_x(\theta) = \cos\left(\frac{\theta}{2}\right) I - i \sin\left(\frac{\theta}{2}\right) X
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
R_x(\theta) = \cos\left(\frac{\theta}{2}\right) I - i \sin\left(\frac{\theta}{2}\right) X
\end{aligned}&lt;/script&gt;

&lt;p&gt;implying that&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert \widetilde{\psi} \rangle = R_x(\theta) \vert \psi\rangle = \cos\left(\frac{\theta}{2}\right) \vert \psi\rangle - i \sin\left(\frac{\theta}{2}\right) X \vert \psi\rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert \widetilde{\psi} \rangle = R_x(\theta) \vert \psi\rangle = \cos\left(\frac{\theta}{2}\right) \vert \psi\rangle - i \sin\left(\frac{\theta}{2}\right) X \vert \psi\rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;You will soon learn that quantum error correction is done by constantly applying non-destructive measurements to our state (the so-called stabilizer measurements), resulting in the above state being projected in either &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi\rangle&lt;/script&gt; with probability &lt;code class=&quot;MathJax_Preview&quot;&gt;\cos^2(\theta/2)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\cos^2(\theta/2)&lt;/script&gt;, or &lt;code class=&quot;MathJax_Preview&quot;&gt;X \vert \psi\rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X \vert \psi\rangle&lt;/script&gt; with probability &lt;code class=&quot;MathJax_Preview&quot;&gt;\sin^2(\theta/2)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\sin^2(\theta/2)&lt;/script&gt;. This process of decomposing any continuous error into &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; errors is called the &lt;strong&gt;digitization of errors&lt;/strong&gt;, and is key to quantum error correction, since analog errors, even on a classical computer, cannot easily be error-corrected.&lt;/p&gt;

&lt;p&gt;So we’ve reduced the infinite range of possible continuous errors to only two types of errors: &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt;. But what is the effect of those errors? Let’s consider a general single-qubit state, given by&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert \psi \rangle = a \vert 0 \rangle + b \vert 1 \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert \psi \rangle = a \vert 0 \rangle + b \vert 1 \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;Applying &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; to it results in the state&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
X \vert \psi \rangle = a \vert 1 \rangle + b \vert 0 \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
X \vert \psi \rangle = a \vert 1 \rangle + b \vert 0 \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;In other words, we have applied a &lt;strong&gt;bit-flip&lt;/strong&gt; to our state. On the other hand, applying a &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; error&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
Z \vert \psi \rangle = a \vert 0 \rangle - b \vert 1 \rangle
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
Z \vert \psi \rangle = a \vert 0 \rangle - b \vert 1 \rangle
\end{aligned}&lt;/script&gt;

&lt;p&gt;results in a &lt;strong&gt;phase-flip&lt;/strong&gt;. That’s a first major difference between classical and quantum error-correction: instead of having just one type of error (bit-flips), we now have two types of error (bit-flips and phase-flips). This is a key fact that makes classical error correction techniques not directly applicable to the quantum setting. So, how can we correct quantum errors?&lt;/p&gt;

&lt;h3 id=&quot;encoding-and-decoding&quot;&gt;Encoding and decoding&lt;/h3&gt;

&lt;p&gt;The idea of quantum error correction is to &lt;strong&gt;encode&lt;/strong&gt; your state on a larger system, using redundant qubits. A simple example of encoding is the 3-repetition code, defined with the following dictionary:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert 0 \rangle \longrightarrow \vert 000 \rangle_E \\
\vert 1 \rangle \longrightarrow \vert 111 \rangle_E
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert 0 \rangle \longrightarrow \vert 000 \rangle_E \\
\vert 1 \rangle \longrightarrow \vert 111 \rangle_E
\end{aligned}&lt;/script&gt;

&lt;p&gt;It means that a general qubit &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle = a \vert 0 \rangle + b \vert 1 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle = a \vert 0 \rangle + b \vert 1 \rangle&lt;/script&gt; will be encoded as &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle_E = a \vert 000 \rangle + b \vert 111 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle_E = a \vert 000 \rangle + b \vert 111 \rangle&lt;/script&gt;. We say that the code maps three &lt;strong&gt;physical qubits&lt;/strong&gt; into one &lt;strong&gt;logical qubit&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;When this encoded state goes through a noisy channel, errors can happen. But this time, we have some degree of protection. For instance, let’s say that a bit-flip occurred on the first qubit, leading to the state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \widetilde{\psi} \rangle_E = a \vert 100 \rangle + b \vert 011 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \widetilde{\psi} \rangle_E = a \vert 100 \rangle + b \vert 011 \rangle&lt;/script&gt;. We can then detect and correct this error, in the so-called &lt;strong&gt;decoding&lt;/strong&gt; process: we perform measurements to the state and apply some correction operators depending on the measurement results. However, here comes another specificity of the quantum setting: we cannot simply measure the whole state (and then apply a majority vote or something), as it would result in a general collapse of the state. So we need to apply non-destructive measurements, also called &lt;strong&gt;stabilizer measurements&lt;/strong&gt;. An example of stabilizer measurement would be to measure the parity of each pair of qubits, i.e. whether the two qubits are equal or not. For instance, the following circuit can be used to measure the parity of qubits 1 and 2:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/intro-qec/stabilizer-measurement.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Indeed, if the first two qubits are in the state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 00 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 00 \rangle&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 11 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 11 \rangle&lt;/script&gt;, you can check that the measurement result in the &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; basis will be &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt; (i.e. the ancilla qubit is in the &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 0 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 0 \rangle&lt;/script&gt; state), while if we are in either &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 01 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 01 \rangle&lt;/script&gt; or &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 10 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 10 \rangle&lt;/script&gt;, the measurement result will be &lt;code class=&quot;MathJax_Preview&quot;&gt;-1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;-1&lt;/script&gt;. Note that by measuring the ancilla qubit, our state has not been destroyed.&lt;/p&gt;

&lt;p&gt;So, what happens if we apply those parity measurements to the state &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \widetilde{\psi} \rangle_E = a \vert 100 \rangle + b \vert 011 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \widetilde{\psi} \rangle_E = a \vert 100 \rangle + b \vert 011 \rangle&lt;/script&gt;? We will see that qubits 2 and 3 are equal, while qubit 1 is different from the two others. Assuming that we only had one &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; error, we can deduce that the only possibility is that the first qubit has been subjected to a bit-flip. Therefore, we apply a Pauli &lt;code class=&quot;MathJax_Preview&quot;&gt;\text{X}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\text{X}&lt;/script&gt; operator on the first qubit to recover our original state.&lt;/p&gt;

&lt;p&gt;The quantum error-correction process can be summarized by the following diagram:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
\vert \psi \rangle \xrightarrow{\text{encoding}} \vert \psi \rangle_E \xrightarrow{\text{noise}} \vert \widetilde{\psi} \rangle_E \xrightarrow{\text{decoding}} \vert \psi \rangle_E
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
\vert \psi \rangle \xrightarrow{\text{encoding}} \vert \psi \rangle_E \xrightarrow{\text{noise}} \vert \widetilde{\psi} \rangle_E \xrightarrow{\text{decoding}} \vert \psi \rangle_E
\end{aligned}&lt;/script&gt;

&lt;p&gt;Note that our code has two major drawbacks: it cannot correctly decode more than one bit-flip errors, and cannot detect phase-flip errors at all. While the first problem could be alleviated by increasing the number of physical qubits, the second one is more fundamental and requires the design of more complex quantum codes. One of the most popular such code is the &lt;strong&gt;surface code&lt;/strong&gt; (also called &lt;strong&gt;toric code&lt;/strong&gt;), which belongs to the more general class of &lt;strong&gt;topological quantum codes&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;surface-code&quot;&gt;Surface code&lt;/h3&gt;

&lt;p&gt;Explaining exactly how the surface code work is a out-of-scope for this article, as it would require a proper introduction to the stabilizer formalism. However, given the importance this code has taken in the QEC world, I couldn’t resist giving you a big picture overview of its main characteristics, as a treat before I write a dedicated article on the topic! If you want to get a more in-depth explanation, feel free to look at the resources posted at the end of this article, such as &lt;a href=&quot;https://decodoku.medium.com/5-the-toric-code-part-1-caaa4b79afd8&quot;&gt;this series of blog post&lt;/a&gt; by James Wootton!&lt;/p&gt;

&lt;p&gt;So what is the surface code? It’s a code that encodes one logical qubit on a 2D grid of &lt;code class=&quot;MathJax_Preview&quot;&gt;L^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^2&lt;/script&gt; physical qubits. For instance, the picture below represents one logical qubit of the surface code, encoded with 25 physical qubits (the white dots). The two colors represent the two types of measurements that are used to detect errors, made either of &lt;code class=&quot;MathJax_Preview&quot;&gt;X&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;X&lt;/script&gt; operators (to detect phase-flips) or &lt;code class=&quot;MathJax_Preview&quot;&gt;Z&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;Z&lt;/script&gt; operators (to detect bit-flips), but we won’t dive into those details now.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/intro-qec/surface-code.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;To achieve noise levels that are low enough to run something like Shor’s algorithm might require grids containing between 1,000 and 10,000 physical qubits per logical qubit&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;! While it might sound like a huge overhead (and indeed, it is!), the surface code still has a few advantages, otherwise it wouldn’t be the most popular code in the market! First, contrary to the repetition code that we saw in the previous section, it can detect both bit-flips and phase-flips. Since doing so is one of the main difficulties in designing QEC codes and the reason why we cannot simply generalize classical codes, it is worth noting. A second advantage compared to other QEC codes is that it’s &lt;strong&gt;two-dimensional&lt;/strong&gt;. It means that in practice, we only need to arrange the qubits on a physical 2D chip with interaction between nearest neighbors, which makes the surface code particularly promising for superconducting chips like IBM’s and Google’s quantum computers. Finally, the threshold has been calculated to be around &lt;code class=&quot;MathJax_Preview&quot;&gt;\sim 1\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\sim 1\%&lt;/script&gt; (the exact number depends on the exact nature of the noise), which is one of the highest in the QEC zoo&lt;sup id=&quot;fnref:5:1&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;. As a reminder, the threshold is the noise level below which increasing the number of physical qubits (here the size of the grid) actually improves the number of errors that can be corrected. So to make the surface code work, it means that we just need our noise level to be below &lt;code class=&quot;MathJax_Preview&quot;&gt;1\%&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1\%&lt;/script&gt; (probably slightly lower in realistic settings), which is definitely within the range of what experimentalists can do!&lt;/p&gt;

&lt;p&gt;Note that many alternatives to the 2D surface code have been proposed, such as 3D and 4D surface codes, color codes, low-density parity-check codes (also known as LDPC codes), subsystem codes, etc. Choosing a code is often a trade-off between connectivity (e.g. LDPC codes often require long-range interaction, so are not easily implementable on 2D chips), ease of measurements (how many qubits are measured simultaneously to detect errors), performance with a given noise model, threshold, gate design, etc.&lt;/p&gt;

&lt;p&gt;Once the encoding and decoding procedures are established, there is still one last step before being able to do quantum computation error-free: designing logical gates that act on the code. It happens that this task is far from trivial in general, and a whole sub-field of QEC is dedicated to it. That’s the subject of &lt;strong&gt;fault-tolerant quantum computing&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;fault-tolerant-quantum-computing&quot;&gt;Fault-tolerant quantum computing&lt;/h2&gt;

&lt;h3 id=&quot;transversality-and-fault-tolerance&quot;&gt;Transversality and fault-tolerance&lt;/h3&gt;

&lt;p&gt;The main challenge in designing gates is to avoid the propagation of errors: if we’re not careful, multi-qubit gates can turn one-qubit errors into correlated multi-qubit ones. This is particularly disturbing when the gate couples several physical qubits representing a single logical one (what we call a &lt;strong&gt;block&lt;/strong&gt;). For instance, imagine you want to apply a logical Hadamard on the 3-repetition code considered earlier. This gate, that we can call &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt;, should use three physical qubits to act on one logical qubit, i.e.:&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
H \vert 0 \rangle = \frac{1}{\sqrt{2}} \left( \vert 0 \rangle + \vert 1 \rangle \right) \; \xrightarrow{\text{encoding}} \; H_L \vert 000 \rangle = \frac{1}{\sqrt{2}} \left( \vert 000 \rangle + \vert 111 \rangle \right) \\
H \vert 1 \rangle = \frac{1}{\sqrt{2}} \left( \vert 0 \rangle - \vert 1 \rangle \right) \; \xrightarrow{\text{encoding}} \; H_L \vert 111 \rangle = \frac{1}{\sqrt{2}} \left( \vert 000 \rangle - \vert 111 \rangle \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;\begin{aligned}
H \vert 0 \rangle = \frac{1}{\sqrt{2}} \left( \vert 0 \rangle + \vert 1 \rangle \right) \; \xrightarrow{\text{encoding}} \; H_L \vert 000 \rangle = \frac{1}{\sqrt{2}} \left( \vert 000 \rangle + \vert 111 \rangle \right) \\
H \vert 1 \rangle = \frac{1}{\sqrt{2}} \left( \vert 0 \rangle - \vert 1 \rangle \right) \; \xrightarrow{\text{encoding}} \; H_L \vert 111 \rangle = \frac{1}{\sqrt{2}} \left( \vert 000 \rangle - \vert 111 \rangle \right)
\end{aligned}&lt;/script&gt;

&lt;p&gt;To implement the unitary &lt;code class=&quot;MathJax_Preview&quot;&gt;H_L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H_L&lt;/script&gt;, some entangling gates will be needed. For example, you can check that the following circuit gives the correct unitary on &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 000 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 000 \rangle&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert 111 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert 111 \rangle&lt;/script&gt;:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/intro-qec/logical-hadamard-small.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The issue here is the presence of physical CNOTs &lt;em&gt;within the block&lt;/em&gt;, as they can create correlated errors that won’t be easily correctable.&lt;/p&gt;

&lt;p&gt;On the other hand, if we wanted to implement a logical CNOT between two logical qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle_1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle_1&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;\vert \psi \rangle_2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\vert \psi \rangle_2&lt;/script&gt;, we would simply use the following circuit&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/intro-qec/cnot-small.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;which doesn’t contain any entangling gate within each block. Such gate is called &lt;strong&gt;transversal&lt;/strong&gt;, while the Hadamard gate we saw previously was &lt;strong&gt;non-transversal&lt;/strong&gt;. An encoded circuit composed only of transversal gates is &lt;strong&gt;fault-tolerant&lt;/strong&gt;, meaning that it doesn’t propagate errors further.&lt;/p&gt;

&lt;p&gt;So, do we know any code such that all the gates can be built transversally? Unfortunately, the answer is no, and we even know that such code cannot exist. That’s the object of a foundational theorem in the field, called the &lt;a href=&quot;https://arxiv.org/abs/0811.4262&quot;&gt;Eastin-Knill theorem&lt;/a&gt;, which states that for any QEC code, there is no universal gate set&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; made only of transversal gates. For instance, in the surface code, only &lt;strong&gt;Clifford gates&lt;/strong&gt; can be implemented transversally, i.e all the gates that can be constructed from &lt;code class=&quot;MathJax_Preview&quot;&gt;H&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;CNOT&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;CNOT&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; gates. It includes all Pauli gates, but not the &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gate for example, which is required for universality.&lt;/p&gt;

&lt;h3 id=&quot;magic-state-distillation&quot;&gt;Magic state distillation&lt;/h3&gt;

&lt;p&gt;Many tricks have been proposed to “by-pass” this no-go theorem. One of the most common tricks is called &lt;strong&gt;magic state distillation&lt;/strong&gt;. To illustrate how it works, let’s say we want to implement a &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gate fault-tolerantly. As a reminder, the &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gate is a one-qubit gate defined by the matrix&lt;/p&gt;

&lt;pre class=&quot;MathJax_Preview&quot;&gt;&lt;code&gt;\begin{aligned}
    T = \left( \begin{matrix}
    1 &amp;amp; 0          \\
    0 &amp;amp; e^{i\pi/4} \\
    \end{matrix} \right)
\end{aligned}&lt;/code&gt;&lt;/pre&gt;
&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\begin{aligned}
    T = \left( \begin{matrix}
    1 &amp; 0          \\
    0 &amp; e^{i\pi/4} \\
    \end{matrix} \right)
\end{aligned} %]]&gt;&lt;/script&gt;

&lt;p&gt;and is one of the simplest examples of non-Clifford gate, meaning that it cannot be written out of just &lt;code class=&quot;MathJax_Preview&quot;&gt;H&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;CNOT&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;CNOT&lt;/script&gt;. On the other hand, appending it to the Clifford gate set leads to a universal gate set, i.e. any gate you can think of can be written out of just &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt;, &lt;code class=&quot;MathJax_Preview&quot;&gt;H&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;H&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;CNOT&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;CNOT&lt;/script&gt; (we don’t need &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; anymore, since &lt;code class=&quot;MathJax_Preview&quot;&gt;S=T^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S=T^2&lt;/script&gt;). Since the surface code can already implement all Clifford gates fault-tolerantly, it means that we only need a procedure to implement &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gates!&lt;/p&gt;

&lt;p&gt;The first idea of magic state distillation is to implement the state &lt;code class=&quot;MathJax_Preview&quot;&gt;T\vert+\rangle=\vert 0 \rangle + e^{i\pi/4} \vert 1 \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T\vert+\rangle=\vert 0 \rangle + e^{i\pi/4} \vert 1 \rangle&lt;/script&gt; non-fault-tolerantly on an ancilla qubit (meaning that errors can occur when creating the state) and to “inject” it in the qubits of our code, thereby creating a &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gate on those qubits. This trick, called &lt;strong&gt;state injection&lt;/strong&gt; (or &lt;strong&gt;gate teleportation&lt;/strong&gt; in the measurement-based QC community) can be summarized by the following circuit:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/intro-qec/magic-state-distillation.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;where the &lt;code class=&quot;MathJax_Preview&quot;&gt;S&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;S&lt;/script&gt; gate is applied when the measurement of the ancilla qubit leads &lt;code class=&quot;MathJax_Preview&quot;&gt;1&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;1&lt;/script&gt;. It’s a little exercise the check that the circuit above indeed leads to a &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gate (and you can find the answer on &lt;a href=&quot;https://quantumcomputing.stackexchange.com/questions/13629/what-are-magic states&quot;&gt;Stack Exchange&lt;/a&gt;). The state &lt;code class=&quot;MathJax_Preview&quot;&gt;T\vert + \rangle&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T\vert + \rangle&lt;/script&gt; is called a &lt;strong&gt;magic state&lt;/strong&gt;, and as we saw, its preparation can involve some errors (it’s not fault-tolerant). The second idea of magic state distillation is therefore distillation. By preparing &lt;code class=&quot;MathJax_Preview&quot;&gt;N&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;N&lt;/script&gt; copies of a noisy magic state, it’s possible to create an arbitrary clean &lt;code class=&quot;MathJax_Preview&quot;&gt;T&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;T&lt;/script&gt; gate (similarly to how &lt;a href=&quot;https://en.wikipedia.org/wiki/Entanglement_distillation&quot;&gt;entanglement distillation&lt;/a&gt; is done in quantum communication). The full protocol can be shown to be fault-tolerant, but it often requires a very large overhead in both the number of qubits and number of gates&lt;sup id=&quot;fnref:7&quot;&gt;&lt;a href=&quot;#fn:7&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt;. This overhead led to the claim that obtaining a quantum advantage with quadratic speed-ups might be unrealistic in the first fault-tolerant quantum computers&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;. Reducing this overhead or finding codes that don’t need magic state distillation is therefore a very important research problem.&lt;/p&gt;

&lt;h3 id=&quot;measurement-based-gates-lattice-surgery-and-twists&quot;&gt;Measurement-based gates: lattice surgery and twists&lt;/h3&gt;

&lt;p&gt;So far, we have presented transversal gates as the good guys of fault-tolerant quantum computing, as they can be implemented directly without propagating errors. However, transversal two-qubit gates, while fault-tolerant, are often far from practical. Take two logical qubits of the surface code for instance, and align them on a single 2D lattice.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/intro-qec/lattice-surgery.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;A transversal two-qubit gate would consist in &lt;code class=&quot;MathJax_Preview&quot;&gt;L^2&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L^2&lt;/script&gt; physical gates between each pair of qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;a&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;a'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a'&lt;/script&gt;. However, as seen in the picture above, it would require some long-range interactions, since qubits &lt;code class=&quot;MathJax_Preview&quot;&gt;a&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a&lt;/script&gt; and &lt;code class=&quot;MathJax_Preview&quot;&gt;a'&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;a'&lt;/script&gt; are always &lt;code class=&quot;MathJax_Preview&quot;&gt;L&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;L&lt;/script&gt; qubits apart. A solution could consist in putting one surface code above the other (in 3D). However, 3D chips are hard to build in practice, and it happens that more convenient solutions exist, namely &lt;strong&gt;lattice surgery&lt;/strong&gt; and &lt;strong&gt;twist deformations&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;In both methods, gates are applied by performing measurements and temporarily changing the code itself. In lattice surgery, those measurements allow to merge different surface codes into a single one, and split it again when needed. It can be shown that many gates, such as the CNOT gate, can be designed by performing such a series of merge and split operations. In twist deformations, measurements create holes in the lattice, and braiding operators around those holes allow to create some gates. All those operations are local, making both techniques amenable to real devices. I hope to describe those techniques in more details in future posts.&lt;/p&gt;

&lt;h3 id=&quot;measurement-errors&quot;&gt;Measurement errors&lt;/h3&gt;

&lt;p&gt;Finally, in fault-tolerant quantum computing, the measurement apparatus is also crucial. To detect errors, measurements are made all the time, and those can be very noisy. It means that our stabilizer measurements can lead to the wrong answer. 
To mitigate this effect, the basic technique simply consists in repeating the stabilizer measurements many times. However, some codes such as the 3D surface code have a property that make them amenable to &lt;strong&gt;single-shot quantum error correction&lt;/strong&gt;, as set of techniques that allow to correct errors with a single noisy measurement per stabilizer. More generally, any fault-tolerant scheme must also include a method to perform measurements without propagating errors in a non-fault-tolerant way.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;In this first post, we set eyes on the big picture of QEC and its different subfields. We discussed a lot of notions and introduced a lot of jargon, that we will review in detail in different posts, so don’t worry if a few things are unclear for the moment. Just retain that quantum error correction comprises two main challenges: designing an encoding process that can protect qubits against noise, and building actual circuits on the code without introducing more errors (the subject of fault-tolerance). In the meantime, feel free to use the following resources if you want to learn more about any of those topics.&lt;/p&gt;

&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Acknowledgment&lt;/strong&gt;: Big thanks to Shashvat Shukla and Michał Stęchły for their detailed feedback on this blog post!&lt;/p&gt;

&lt;h2 id=&quot;resources&quot;&gt;Resources&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/abs/1907.11157&quot;&gt;Quantum Error Correction: An Introductory Guide&lt;/a&gt;, by Joschka Roffe&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://sites.google.com/site/danbrowneucl/teaching/lectures-on-topological-codes-and-quantum-computation&quot;&gt;Lectures on Topological Codes and Quantum Computation&lt;/a&gt;, by Dan Browne&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=ltJ1jXQeDl8&amp;amp;ab_channel=InstituteforQuantumComputing&quot;&gt;Video lectures on Quantum Error Correction and Fault Tolerance&lt;/a&gt;, by Daniel Gottesman&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://mmrc.amss.cas.cn/tlb/201702/W020170224608149940643.pdf&quot;&gt;Quantum Computation and Quantum Information — Chapter 7&lt;/a&gt;, Nielsen &amp;amp; Chuang&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://decodoku.medium.com/1-what-is-quantum-error-correction-4ab6d97cb398&quot;&gt;What is Quantum Error Correction&lt;/a&gt;, series of blog posts by James Wootton&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Richard Hamming, &lt;a href=&quot;http://worrydream.com/refs/Hamming-TheArtOfDoingScienceAndEngineering.pdf&quot;&gt;The Art of Doing Science and Engineering&lt;/a&gt;, 1997 &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;E. Knill, R. Laflamme, W. Zurek, &lt;a href=&quot;https://arxiv.org/abs/quant-ph/9610011&quot;&gt;Threshold Accuracy for Quantum Computation&lt;/a&gt;, 1996 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Eric Dennis, Alexei Kitaev, Andrew Landahl, John Preskill, &lt;a href=&quot;https://arxiv.org/abs/quant-ph/0110143&quot;&gt;Topological quantum memory&lt;/a&gt;, 2001 &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;David S. Wang, Austin G. Fowler, Lloyd C. L. Hollenberg, &lt;a href=&quot;https://arxiv.org/abs/1009.3686&quot;&gt;Quantum computing with nearest neighbor interactions and error rates over 1%&lt;/a&gt;, 2010 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Austin G. Fowler, Matteo Mariantoni, John M. Martinis,  Andrew N. Cleland, &lt;a href=&quot;https://arxiv.org/abs/1208.0928&quot;&gt;Surface codes: Towards practical large-scale quantum computation&lt;/a&gt; &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt; &lt;a href=&quot;#fnref:5:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;Here, a universal gate set is defined as a set that can approximate any unitary up to a precision &lt;code class=&quot;MathJax_Preview&quot;&gt;\epsilon&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\epsilon&lt;/script&gt; with &lt;code class=&quot;MathJax_Preview&quot;&gt;O\left(\log\left( \frac{1}{\epsilon}\right)^c\right)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;O\left(\log\left( \frac{1}{\epsilon}\right)^c\right)&lt;/script&gt; gates. &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:7&quot;&gt;
      &lt;p&gt;Sergey Bravyi, Jeongwan Haah, &lt;a href=&quot;https://arxiv.org/abs/1209.2426&quot;&gt;Magic-state distillation with low overhead&lt;/a&gt; &lt;a href=&quot;#fnref:7&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;Ryan Babbush, Jarrod McClean, Michael Newman, Craig Gidney, Sergio Boixo, Hartmut Neven, &lt;a href=&quot;https://arxiv.org/abs/2011.04149&quot;&gt;Focus beyond quadratic speedups for error-corrected quantum advantage&lt;/a&gt; &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="quantum-computing" /><summary type="html">This Summer marked the beginning of my thesis work, and with it, of my trip in the fascinating world of quantum error correction. I quickly found in this area the interdisciplinarity that I love: the field takes its roots in theoretical computer science (classical error correction), uses intuitions and techniques from theoretical physics (condensed matter, statistical physics, quantum field theory) and has deep connections to black hole research, statistical inference, algebraic topology and geometry, and many other areas of science and mathematics.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/intro-qec/thumbnail.png" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/intro-qec/thumbnail.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Improve your Scientific Models with Meta-Learning and Likelihood-Free Inference</title><link href="https://arthurpesah.me/blog/2018-12-23-alfi/" rel="alternate" type="text/html" title="Improve your Scientific Models with Meta-Learning and Likelihood-Free Inference" /><published>2018-12-23T00:00:00+01:00</published><updated>2018-12-23T00:00:00+01:00</updated><id>https://arthurpesah.me/blog/alfi</id><content type="html" xml:base="https://arthurpesah.me/blog/2018-12-23-alfi/">&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: This post was first published as a &lt;a href=&quot;https://towardsdatascience.com/improve-your-scientific-models-with-meta-learning-and-likelihood-free-inference-2f904d0bd7fa&quot;&gt;Medium Article&lt;/a&gt; for Towards Data Science&lt;/p&gt;
&lt;p&gt;Introduction to likelihood-free inference and distillation of the paper &lt;a href=&quot;https://arxiv.org/abs/1811.12932&quot;&gt;Recurrent Machines for Likelihood-Free Inference&lt;/a&gt;, published at the &lt;a href=&quot;http://metalearning.ml&quot;&gt;NeurIPS 2018 Workshop on Meta-Learning&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Article jointly written by Arthur Pesah and Antoine Wehenkel&lt;/p&gt;

&lt;h1 id=&quot;motivation&quot;&gt;Motivation&lt;/h1&gt;

&lt;p&gt;There are usually two ways of coming up with a new scientific theory:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Starting from first principles, deducing the consequent laws, and coming up with experimental predictions in order to verify the theory&lt;/li&gt;
  &lt;li&gt;Starting from experiments and inferring the simplest laws that explain your data.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The role of statistics and machine learning in science is usually related to the second kind of inference, also called &lt;em&gt;induction&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Imagine for instance that you want to model the evolution of two populations (let’s say foxes and rabbits) in an environment. A simple model is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Lotka–Volterra_equations&quot;&gt;Lotka-Volterra differential equation&lt;/a&gt;: you consider the probability that an event such as “a fox eating a rabbit”, “a rabbit being born”, “a fox being born”, etc. happens in a small time interval, deduce a set of differential equations depending on those probabilities, and predict the evolution of the two animals by solving those equations. By comparing your prediction with the evolution of a real population, you can infer the best model parameters (probabilities) in this environment.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*t9Lv2LZ6EJiutaVzKoQ3lQ.jpeg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Modern theories require &lt;strong&gt;simulations&lt;/strong&gt; in order to be linked to observations. It can be either a simple differential equation solver as in the case of the Lotka-Volterra model, or a complex Monte-Carlo simulator as they use in particle physics for instance.&lt;/p&gt;

&lt;p&gt;By comparing the results of a simulation, i.e. the predictions of a model, with real data, it is then possible to know the correctness of your model and adjust it accordingly. If this process of going back and forth between the model and the experimental data is usually done manually, the question that any machine learning practitioner would ask is: can we do it automatically? Can we build a machine that takes a tweakable simulator and real data as input, and returns the version of the simulator that fits best some real data?&lt;/p&gt;

&lt;p&gt;That’s the object of our recent work&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, where we trained a neural network to come up with the best sequence of simulator tweaks in order to approximate experimental data, capitalizing on the recent advances in the fields of likelihood-free inference and meta-learning.&lt;/p&gt;

&lt;h1 id=&quot;likelihood-free-inference&quot;&gt;Likelihood-free inference&lt;/h1&gt;

&lt;p&gt;Let’s rephrase our problem in a more formal way. We can model a simulator (also called generative model) by a stochastic function that takes some parameters &lt;code class=&quot;MathJax_Preview&quot;&gt;\theta&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; and returns samples &lt;code class=&quot;MathJax_Preview&quot;&gt;x&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;x&lt;/script&gt; drawn from a certain distribution (the so-called &lt;em&gt;model&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;This formalism applies to any scientific theory that includes randomness, as it’s very often the case in modern science (particle collisions are governed by the law of quantum physics which are intrinsically random, biological processes or chemical reactions often occur in a noisy environment, etc.).&lt;/p&gt;

&lt;p&gt;Experimental data consist in a set of points living in the same space as the output of the simulator. The goal of inference is then to find the parameters &lt;code class=&quot;MathJax_Preview&quot;&gt;\theta&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; such that the simulator generate points as close as possible to the real data.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*328OmNFA4xBuj4xgLQdK9w.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Scientific fields using such simulators include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Population genetics. &lt;strong&gt;Model:&lt;/strong&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Coalescent_theory&quot;&gt;Coalescent theory&lt;/a&gt;. &lt;strong&gt;Observation:&lt;/strong&gt; the DNA of a current population. &lt;strong&gt;Parameters:&lt;/strong&gt; the DNA of the common ancestor.&lt;/li&gt;
  &lt;li&gt;High-energy particle physics. &lt;strong&gt;Model&lt;/strong&gt;: &lt;a href=&quot;https://en.wikipedia.org/wiki/Standard_Model&quot;&gt;Standard Model&lt;/a&gt; of particle physics. &lt;strong&gt;Observation:&lt;/strong&gt; output of the detector during a collision. &lt;strong&gt;Parameters:&lt;/strong&gt; coupling constants of the Standard Model (like the mass of the particles or the strength of the different forces).&lt;/li&gt;
  &lt;li&gt;Computational neuroscience. &lt;strong&gt;Model:&lt;/strong&gt; &lt;a href=&quot;https://en.wikipedia.org/wiki/Hodgkin%E2%80%93Huxley_model&quot;&gt;Hodgkin-Huxley model&lt;/a&gt;. &lt;strong&gt;Observation:&lt;/strong&gt; evolution of the voltage of a neuron after activation. &lt;strong&gt;Parameters&lt;/strong&gt;: biophysical parameters of the neuron.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So how can we predict the parameters of a simulator given some real observations? Let’s consider the simple example of a Gaussian simulator, that takes a vector &lt;code class=&quot;MathJax_Preview&quot;&gt;\theta=(\mu,\sigma)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\theta=(\mu,\sigma)&lt;/script&gt; as parameters and returns samples from the Gaussian distribution &lt;code class=&quot;MathJax_Preview&quot;&gt;\mathcal{N}(\mu,\sigma)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\mathcal{N}(\mu,\sigma)&lt;/script&gt;.&lt;/p&gt;

&lt;p&gt;The classical way to infer the parameters of such a simulator is called &lt;em&gt;Maximum Likelihood Estimation (MLE)&lt;/em&gt;. The likelihood is defined as the density of the real data under a parametric model. It means that if most data points are located in high density regions, the likelihood will be high. Hence, the best parameters of a model are often the ones that maximize the likelihood of real data. If you are unfamiliar with likelihood-based inference, you can read &lt;a href=&quot;https://towardsdatascience.com/probability-concepts-explained-maximum-likelihood-estimation-c7b4342fdbb1&quot;&gt;this excellent introduction to the subject&lt;/a&gt;.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*16t2IyuYfARkjea8mfUDTQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If you have explicitly access to the underlying probability distribution of your simulator, as well as the gradient of this distribution, you can for instance perform a gradient descent in the parameters space, in order to maximize the likelihood and infer the best parameters of your model.&lt;/p&gt;

&lt;p&gt;However, many real-life simulators have an &lt;strong&gt;intractable likelihood&lt;/strong&gt;, which means that the explicit probability distribution is too hard to compute (either analytically or numerically) . We must therefore find new ways to infer the optimal parameters without using neither the likelihood function nor its gradient.&lt;/p&gt;

&lt;p&gt;To sum it up, we have a black-box stochastic simulator that takes parameters and generates samples from an unknown probability distribution, as well as real data that we are able to compare to the generated ones. Our goal is to find the parameters that lead the simulator to generate data as close as possible to the real ones. This setting is called &lt;strong&gt;likelihood-free inference&lt;/strong&gt;.&lt;/p&gt;

&lt;h1 id=&quot;how-can-we-likelihood-free-infer&quot;&gt;How can we likelihood-free infer?&lt;/h1&gt;

&lt;p&gt;Let’s try to come up progressively with a method to solve our problem. The first thing we can do is to start from a random parameter, and simulate the corresponding data:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*Dgh8KZYJ_aAYYI73jy8wUQ.png&quot; alt=&quot;&quot; /&gt;&lt;em&gt;Representation of the two spaces of interest. The true parameter (that we wish to infer) is the red point on the left. The real data correspond to the red cloud of points on the right. We start by choosing a random parameter θ (in gray on the left) and simulating the corresponding data points (in gray on the right)&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;By doing so, we can see how far our generated data are from the real data, but we have no way to know where to move in the parameter-space. Instead, let’s simulate several parameters:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*a6mfrolFz-s9CicMOULgvA.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
&lt;p&gt;To do so, we consider a distribution in the parameter-space, called &lt;strong&gt;proposal distribution&lt;/strong&gt; and noted &lt;code class=&quot;MathJax_Preview&quot;&gt;q(\theta|\psi)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;q(\theta|\psi)&lt;/script&gt;. If we choose &lt;code class=&quot;MathJax_Preview&quot;&gt;q&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;q&lt;/script&gt; to be a Gaussian distribution, we will have &lt;code class=&quot;MathJax_Preview&quot;&gt;\psi=(\mu,\sigma)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\psi=(\mu,\sigma)&lt;/script&gt;. The first step consists in initializing &lt;code class=&quot;MathJax_Preview&quot;&gt;\psi&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt; randomly. In the figure above, we considered &lt;code class=&quot;MathJax_Preview&quot;&gt;\psi=\mu&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\psi=\mu&lt;/script&gt; for simplicity. Then, we can perform the following step until convergence:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sampling a few parameters from the proposal distribution: 4 parameters around &lt;code class=&quot;MathJax_Preview&quot;&gt;\psi&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt; in the figure.&lt;/li&gt;
  &lt;li&gt;Generating data from them: the 4 cloud of points on right.&lt;/li&gt;
  &lt;li&gt;Choosing a good direction to move &lt;code class=&quot;MathJax_Preview&quot;&gt;\psi&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The third step is the hard one. Intuitively, you would like to move &lt;code class=&quot;MathJax_Preview&quot;&gt;\psi&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt; towards the orange and green parameters, since the corresponding predictions (orange and green cloud of points) are the closest to the real data. A set of methods, called &lt;em&gt;natural evolution strategies&lt;/em&gt; &lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, allow you to link the performance of each &lt;code class=&quot;MathJax_Preview&quot;&gt;\theta&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (in terms of similarity between its predictions and the real data) to a direction in the parameter space. A recent paper &lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt; use for instance the similarity measure given by a Generative Adversarial Network (GAN) to find the best direction. Even though those algorithms perform well in the general case, one can wonder if for a given simulator, it is not possible to find a better algorithm that would exploit the particular properties of this simulator. That’s where meta-learning comes into play!&lt;/p&gt;

&lt;h1 id=&quot;meta-learning-for-optimization&quot;&gt;Meta-learning for optimization&lt;/h1&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*Wip2SwVt4aMqBPtE2Spffw.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;The idea behind meta-learning is to learn how to learn, and in our case to &lt;strong&gt;learn the optimization process&lt;/strong&gt;. The main idea, introduced in the paper &lt;a href=&quot;https://arxiv.org/abs/1606.04474&quot;&gt;Learning to learn gradient descent by gradient descent&lt;/a&gt;&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, is to use a recurrent neural network (RNN) to find the best descent direction at each iteration. Below is an example of sequence of points produced by a randomly initialized RNN:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*5Axutz0l_0TjxRupjEt-1Q.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Each descent direction is random and the last point produced is far from the minimum. During training, it should learn to exploit the gradient information at each point in order to move toward the minimum, giving something like:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*r2Ww8UZAmL3cBRds_p35OQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So how to train it? Generate many functions whose you know the minimum, and ask the RNN to minimize the distance between the last point of the sequence and the real minimum.&lt;/p&gt;

&lt;h1 id=&quot;learning-to-learn-scientific-models&quot;&gt;Learning to learn scientific models&lt;/h1&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*qKC9tH01bkQ_giLs_yGJxg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;In the case of likelihood-free inference, the RNN should return a sequence of proposal parameters &lt;code class=&quot;MathJax_Preview&quot;&gt;\psi&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\psi&lt;/script&gt;, given the real observations and the generated cloud of points at each step.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*La-daJwmoy6ksOpAeIrFkQ.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Now, same question as for learning to learn by gradient descent, how do we train the RNN? Here, the trick is to generate many random parameters θ and to pretend for each one that it is the “true parameter”. We can then simulate each θ generated and obtain a set of “real observations”. The RNN can then be trained by passing it those real observations, looking at its final proposal distribution, and comparing it to the true parameter (that we know because we have generated it).&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*7j8kOuY8p0MlwLXnDVzOEg.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Let’s go through an example to clarify all of that. In the figures below, the proposal distribution is represented in color (red = high density). At the beginning, the RNN is initialized randomly and we evaluate it on our first generated true parameter &lt;code class=&quot;MathJax_Preview&quot;&gt;\theta&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;\theta&lt;/script&gt; (in red).&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*_PA7u4qOMkAnVEMm73XPiQ.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can then backpropagate the loss into the RNN. After repeating this process for 200 different “true parameters”, this is what is should look like:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*j6eVXNAOHY3rQxD2AqjKWQ.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We can see that it has learnt to exploit the information of the observation space to move towards the good parameter.&lt;/p&gt;

&lt;h1 id=&quot;results&quot;&gt;Results&lt;/h1&gt;

&lt;p&gt;We evaluated our model on different toy simulators, some where we the likelihood is known and some where it is not.&lt;/p&gt;

&lt;h2 id=&quot;non-likelihood-free-problem-poisson-simulator&quot;&gt;Non-likelihood-free problem: Poisson Simulator&lt;/h2&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*204e7qk6Ml3dmQhwbjx7rw.png&quot; alt=&quot;&quot; /&gt;&lt;em&gt;Example of Poisson distributions for various parameters. Source: Wikipedia&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The first simulator takes a parameter λ and draw samples from a Poisson distribution &lt;code class=&quot;MathJax_Preview&quot;&gt;P(\lambda)&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;P(\lambda)&lt;/script&gt;. The goal of this example was to see if we obtain comparable performance as the maximum likelihood estimator. Here are the results:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*ALQZ7-7AD6RVjJqQpgXfMA.png&quot; alt=&quot;&quot; /&gt;&lt;em&gt;Comparison of ALFI (Automatic Likelihood-Free Inference, the name of our model), to a maximum likelihood estimator (MLE). Those box-plots represent the distribution of the mean-squared errors between the true parameters and the expected value of the final proposal distributions.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;We can see that the performance are comparable, even though we didn’t give our model access to the likelihood.&lt;/p&gt;

&lt;h2 class=&quot;figure&quot; id=&quot;likelihood-free-problem-particle-physics-simulator&quot;&gt;Likelihood-free problem: Particle Physics Simulator&lt;/h2&gt;

&lt;p&gt;To evaluate our model in a true likelihood-free setting, we considered a simplified particle physics model that simulate the collision of an electron and a positron turning into a muon and an antimuon.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*_Zpy-kvc2wiMW-9KzowoLw.png&quot; alt=&quot;&quot; /&gt;&lt;em&gt;Feynman diagram of the simulated process&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The parameters of the simulator are the energy of the incoming particles and the Fermi constant, and the output is the angle between the two muons.&lt;/p&gt;

&lt;p&gt;To evaluate our method, we compared the real observations with the ones generated by the last parameter found. Here are the results:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/1600/1*gr7tU9hWoGt8FRkPpZKppQ.png&quot; alt=&quot;&quot; /&gt;&lt;em&gt;Results of our method on a simple particle physics model. Comparison of our the real observations (angles of the produced particles) with the ones generated by our predicted parameter.&lt;/em&gt;&lt;/p&gt;

&lt;h1 id=&quot;discussion&quot;&gt;Discussion&lt;/h1&gt;

&lt;p&gt;We saw what likelihood-free inference is and how meta-learning can be used to solve it by learning the best sequence of simulator tweaks to fit a model to the reality.&lt;/p&gt;

&lt;p&gt;As most meta-learning models, a limitation is that it is hard to train. We had trouble scaling our method to more complex simulators, since meta-training requires a lot of simulator calls, which might be very slow in real-world settings. However, as the field of meta-learning makes progress, we hope that new methods will emerge to alleviate this problem and make it more scalable.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;A. Pesah, A. Wehenkel and G. Louppe, &lt;a href=&quot;https://arxiv.org/abs/1811.12932&quot;&gt;Recurrent Machines for Likelihood-Free Inference&lt;/a&gt; (2018), NeurIPS 2018 Workshop on Meta-Learning &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;D. Wierstra, T. Schaul, T. Glasmachers, Y. Sun, J. Peter, J. Schmidhuber, &lt;a href=&quot;http://jmlr.org/papers/v15/wierstra14a.html&quot;&gt;Natural Evolution Strategies&lt;/a&gt; (2014), Journal of Machine Learning Research (JMLR). &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;G. Louppe, J. Hermans, K. Cranmer, &lt;a href=&quot;https://arxiv.org/abs/1707.07113&quot;&gt;Adversarial Variational Optimization of Non-Differentiable Simulator&lt;/a&gt; (2017), arXiv e-prints 1707.07113 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;M. Andrychowicz, M. Denil, S. Gomez, M. W. Hoffman, D. Pfau, T. Schaul, B. Shillingford, N. de Freitas, &lt;a href=&quot;https://arxiv.org/abs/1606.04474&quot;&gt;Learning to learn gradient descent by gradient descent&lt;/a&gt; (2016), NIPS 2016 &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="machine-learning" /><summary type="html">Note: This post was first published as a Medium Article for Towards Data Science Introduction to likelihood-free inference and distillation of the paper Recurrent Machines for Likelihood-Free Inference, published at the NeurIPS 2018 Workshop on Meta-Learning.</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/alfi/cms_coverl.jpg" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/alfi/cms_coverl.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Recent Advances for a Better Understanding of Deep Learning</title><link href="https://arthurpesah.me/blog/2018-08-19-theory-deep-learning/" rel="alternate" type="text/html" title="Recent Advances for a Better Understanding of Deep Learning" /><published>2018-08-19T00:00:00+02:00</published><updated>2018-08-19T00:00:00+02:00</updated><id>https://arthurpesah.me/blog/theory-deep-learning</id><content type="html" xml:base="https://arthurpesah.me/blog/2018-08-19-theory-deep-learning/">&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: This post was first published as a &lt;a href=&quot;https://towardsdatascience.com/recent-advances-for-a-better-understanding-of-deep-learning-part-i-5ce34d1cc914&quot;&gt;Medium Article&lt;/a&gt; for Towards Data Science*&lt;/p&gt;

&lt;blockquote class=&quot;lead&quot;&gt;
  &lt;p&gt;I would like to live in a world whose systems are built on &lt;strong&gt;rigorous, reliable, verifiable knowledge&lt;/strong&gt;, and not on alchemy. […] Simple experiments and simple theorems are the &lt;strong&gt;building blocks&lt;/strong&gt; that help understand complicated larger phenomena.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This call for a better &lt;strong&gt;understanding&lt;/strong&gt; of deep learning was the core of Ali Rahimi’s &lt;a href=&quot;http://www.argmin.net/2017/12/05/kitchen-sinks/&quot;&gt;Test-of-Time Award presentation&lt;/a&gt; at NIPS in December 2017. By comparing deep learning with alchemy, the goal of Ali was not to dismiss the entire field, but “&lt;a href=&quot;http://www.argmin.net/2017/12/11/alchemy-addendum/&quot;&gt;to open a conversation&lt;/a&gt;”. This goal &lt;a href=&quot;https://syncedreview.com/2017/12/12/lecun-vs-rahimi-has-machine-learning-become-alchemy/&quot;&gt;has definitely been achieved&lt;/a&gt; and people &lt;a href=&quot;https://twitter.com/RandomlyWalking/status/1017899452378550273&quot;&gt;are still debating&lt;/a&gt; whether our current practice of deep learning should be considered as alchemy, engineering or science.&lt;/p&gt;

&lt;p&gt;Seven months later, the machine learning community gathered again, this time in Stockholm for the International Conference on Machine Learning (ICML). With more than 5,000 participants and 629 papers published, it was one of the most important events regarding fundamental machine learning research. And &lt;strong&gt;deep learning theory&lt;/strong&gt; has become one of the biggest subjects of the conference.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/trends.jpg&quot; alt=&quot;trends&quot; /&gt;&lt;/p&gt;

&lt;p&gt;This renew interest was revealed on the first day, with one of the biggest rooms of the conference full of machine learning practitioners ready to listen to the tutorial &lt;a href=&quot;http://unsupervised.cs.princeton.edu/deeplearningtutorial.html&quot;&gt;Towards Theoretical Understanding of Deep Learning&lt;/a&gt; by Sanjeev Arora. In his talk, the Professor of computer science at Princeton summarized the current areas of deep learning theory research, by dividing them into four branches:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Non Convex Optimization&lt;/strong&gt;: How can we understand the highly non-convex loss function associated with deep neural networks? Why does stochastic gradient descent even converge?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Overparametrization and Generalization&lt;/strong&gt;: In classical statistical theory, generalization depends on the number of parameters but not in deep learning. Why? Can we find another good measure of generalization?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Role of Depth&lt;/strong&gt;: How does depth help a neural network to converge? What is the link between depth and generalization?&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Generative Models&lt;/strong&gt;: Why do Generative Adversarial Networks (GANs) work so well? What theoretical properties could we use to stabilize them or avoid mode collapse?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this series of articles, we will try to build intuition in those four areas based on the most recent papers, with a particular focus on ICML 2018.&lt;/p&gt;

&lt;p&gt;This first article will focus on the mysteries of non-convex optimization for deep networks.&lt;/p&gt;

&lt;h1 id=&quot;non-convex-optimization&quot;&gt;Non-Convex Optimization&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/energy-landscape.png&quot; alt=&quot;energy-landscape&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;I bet a lot of you have tried training a deep net of your own from scratch and walked away feeling bad about yourself because you couldn’t get it to perform. I don’t think it’s your fault. I think it’s gradient descent’s fault.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;stated Ali Rahimi with a provocative tone in his talk at NIPS. Stochastic Gradient Descent (SGD) is indeed the cornerstone of deep learning. It is supposed to find a solution of a highly non-convex optimization problem, and understanding when it works or not, and why, is one the most fundamental questions we would have to adress in a general theory of deep learning. More specifically, the study of non-convex optimization for deep neural networks can be divided into two questions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;What does the loss function look like?&lt;/li&gt;
  &lt;li&gt;Why does SGD converge?&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;what-does-the-loss-function-look-like&quot;&gt;What does the loss function look like?&lt;/h1&gt;

&lt;p&gt;If I ask you to visualize a global minimum, it’s very likely that the first representation that will come to your mind will look something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/minimum.png&quot; alt=&quot;minimum&quot; /&gt;&lt;/p&gt;

&lt;p&gt;And it’s normal. In a 2D-world, it’s not rare to find problems, where around a global minimum, your function will be &lt;strong&gt;strictly&lt;/strong&gt; convex (which means that the two eigenvalues of the hessian matrix at this point will be both strictly positive). But in a world with billions of parameters, as it is the case in deep learning, what are the odds that none of the directions around a global minimum are flat? Or equivalently that the hessian contains not a single zero (or almost zero) eigenvalue?&lt;/p&gt;

&lt;p&gt;One of the first comment of Sanjeev Arora in his tutorial was that the number of possible directions that you can take on a loss function grows exponentially with the dimension.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/curse-dimensionality.png&quot; alt=&quot;curse-dimensionality&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Then, intuitively, it seems likely that a global minimum will not be a point, but a &lt;strong&gt;connected manifold&lt;/strong&gt;. Which means that if you’ve reached a global minimum, you should be able to walk around on a flat path where all the points are also minima. This has been experimentally proven on large networks by a team at Heidelberg University, in their paper &lt;a href=&quot;https://icml.cc/Conferences/2018/Schedule?showEvent=2780&quot;&gt;Essentially No Barriers in Neural Network Energy Landscape&lt;/a&gt;&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;. They argue an even more general statement, namely that any two global minima can be connected through a flat path.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/no-barrier.png&quot; alt=&quot;no-barrier&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It was already known to be the case for a CNN on MNIST or an RNN on PTB&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;, but this work extended that knowledge to much bigger networks (some DenseNets and ResNets) trained on more advanced datasets (CIFAR10 and CIFAR100). To find this path, they used a heuristic coming from molecular statistical mechanics, called AutoNEB. The idea is to create an initial path (for instance linear) between your two minima, and to place pivots on that path. You then iteratively modify the positions of the pivots, such that it minimizes the loss of each pivot and make sure the distances between pivots stay about the same (by modelling the space between pivots by springs).&lt;/p&gt;

&lt;p&gt;If they didn’t prove that result theoretically, they gave some intuitive explanations on why such path exists:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;If we perturb a single parameter, say by adding a small constant, but leave the others free to adapt to this change to still minimise the loss, it may be argued that by adjusting somewhat, the myriad other parameters can “make up” for the change imposed on only one of them&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thus, the results of this paper can help us seeing minima in a different way, through the lens of overparametrization and high-dimensional spaces.&lt;/p&gt;

&lt;p&gt;More generally, when thinking about the loss function of neural network, you should always have in mind that the number of possible directions at a given point is huge. Another consequence of that is the fact that saddle points must be much more abundant than local minima: at a given (critical) point, among the billions of possible directions, it’s very likely to find one that goes down (if you’re not in a global minimum). This intuition was formalized rigorously and proved empirically in a paper published at NIPS 2014: &lt;a href=&quot;https://arxiv.org/abs/1406.2572&quot;&gt;Identifying and attacking the saddle point problem in high-dimensional non-convex optimization&lt;/a&gt;&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;

&lt;h1 id=&quot;why-does-sgd-converge-or-not&quot;&gt;Why does SGD converge (or not)?&lt;/h1&gt;

&lt;p&gt;The second important question in optimization of deep neural networks is related to the convergence properties of SGD. While this algorithm has long been seen as a faster but approximate version of gradient descent, we now have evidence that SGD actually converges to better, more general, minima&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;. But can we formalize it and explain quantitatively the capacity of SGD to escape from local minima or saddle points?&lt;/p&gt;

&lt;h2 id=&quot;sgd-modifies-the-loss-function&quot;&gt;SGD modifies the loss function&lt;/h2&gt;

&lt;p&gt;The paper &lt;a href=&quot;https://arxiv.org/abs/1802.06175&quot;&gt;An Alternative View: When Does SGD Escape Local Minima?&lt;/a&gt;&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt; showed that performing SGD is equivalent to doing regular gradient descent on a convolved (thus smoothed) loss function. With that point of view and under certain assumptions (shown by the authors to be often true in practice), they prove that SGD will manage to escape local minima and converge to a small region around a global minimum.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/sgd-convolution.png&quot; alt=&quot;sgd-convolution&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;sgd-is-governed-by-stochastic-differential-equations&quot;&gt;SGD is governed by stochastic differential equations&lt;/h2&gt;

&lt;p&gt;Another approach to SGD that has really changed my vision of this algorithm is continuous SGD. The idea was presented by Yoshua Bengio during his talk &lt;a href=&quot;http://www.iro.umontreal.ca/~bengioy/talks/ICMLW-nonconvex-14july2018.pptx.pdf&quot;&gt;On stochastic gradient descent, flatness and generalization&lt;/a&gt;, given at the ICML Workshop on Non-Convex Optimization. SGD does not move a point on a loss function, but a &lt;strong&gt;cloud of points&lt;/strong&gt;, or in other words, &lt;strong&gt;a distribution&lt;/strong&gt;.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/bengio-01.png&quot; alt=&quot;bengio-01&quot; /&gt;
Slide extracted from the presentation On stochastic gradient descent, flatness and generalization, 
by Y. Bengio, at ICML 2018. He presented an alternative way to see SGD, 
where you replace points by distributions (clouds of points)&lt;/p&gt;

&lt;p&gt;The size of this cloud of point (i.e. the variance of the associated distribution) is proportional to the factor &lt;em&gt;learning_rate / batch_size&lt;/em&gt;. A proof of this is given in the amazing paper by Pratik Chaudhari and Stefano Soatto, &lt;a href=&quot;https://arxiv.org/pdf/1710.11029.pdf&quot;&gt;Stochastic gradient descent performs variational inference&lt;/a&gt;, converges to limit cycles for deep networks&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;, that they presented during the Workshop on Geometry in Machine Learning. This formula is quite intuitive: a low batch size means a very noisy gradient (because computed on a very small subset of the dataset), and a high learning rate means noisy steps.&lt;/p&gt;

&lt;p&gt;The consequence of seeing SGD as a distribution moving over time is that the equations governing the descent are now &lt;a href=&quot;https://en.wikipedia.org/wiki/Stochastic_partial_differential_equation&quot;&gt;stochastic partial differential equations&lt;/a&gt;. More precisely, under certain assumptions, [5] showed that the governing equation is actually a &lt;a href=&quot;https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation&quot;&gt;Fokker-Planck equation&lt;/a&gt;.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/continuous-sgd.jpeg&quot; alt=&quot;continuous-sgd&quot; /&gt;
Slide extracted from the presentation High-dimensional Geometry and Dynamics of 
Stochastic Gradient Descent for Deep Networks, by P. Chaudhari and S. Soatto, at ICML 2018. 
They showed how to pass from a discrete system to a continuous one described
by the Fokker-Plank equation&lt;/p&gt;

&lt;p&gt;In statistical physics, this type of equations describes the evolution of particles exposed to a drag force (that drifts the distribution, i.e. moves its mean) and to random forces (that diffuse the distribution, i.e. increase its variance). In SGD, the drag force is modeled by the true gradient while the random forces correspond to noise inherent to the algorithm. As you can see in the slide above, the diffusion term is proportional to a temperature term T=1/β=learning_rate/(2*batch_size), which shows once again the importance of this ratio!&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/FokkerPlanck.gif&quot; alt=&quot;FokkerPlanck&quot; /&gt;
Evolution of a distribution under the Fokker-Planck equation. 
It drifts on the left and diffuses with time. 
Source: Wikipedia&lt;/p&gt;

&lt;p&gt;Using this framework, Chaudhari and Soatto proved that our distribution will monotonically converge to a certain steady distribution (in the sense of the KL-divergence):&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/theory-deep-learning/theorem-5.png&quot; alt=&quot;theorem-5&quot; /&gt;
One of the main theorems of [5], proving monotonic convergence of the distribution to a steady state 
(in the sense of the KL divergence). The second equation shows that minimizing F is equivalent to 
minimizing a certain potential ϕ as well as maximizing the entropy of the distribution 
(trade-off controlled by the temperature 1/β)*&lt;/p&gt;

&lt;p&gt;There are several interesting points to comment in the theorem above:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The functional that is minimized by SGD can be rewritten as a sum of two terms (Eq. 11): the expectancy of a potential Φ, and the entropy of the distribution. The temperature 1/β controls the trade-off between those two terms.&lt;/li&gt;
  &lt;li&gt;The potential Φ depends only on the data and the architecture of the network (and not the optimization process). If it is equal to the loss function, SGD will converge to a global minimum. However, the paper shows that it’s rarely the case, and knowing how far Φ is from the loss function will tell you how likely your SGD will converge.&lt;/li&gt;
  &lt;li&gt;The entropy of the final distribution depends on the ratio &lt;em&gt;learning_rate/batch_size&lt;/em&gt; (the temperature). Intuitively, the entropy is related to the size of a distribution and having a high temperature often comes down to having a distribution with high variance, which usually means a flat minimum. Since flat minima are often considered to generalize better, it’s consistent with the empirical finding that high learning and low batch size often lead to better minima.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Therefore, seeing SGD as a distribution moving over time showed us that &lt;em&gt;learning_rate/batch_size&lt;/em&gt; is more meaningful than each hyperparameter separated regarding convergence and generalization. Moreover, it enabled the introduction of the potentiel of a network, related to convergence and that could give a good metric for architecture search.&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;The quest of finding a deep learning theory can be broken down into two parts: first, building intuitions on how and why it works, through toy models and experiments, then expressing those intuitions into a mathematical form that can help us explaining our current results and making new ones.&lt;/p&gt;

&lt;p&gt;In this first article, we tried to convey more intuition of both the high-dimensional loss function of neural networks and the interpretations of SGD, while showing that new kinds of formalism are being built in the objective of having a real mathematical theory of deep neural networks optimization.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;Felix Draxler, Kambis Veschgini, Manfred Salmhofer, Fred Hamprecht. &lt;em&gt;Essentially No Barriers in Neural Network Energy Landscape&lt;/em&gt;, ICML 2018. &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;C. Daniel Freeman, Joan Bruna. &lt;em&gt;Topology and Geometry of Half-Rectified Network Optimization&lt;/em&gt;, arXiv:1611.01540, 2016. &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;Yann Dauphin, Razvan Pascanu, Caglar Gulcehre, Kyunghyun Cho, Surya Ganguli, Yoshua Bengio. &lt;em&gt;Identifying and attacking the saddle point problem in high-dimensional non-convex optimization&lt;/em&gt;, NIPS 2014 &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;Nitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, Ping Tak Peter Tang. &lt;em&gt;On large-batch training for deep learning: Generalization gap and sharp minima&lt;/em&gt;, ICLR 2017. &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;Robert Kleinberg, Yuanzhi Li, Yang Yuan. &lt;em&gt;An Alternative View: When Does SGD Escape Local Minima?&lt;/em&gt;, ICML 2018 &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;Pratik Chaudhari, Stefano Soatto. &lt;em&gt;Stochastic gradient descent performs variational inference, converges to limit cycles for deep network&lt;/em&gt;, ICLR 2018 &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="machine-learning" /><summary type="html">Note: This post was first published as a Medium Article for Towards Data Science*</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/theory-deep-learning/blackboard.jpg" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/theory-deep-learning/blackboard.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">A Little Review of Domain Adaptation in 2017</title><link href="https://arthurpesah.me/blog/2018-01-03-domain-adaptation-2017/" rel="alternate" type="text/html" title="A Little Review of Domain Adaptation in 2017" /><published>2018-01-03T00:00:00+01:00</published><updated>2018-01-03T00:00:00+01:00</updated><id>https://arthurpesah.me/blog/domain-adaptation-2017</id><content type="html" xml:base="https://arthurpesah.me/blog/2018-01-03-domain-adaptation-2017/">&lt;p class=&quot;message&quot;&gt;&lt;strong&gt;Note&lt;/strong&gt;: This post was first published as a Quora answer to the question &lt;a href=&quot;https://www.quora.com/What-are-the-most-significant-machine-learning-advances-in-2017/answer/Arthur-Pesah&quot;&gt;What are the most significant machine learning advances in 2017?&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;2017 has been an amazing year for domain adaptation: awesome image-to-image and language-to-language translations have been produced, adversarial methods for DA have made huge progress and very innovative algorithms have been proposed to tackle the giant problem of adapting two domains.&lt;/p&gt;

&lt;p&gt;By domain adaptation, I mean any algorithm trying to transfer two domains, usually called source and target (for instance paintings and real photos), into a common domain. To do so, one can chose either to translate one domain into the other (e.g. translate paintings to photos) or to find a common embedding between the two domains. When only the source domain has labels and the goal is to predict the labels of the target domain, it’s called unsupervised domain adaptation and that’s where the advances were the most incredible. There are many benchmarks to evaluate a DA algorithm, one of the most common being to predict the labels of SVHN (a dataset of digits built with house numbers) by using MNIST (the most common handwritten digits dataset) and its labels. In a year, the results have passed from 90% (with Domain Transfer Network (DTN)&lt;sup id=&quot;fnref:1&quot;&gt;&lt;a href=&quot;#fn:1&quot; class=&quot;footnote&quot;&gt;1&lt;/a&gt;&lt;/sup&gt;, which was already a great improvement on previous methods that turned around 82%, like DRCN&lt;sup id=&quot;fnref:2&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;) to 99.2% (with self-ensembling DA&lt;sup id=&quot;fnref:3&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;). Besides this quantitative analysis, the translations performed by some algorithms released this year are qualitatively amazing, particularly in visual DA and NLP.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/svhn2mnist-SBDA-GAN.png&quot; alt=&quot;&quot; /&gt;
Figure 1. Transfer of SVHN to MNIST by SBADA-GAN&lt;sup id=&quot;fnref:4&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt;, May 2017. For testing a DA algorithm, one can try to predict the labels of SVHN by only using the labels of MNIST and the unsupervised translation between SVHN and MNIST.*&lt;/p&gt;

&lt;p&gt;Let’s try to summarize how awesome this year has been for domain adaptation.&lt;/p&gt;

&lt;h1 id=&quot;adversarial-domain-adaptation&quot;&gt;Adversarial Domain Adaptation&lt;/h1&gt;

&lt;p&gt;If 2015 saw the birth of adversarial domain adaptation (with DANN&lt;sup id=&quot;fnref:5&quot;&gt;&lt;a href=&quot;#fn:5&quot; class=&quot;footnote&quot;&gt;5&lt;/a&gt;&lt;/sup&gt;) and 2016 the birth of GAN-based domain adaptation (with CoGAN&lt;sup id=&quot;fnref:6&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt; and DTN&lt;sup id=&quot;fnref:2:1&quot;&gt;&lt;a href=&quot;#fn:2&quot; class=&quot;footnote&quot;&gt;2&lt;/a&gt;&lt;/sup&gt; ), 2017 has seen huge improvements and amazing results with these methods. The idea behind adversarial DA is to train two neural networks: a discriminator that tries to separate the target domain from the transformed source domain, and a generator that tries to fool the discriminator to make the source domain look like the target one as much as possible. It’s basically a GAN but taking the source distribution as input instead of a uniform distribution (it is usually called a conditional GAN). I’ve realized a little animation to explain the concept more visually (you can find the code &lt;a href=&quot;https://github.com/artix41/transfer-learning-algorithms/tree/master/adda&quot;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/gan-working.gif&quot; alt=&quot;&quot; /&gt;
Figure 2. GAN-based adversarial domain adaptation for two Gaussian domains. 
The discriminator (background) tries to separate the green distribution from the orange 
distribution, and the generator modifies the green distribution to fool the discriminator. 
You can find the code &lt;a href=&quot;https://github.com/artix41/transfer-learning-algorithms/tree/master/adda&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;So, what were the “significant advances” in 2017?&lt;/p&gt;

&lt;h2 id=&quot;adda&quot;&gt;ADDA&lt;/h2&gt;

&lt;p&gt;First, in February, ADDA&lt;sup id=&quot;fnref:8&quot;&gt;&lt;a href=&quot;#fn:8&quot; class=&quot;footnote&quot;&gt;7&lt;/a&gt;&lt;/sup&gt; released a generalized theoretical framework for adversarial domain adaptation and achieved a 76.0% score with a simple GAN loss on SVHN → MNIST (which they thought to be the best score for an adversarial network on this task, but they had probably not heard of DTN at the time they submitted their article).&lt;/p&gt;

&lt;h2 id=&quot;cyclegan&quot;&gt;CycleGAN&lt;/h2&gt;

&lt;p&gt;A month later, the most important contribution of adversarial DA occurred: the invention of the cycle-consistency loss by &lt;strong&gt;CycleGAN&lt;/strong&gt;&lt;sup id=&quot;fnref:9&quot;&gt;&lt;a href=&quot;#fn:9&quot; class=&quot;footnote&quot;&gt;8&lt;/a&gt;&lt;/sup&gt;. This paper was a real revolution. Their idea was to train two conditional GANs, one transferring source to target, and the other target to source, and to consider a new loss, called cycle-consistency, which ensures that if you connect the two networks together it will produce an identity mapping (source → target → source). Their examples of transferring horses to zebra or painting to photos have become really famous and I consider it to be one of the coolest thing of this year! Contrary to other methods like pix2pix&lt;sup id=&quot;fnref:10&quot;&gt;&lt;a href=&quot;#fn:10&quot; class=&quot;footnote&quot;&gt;9&lt;/a&gt;&lt;/sup&gt;, they didn’t train their algorithm on pairs of images (like a photo of cat and the sketch of this same cat, for pix2pix), but only on the two distributions separated, which makes their results even more impressive.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/cycleGAN.png&quot; alt=&quot;&quot; /&gt;
Figure 3. Examples of image-to-image translations with CycleGAN&lt;/p&gt;

&lt;h2 id=&quot;discogan&quot;&gt;DiscoGAN&lt;/h2&gt;

&lt;p&gt;What’s fun is that a bunch of other papers discovered the cycle-consistency loss simultaneously, between March and May, sometimes giving it another name (like reconstruction loss). It’s for instance the case of &lt;strong&gt;DiscoGAN&lt;/strong&gt;&lt;sup id=&quot;fnref:11&quot;&gt;&lt;a href=&quot;#fn:11&quot; class=&quot;footnote&quot;&gt;10&lt;/a&gt;&lt;/sup&gt;, whose loss was a bit different (cross-entropy for the GAN loss instead of MSE for instance) but they also achieved incredible results, by managing to transfer both texture properties (like transforming blonde-haired to brown-haired people, women to men or people with glasses to people without glasses) and geometrical properties (chairs to cars and faces to cars).&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/discoGAN-01.png&quot; alt=&quot;discoGAN-01&quot; /&gt;
&lt;img src=&quot;/assets/img/blog/domain-adaptation/discoGAN-02.png&quot; alt=&quot;discoGAN-02&quot; /&gt;
Figure 4. Examples of image-to-image translations with DiscoGAN&lt;/p&gt;

&lt;h2 id=&quot;dualgan&quot;&gt;DualGAN&lt;/h2&gt;

&lt;p&gt;It’s also the case of &lt;strong&gt;DualGAN&lt;/strong&gt;&lt;sup id=&quot;fnref:12&quot;&gt;&lt;a href=&quot;#fn:12&quot; class=&quot;footnote&quot;&gt;11&lt;/a&gt;&lt;/sup&gt;, who used the cycle loss with a WGAN and other recent tricks on how to train GANs. They applied it on day ←→ night or sketch ←→ photos translations, and here are the results:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/dualgan.png&quot; alt=&quot;dualgan&quot; /&gt;
Figure 5. Examples of image-to-image translations with DualGAN&lt;/p&gt;

&lt;h2 id=&quot;sbada-gan&quot;&gt;SBADA-GAN&lt;/h2&gt;

&lt;p&gt;But those 3 papers didn’t consider any dataset with a task (like classification), so didn’t give any quantitative evaluation of their method. &lt;strong&gt;SBADA-GAN&lt;/strong&gt;&lt;sup id=&quot;fnref:4:1&quot;&gt;&lt;a href=&quot;#fn:4&quot; class=&quot;footnote&quot;&gt;4&lt;/a&gt;&lt;/sup&gt; did it by adding a classifier at the end of their network in order to predict the labels of both the source and the transformed target sample. During the training, pseudo-labels are assigned to the target samples and contribute to the classification loss. The score obtained for SVHN → MNIST is not very good (~76%, same as ADDA), but they achieved new state-of-the-arts on the opposite transformation (MNIST→SVHN) and on MNIST ←→ USPS (another handwritten-digits dataset very close to MNIST).&lt;/p&gt;

&lt;h2 id=&quot;gentoadapt&quot;&gt;GenToAdapt&lt;/h2&gt;

&lt;p&gt;Other kind of adversarial architectures have been tried this year with more success on digits benchmarks, like &lt;strong&gt;GenToAdapt&lt;/strong&gt;&lt;sup id=&quot;fnref:14&quot;&gt;&lt;a href=&quot;#fn:14&quot; class=&quot;footnote&quot;&gt;12&lt;/a&gt;&lt;/sup&gt; in April who made the first real state-of-the-art of the year in SVHN → MNIST, with a score of 92.4%. Their technique was basically to use a GAN to generate source images from both source and target samples, and to discriminate both real vs fake samples and the different classes of the source samples (like AC-GAN). The learned embedding is then used to train a third network, C, to directly predict the labels of the input samples. The figure below (from the original paper) is certainly clearer than my explanation:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/gentoadapt.png&quot; alt=&quot;gentoadapt&quot; /&gt;
Figure 6. The architecture of GenToAdapt&lt;/p&gt;

&lt;h2 id=&quot;unit&quot;&gt;UNIT&lt;/h2&gt;

&lt;p&gt;It’s also the case of &lt;strong&gt;UNIT&lt;/strong&gt;&lt;sup id=&quot;fnref:15&quot;&gt;&lt;a href=&quot;#fn:15&quot; class=&quot;footnote&quot;&gt;13&lt;/a&gt;&lt;/sup&gt;, an adversarial method proposed by Nvidia. Like in many Nvidia papers, they performed a large bunch of amazing experiments (image-to-image translation between different outside conditions on the road, between GTA and reality, between different breeds of dogs, etc.). They have also tested their algorithm on SVHN → MNIST, and obtained 90.53%, which is very close to DTN score, but they manage to transfer much higher-resolution images. Their technique is based on CoGAN&lt;sup id=&quot;fnref:6:1&quot;&gt;&lt;a href=&quot;#fn:6&quot; class=&quot;footnote&quot;&gt;6&lt;/a&gt;&lt;/sup&gt;, which consists in two GANs, one for generating the source domain and one for the target domain, with weight-sharing for some layers. Nvidia’s main contribution was to replace the generator by a VAE. They indeed show that the VAE loss is equivalent to the cycle-consistency constraint described in the previous papers.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/UNIT.png&quot; alt=&quot;UNIT&quot; /&gt;
Figure 7. Examples of image-to-image translations with UNIT&lt;/p&gt;

&lt;h2 id=&quot;stargan&quot;&gt;StarGAN&lt;/h2&gt;

&lt;p&gt;However, those architectures are only capable of transferring one source domain to one target domain at a time. But if you have multiple domains, there should be a way to train a network to perform transfers in all the domains. In November &lt;strong&gt;StarGAN&lt;/strong&gt;&lt;sup id=&quot;fnref:17&quot;&gt;&lt;a href=&quot;#fn:17&quot; class=&quot;footnote&quot;&gt;14&lt;/a&gt;&lt;/sup&gt; adapted CycleGAN to this so-called multi-source domain adaptation problem. Their results in transferring different hair colors or emotions for the same person were pretty amazing as you can see:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/StarGAN.png&quot; alt=&quot;StarGAN&quot; /&gt;
Figure 8. Example of multi-domain image translations with StarGAN&lt;/p&gt;

&lt;h2 id=&quot;word-translation-without-parallel-data&quot;&gt;Word Translation Without Parallel Data&lt;/h2&gt;

&lt;p&gt;It might seem from the examples above that the DA community is putting all its efforts into computer vision (CV). But one of the most impressive (and shared) DA paper of the year is in natural language processing (NLP) : &lt;strong&gt;Word Translation Without Parallel Data&lt;/strong&gt;&lt;sup id=&quot;fnref:18&quot;&gt;&lt;a href=&quot;#fn:18&quot; class=&quot;footnote&quot;&gt;15&lt;/a&gt;&lt;/sup&gt;. They basically used adversarial DA to find a common embedding between samples from two languages (source and target), and managed to perform very accurate translations without having trained on any example of translation! If you read the paper, you can notice that the expression “domain adaptation” haven’t been used once… Since most DA folks are into computer vision, it seems that the NLP guys who wrote this paper were not aware that their work entered into domain adaptation. So I think NLP would benefit a great deal by testing on their data all the brand new DA methods that the CV community has invented this year.&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/translation-without-pairs.png&quot; alt=&quot;translation-without-pairs&quot; /&gt;
Figure 9. Alignement of the embedding word spaces of the source (english) and the target (italian) domains.&lt;/p&gt;

&lt;h2 id=&quot;pix2pix-hd&quot;&gt;Pix2Pix HD&lt;/h2&gt;

&lt;p&gt;Finally, I have talked only about unpaired domain adaptation (where you don’t use any pair of corresponding source/target samples during the training), but paired DA has also known a little revolution with &lt;strong&gt;pix2pixHD&lt;/strong&gt;&lt;sup id=&quot;fnref:19&quot;&gt;&lt;a href=&quot;#fn:19&quot; class=&quot;footnote&quot;&gt;16&lt;/a&gt;&lt;/sup&gt;. It’s basically an improved version of pix2pix (a conditional GAN trained on pairs of images) with many tricks to make it scalable to bigger images. They trained their network to transform semantic maps into realistic photos of street scenes, as you can see on the animation below:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/pix2pixHD.gif&quot; alt=&quot;pix2pixHD&quot; /&gt;
Figure 10. Translation of a semantic map (map of labels) to a real street scene with pix2pixHD&lt;/p&gt;

&lt;h1 id=&quot;embedding-methods&quot;&gt;Embedding methods&lt;/h1&gt;

&lt;p&gt;Apart from adversarial DA, many other methods have been tried this year, some of them being very successful. That’s the case of two recent methods which try to find a common embedding between the source and target domains, leading at the end to a single neural network capable of classifying both source and target samples.&lt;/p&gt;

&lt;h2 id=&quot;associative-da&quot;&gt;Associative DA&lt;/h2&gt;

&lt;p&gt;The first one is &lt;strong&gt;Associative DA&lt;/strong&gt; &lt;code class=&quot;MathJax_Preview&quot;&gt;DA_{assoc}&lt;/code&gt;&lt;script type=&quot;math/tex&quot;&gt;DA_{assoc}&lt;/script&gt;&lt;sup id=&quot;fnref:20&quot;&gt;&lt;a href=&quot;#fn:20&quot; class=&quot;footnote&quot;&gt;17&lt;/a&gt;&lt;/sup&gt; who achieved a score of &lt;strong&gt;97.6%&lt;/strong&gt; on SVHN→MNIST. In order to find the best embedding, they used the new trend of 2017… cycle-consistency loss! Yes, again, but this time without any GAN or other adversarial network: they just try to learn an embedding (last layer of a neural network) such that the probability of translating a source sample to a target sample (based on the distance between the two points in the embedding space), then converting back this target sample to another source sample will be high if the two source samples belong to the same class.&lt;/p&gt;

&lt;h2 id=&quot;self-ensembling-da&quot;&gt;Self-Ensembling DA&lt;/h2&gt;

&lt;p&gt;The second one is &lt;strong&gt;Self-Ensembling DA&lt;/strong&gt;&lt;sup id=&quot;fnref:3:1&quot;&gt;&lt;a href=&quot;#fn:3&quot; class=&quot;footnote&quot;&gt;3&lt;/a&gt;&lt;/sup&gt;, who really destroyed our benchmark SVHN→MNIST with a score of &lt;strong&gt;99.2%&lt;/strong&gt; ! We’ll have to find other benchmarks next year! They did this exploit by adapting Mean Teacher − a method coming from semi-supervised learning that has achieved recent SOTA in this field − to domain adaptation. The idea is to have two networks, a student and a teacher, and to make the weights of the teacher a moving average of all the weights that the student got during training. Then, labeled source samples are used to train the student to be a good classifier, and unlabeled target samples to train the student to be like the teacher (with a consistency loss). You can find a more visual explanation &lt;a href=&quot;https://thecuriousaicompany.com/mean-teacher/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;optimal-transport&quot;&gt;Optimal Transport&lt;/h1&gt;

&lt;p&gt;Another kind of method has been developed this year: domain adaptation based on optimal transport. Optimal transport is a huge area of applied mathematics, consisting in finding the best transport plan from one distribution to another, by minimizing the total cost of transporting a source mass to a target point. For instance, if you consider two sets of points (with the same number of points each), source and target, and take as the cost function simply the euclidean distance, optimal transport asks you to associate every source point to a target points, so that the total distance is minimized. Here is the solution for two Gaussian domains:&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/simple-ot.png&quot; alt=&quot;simple-ot&quot; /&gt;
Figure 11. Best transport plan between two Gaussian domains. 
Each source point is transported to a target point, and the total distance is minimized. 
This graph has been produced with the library &lt;a href=&quot;https://github.com/rflamary/POT&quot;&gt;POT&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This &lt;a href=&quot;https://vincentherrmann.github.io/blog/wasserstein/&quot;&gt;blog article&lt;/a&gt; is an excellent introduction if you want to learn more about OT.&lt;/p&gt;

&lt;p&gt;If you start to understand a bit domain adaptation, I think you can now clearly see the link between OT and DA. The relation between those two fields had been theorized in 2016&lt;sup id=&quot;fnref:22&quot;&gt;&lt;a href=&quot;#fn:22&quot; class=&quot;footnote&quot;&gt;18&lt;/a&gt;&lt;/sup&gt;, but a very interesting algorithm has come out in 2017: &lt;strong&gt;Joint Distribution Optimal Transportation (JDOT)&lt;/strong&gt;&lt;sup id=&quot;fnref:23&quot;&gt;&lt;a href=&quot;#fn:23&quot; class=&quot;footnote&quot;&gt;19&lt;/a&gt;&lt;/sup&gt;. Their method is an iterative process: at each iteration, pseudo-labels are given to every target points (at first using a classifier trained on the source samples). Then, the goal is to transport every source point to a target point, minimizing not only the total distance traveled, but also the number of change of label during the transport (between the label of the source point and the pseudo-label of the target point). I made a visual explanation here : &lt;a href=&quot;https://github.com/artix41/transfer-learning-algorithms/blob/master/jdot/README.md&quot;&gt;A Visual Explanation of JDOT Algorithm&lt;/a&gt;, summarized in this GIF (not sure if understandable without pausing at each step):&lt;/p&gt;

&lt;p class=&quot;figure&quot;&gt;&lt;img src=&quot;/assets/img/blog/domain-adaptation/animation.gif&quot; alt=&quot;animation&quot; /&gt;
Figure 12. Animation showing the different steps of the JDOT algorithm. 
You can find all those images separated and associated to some explanations 
&lt;a href=&quot;https://github.com/artix41/transfer-learning-algorithms/blob/master/jdot/README.md&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;

&lt;p&gt;To sum it up, not only has 2017 destroyed some domain adaptation benchmarks, it has also produced the first high-quality translations from one domain to another (as you can see in all those pictures above). But we can still do much better on many more complicated benchmarks and adapt DA to other areas of machine learning (like reinforcement learning and NLP), so 2018 has all its chances to be as awesome as 2017, and I look forward to see what it gives!&lt;/p&gt;

&lt;p&gt;If you want to learn more about domain adaptation, I’m maintaining an updated list of great resources (papers, datasets, results, etc.) about DA and transfer learning on &lt;a href=&quot;https://github.com/artix41/awesome-transfer-learning&quot;&gt;this GitHub repository&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Disclaimer&lt;/strong&gt;: the description of those papers only corresponds to my current understanding of them, so take it with a grain of salt and don’t hesitate to tell me if I am incorrect or imprecise in some of my explanations. Concerning the results I give, they are only the ones given in the original papers and a more rigorous methodology should be used in order to make a real comparison.&lt;/p&gt;

&lt;div class=&quot;footnotes&quot;&gt;
  &lt;ol&gt;
    &lt;li id=&quot;fn:1&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.02200.pdf&quot;&gt;Unsupervised Cross-domain Image Generation&lt;/a&gt; (2016) &lt;a href=&quot;#fnref:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:2&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1607.03516.pdf&quot;&gt;Deep Reconstruction-Classification Networks for Unsupervised Domain Adaptation&lt;/a&gt; (2016) &lt;a href=&quot;#fnref:2&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt; &lt;a href=&quot;#fnref:2:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:3&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1706.05208.pdf&quot;&gt;Self-ensembling for domain adaptation&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:3&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt; &lt;a href=&quot;#fnref:3:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:4&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.08824.pdf&quot;&gt;From source to target and back: symmetric bi-directional adaptive GAN&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:4&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt; &lt;a href=&quot;#fnref:4:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:5&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1505.07818.pdf&quot;&gt;Domain-Adversarial Training of Neural Networks&lt;/a&gt; (2015) &lt;a href=&quot;#fnref:5&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:6&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1606.07536.pdf&quot;&gt;Coupled Generative Adversarial Networks&lt;/a&gt; (2016) &lt;a href=&quot;#fnref:6&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt; &lt;a href=&quot;#fnref:6:1&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:8&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1702.05464.pdf&quot;&gt;Adaptative Discriminative Domain Adaptation&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:8&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:9&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.10593&quot;&gt;Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:9&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:10&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1611.07004.pdf&quot;&gt;Image-to-Image Translation with Conditional Adversarial Networks&lt;/a&gt; (2016) &lt;a href=&quot;#fnref:10&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:11&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.05192.pdf&quot;&gt;Learning to Discover Cross-Domain Relations with Generative Adversarial Networks&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:11&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:12&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.02510.pdf&quot;&gt;DualGAN: Unsupervised Dual Learning for Image-to-Image Translation&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:12&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:14&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1704.01705.pdf&quot;&gt;Generate To Adapt: Aligning Domains using Generative Adversarial Networks&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:14&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:15&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1703.00848.pdf&quot;&gt;Unsupervised Image-to-Image Translation Networks&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:15&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:17&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1711.09020.pdf&quot;&gt;StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:17&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:18&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;&quot;&gt;Word Translation without Parallel Data&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:18&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:19&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1711.11585.pdf&quot;&gt;High-Resolution Image Synthesis and Semantic Manipulation with Conditional GANs&lt;/a&gt; &lt;a href=&quot;#fnref:19&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:20&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1708.00938.pdf&quot;&gt;Associative Domain Adaptation&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:20&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:22&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1610.04420.pdf&quot;&gt;Theoretical Analysis of Domain Adaptation with Optimal Transport&lt;/a&gt; (2016) &lt;a href=&quot;#fnref:22&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
    &lt;li id=&quot;fn:23&quot;&gt;
      &lt;p&gt;&lt;a href=&quot;https://arxiv.org/pdf/1705.08848.pdf&quot;&gt;Joint distribution optimal transportation for domain adaptation&lt;/a&gt; (2017) &lt;a href=&quot;#fnref:23&quot; class=&quot;reversefootnote&quot;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
    &lt;/li&gt;
  &lt;/ol&gt;
&lt;/div&gt;</content><author><name>Arthur Pesah</name><email>arthur.pesah@gmail.com</email></author><category term="blog" /><category term="machine-learning" /><summary type="html">Note: This post was first published as a Quora answer to the question What are the most significant machine learning advances in 2017?</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://arthurpesah.me/assets/img/blog/domain-adaptation/teaser_high_res.jpg" /><media:content medium="image" url="https://arthurpesah.me/assets/img/blog/domain-adaptation/teaser_high_res.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>